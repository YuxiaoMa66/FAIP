{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj2Jai2eHNDo"
      },
      "source": [
        "# **Introduction to Computer Vision - Tutorial**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Welcome to a tutorial session on computer vision as part of the Fundamentals of Artificial Intelligence Programme. In this notebook, we introduce libraries and codes that you need for the computer vision assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LkoMwBhJAV_"
      },
      "source": [
        "##  **Image Processing** \n",
        "---\n",
        "\n",
        "### **Image Array**\n",
        "An image is a two-dimensional array, thus we use the most popular array library, *Numpy*, in Python to represent and process as an image array. An example array is represented in the following generated by a custom function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install packages for running locally\n",
        "# !pip install opencv-python \n",
        "# matplotlib numpy torch torchvision \n",
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uSjx9dPfOVR1"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1AdY3CXXt-X"
      },
      "outputs": [],
      "source": [
        "# This is a custom funcion to generate chekered pattern in a 2D array\n",
        "# Returns an LxL array, with C checkered blocks per direction\n",
        "def np_checkered(L, C):\n",
        "    assert L % C == 0\n",
        "    r = np.arange(C, dtype=np.uint8) & 1\n",
        "    r = np.kron(r, np.ones(L // C, dtype=np.uint8))\n",
        "    # `^ 1` fill force upper-left cell to consist of 1s\n",
        "    return (r ^ 1) ^ r[:, None]\n",
        " \n",
        "print(np_checkered(8, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9taY3zu-Yt5h"
      },
      "source": [
        "###  **Read & Display Images** \n",
        "\n",
        "However, we often visualize the image array into interpretable format that human eye can perceive. There are some libraries that support image formats in Python \n",
        "\n",
        "\n",
        "*   Matplotlib — plt.imread(), plt.imshow()\n",
        "*   OpenCV — cv2.imread(), cv2.imshow()\n",
        "*   Pillow — Image.open(), \n",
        "*   scikit-image — io.imread()\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VGhYxpxsOczl"
      },
      "outputs": [],
      "source": [
        "# we use matplotlib to visualize our generated checkered pattern\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzwLCkftaJCN"
      },
      "outputs": [],
      "source": [
        "# the image can be visualized using one line of code \n",
        "plt.imshow(np_checkered(8, 4), cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDt6U0bQXeb7"
      },
      "source": [
        "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. Natively, matplotlib only supports PNG images. PNG images are returned as float arrays (0 to 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5HllBIxZLIc"
      },
      "source": [
        "A photo image is commonly captured by a camera sensor and saved in \n",
        "\n",
        "- (M, N) for grayscale images.\n",
        "- (M, N, 3) for RGB images.\n",
        "- (M, N, 4) for transparent images.\n",
        "\n",
        "Computer-generated images (graphics) can be saved in vector and 3D formats. \n",
        "In this tutorial, we focus on 2D images. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCRHK_o4K1FD"
      },
      "outputs": [],
      "source": [
        "# The type of the image is just a numpy array\n",
        "print(f\"type(img): {type(img)}, img.shape: {img.shape}\\n\\n\")\n",
        "\n",
        "# The image can be printed as an array \n",
        "imread = print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHFDav7TRjU8"
      },
      "outputs": [],
      "source": [
        "# you can read url jpeg images from a link and visualize it \n",
        "import urllib.request\n",
        "\n",
        "req = urllib.request.urlopen(\"https://i.pinimg.com/originals/32/ae/1f/32ae1ff77bc598200309bb9eddd11622.jpg\")\n",
        "img = plt.imread(req ,0)\n",
        "\n",
        "# jpgs are returned with values between 0 and 255\n",
        "print(img.min(), img.max())\n",
        "\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS_v6opJkkYe"
      },
      "outputs": [],
      "source": [
        "# What is the size of my image?\n",
        "print(f\"shape: {img.shape}\")\n",
        "\n",
        "height, width, channels = img.shape\n",
        "\n",
        "print(f\"Image has height={height}, width={width}, and {channels} channels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSUNPCO65aWg"
      },
      "outputs": [],
      "source": [
        "# Image size can be manipulated by cutting pixels from the width and the hight of the image (crop), using numpy array slicing\n",
        "\n",
        "# Use ':' in the channel dimension to select all channels\n",
        "imgresize = img[50:410, 90:600, :]\n",
        "\n",
        "height, width, channels = imgresize.shape\n",
        "print(f\"Image has height={height}, width={width}, and {channels} channels\")\n",
        "\n",
        "plt.imshow(imgresize) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIIYYkVgOStt"
      },
      "source": [
        "One can do photoshop-like processing with OpenCV library such as downsampling and filtering an image  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rGq__DRq5Xnc"
      },
      "outputs": [],
      "source": [
        "# import OpenCV library \n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3holA9qOrto"
      },
      "outputs": [],
      "source": [
        "# resizing the image can be done using OpenCV functions easily \n",
        "\n",
        "# with the downsampling the height to width ratio of image is preserved\n",
        "img_resized = cv2.resize(imgresize,(0,0), fx=0.8, fy=0.8)\n",
        "\n",
        "#resize the image by forcing the dimensions \n",
        "#img_resized = cv2.resize(imgresize,(256, 256))\n",
        "\n",
        "height, width, channels = img_resized.shape\n",
        "print(height,width,channels)\n",
        "plt.imshow(img_resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ew74GIDq53n_"
      },
      "outputs": [],
      "source": [
        "# image can be converted to grayscale \n",
        "img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
        "plt.imshow(img_gray, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5cv-1iZ7eaA"
      },
      "outputs": [],
      "source": [
        "# image can be smoothed using Gaussian filter\n",
        "img_blur = cv2.GaussianBlur(img_gray, (13,13), 0)\n",
        "plt.imshow(img_blur, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ertjXHtB7iy6"
      },
      "outputs": [],
      "source": [
        "# use edge detector filter \n",
        "img_edges = cv2.Canny(image=img_blur, threshold1=60, threshold2=60) \n",
        "plt.imshow(img_edges, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN-l4uRZWdhZ"
      },
      "outputs": [],
      "source": [
        "# Invert image colours\n",
        "img_not= cv2.bitwise_not(img_edges)\n",
        "plt.imshow(img_not, cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghIjapRWXjmR"
      },
      "outputs": [],
      "source": [
        "# check the pixel values  \n",
        "imread = print(img_gray)\n",
        "\n",
        "# normalize image to the range [0, 1], make sure the output data type is float.\n",
        "norm_image = cv2.normalize(img_gray, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "print(f\"type(img): {type(img_not)}, img.shape: {img_not.shape}\\n\\n\")\n",
        "\n",
        "# double check the pixel values \n",
        "imread = print(norm_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXnCsDZ7My1J"
      },
      "source": [
        "# **Convolutional Neural Network**\n",
        "---\n",
        "\n",
        "*Pytorch* is one of the popular machine learning programming frameworks to implement Python's convolutional neural network (CNN). *Pytorch* is based on the *Torch* library performing operations on the tensor data format. Tensors are high-dimensional arrays used to stack visual features in intermediate layers of CNN models. See [Pytorch Totorial](https://pytorch.org/tutorials/beginner/introyt/introyt1_tutorial.html) if you are looking for more details. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eovDrHMlRoI1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "# example tensor of shape 2x3x2\n",
        "z = torch.zeros(2, 3, 2)\n",
        "\n",
        "print(z)\n",
        "print(z.dtype)\n",
        "\n",
        "# You can convert a (numpy) image to a tensor\n",
        "img_tensor = transforms.functional.to_tensor(img_gray)\n",
        "\n",
        "print(img_tensor.shape)\n",
        "\n",
        "# to_tensor also rescales images to 0-1\n",
        "print(f\"image range: {img_gray.min(), img_gray.max()}\")\n",
        "print(f\"img_tensor range: {img_tensor.min(), img_tensor.max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X_6KXgSX-O3H"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a neural network model.\n",
        "def create_model():\n",
        "  # nn.Sequential takes multiple neural network modules and sequentially passes \n",
        "  # the input through the modules.\n",
        "  model = nn.Sequential(\n",
        "              # MNIST image has dimension 28 x 28 (height x width)\n",
        "              nn.Conv2d(1, 28, kernel_size=3, padding=1), # output: 28 x 28 x 28\n",
        "              nn.ReLU(),\n",
        "              \n",
        "              nn.Conv2d(28, 32, kernel_size=3, stride=1, padding=1), # output: 32 x 28 x 28\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2, 2), # output: 32 x 14 x 14\n",
        "              nn.BatchNorm2d(32),\n",
        "              \n",
        "              nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # output: 64 x 14 x 14\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(2, 2), # output: 64 x 7 x 7\n",
        "              nn.BatchNorm2d(64),\n",
        "\n",
        "              nn.Flatten(), # Flattens the 64 x 7 x 7 tensor into a one dimensional array of length 64*7*7\n",
        "\n",
        "              nn.Linear(64*7*7, 10) # output: one dimensional array of size 10\n",
        "          )\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEhoHceT-mzy"
      },
      "outputs": [],
      "source": [
        "# Check the model\n",
        "print(create_model())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJvQVO0n49wC"
      },
      "source": [
        "### **MNIST dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSrNfjGMhben"
      },
      "outputs": [],
      "source": [
        "# Import MNIST\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Download and Save MNIST \n",
        "data_train = MNIST('~/mnist_data', train=True, download=True, transform=ToTensor())\n",
        "data_test = MNIST('~/mnist_data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "# Print Data\n",
        "print(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array(data_train.data[0]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRVnPBb_kCKX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show the first image in the training set\n",
        "random_image = data_train.data[0]\n",
        "random_image_label = data_train.targets[0]\n",
        "\n",
        "# Print the Image using Matplotlib\n",
        "plt.imshow(random_image,cmap='gray')\n",
        "print(\"The label of the image is:\", random_image_label)\n",
        "\n",
        "print(random_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvz_O-B7mkxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# DataLoaders allow you to iterate through the data in randomized batches.\n",
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(data_train, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "    \n",
        "    'test'  : torch.utils.data.DataLoader(data_test, \n",
        "                                          batch_size=100, \n",
        "                                          shuffle=True, \n",
        "                                          num_workers=1),\n",
        "}\n",
        "\n",
        "loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkDTpOKdUbcy"
      },
      "outputs": [],
      "source": [
        "example_batch = None\n",
        "\n",
        "# A batch from the dataloader consists of a tensor of 100 images, and \n",
        "# a tensor of 100 labels\n",
        "for images, labels in loaders[\"train\"]:\n",
        "  print(images.shape, labels.shape)\n",
        "\n",
        "  example_batch = images, labels\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vxJBpQZn1LQ"
      },
      "source": [
        "### **Training the CNN model on MNIST data**\n",
        "\n",
        "Now that the CNN model is defined and the dataset is loaded, it's time to train the model on the training set!\n",
        "\n",
        "You may change the CNN parameters such as convolutional layers, or/and training hyperparameters such as numeber of epochs to improve the accuracy of the model. Note that the model needs to be re-trained if you change these parameters.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PRMlF00SoIvu"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Axi71S_XlrZM"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "# model.parameters() are the weights that should be updated during training\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hlkEfejlqLh3"
      },
      "outputs": [],
      "source": [
        "# Setup tensorboard to log training results\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Change the comment to something else to identify the run in tensorboard\n",
        "writer = SummaryWriter(comment=\"mnist_run\")\n",
        "\n",
        "# Adds a graph of the model to tensorboard.\n",
        "# In the graph tab you can see the computional graph of the model.\n",
        "writer.add_graph(model, example_batch[0])\n",
        "\n",
        "writer.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMxGSMvLmL1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# device = \"cpu\"\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX42smnXrjFA"
      },
      "outputs": [],
      "source": [
        "# Move the model to the GPU to train faster\n",
        "# If you get an error, choose gpu as hardware accelerator under Runtime -> Change runtime type\n",
        "# model.cuda()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhetQiLbmSBJ"
      },
      "outputs": [],
      "source": [
        "# The number of epochs to train for.\n",
        "# During each epoch, the model is trained on all of the training data\n",
        "num_epoch = 5\n",
        "\n",
        "for epoch in range(1, num_epoch+1):\n",
        "  train_loss=0.0\n",
        "  valid_loss=0.0\n",
        "\n",
        "  train_correct = 0\n",
        "  valid_correct = 0\n",
        "\n",
        "  # Set the model to train mode\n",
        "  model.train()\n",
        "\n",
        "  # Go through all the mini-batches in the train loader\n",
        "  for img, lbl in loaders['train']:\n",
        "\n",
        "    # Put the data on the gpu\n",
        "    img=img.to(device)\n",
        "    lbl=lbl.to(device)\n",
        "\n",
        "    # Set the accumaleted gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Get the output of the model\n",
        "    predict = model(img)\n",
        "    \n",
        "    # Compute the loss\n",
        "    loss=loss_fn(predict,lbl)\n",
        "    \n",
        "    # Compute the gradients and update the weigths\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Update the cumulative train loss of this epoch\n",
        "    train_loss += loss.item() * img.size(0)\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = predict.argmax(dim=1)\n",
        "\n",
        "    train_correct += torch.sum(predicted_labels == lbl)\n",
        "\n",
        "\n",
        "  # Evaluate the model on the test data\n",
        "  model.eval()\n",
        "  for img,lbl in loaders['test']:\n",
        "    img=img.to(device)\n",
        "    lbl=lbl.to(device)\n",
        "\n",
        "    predict=model(img)\n",
        "    loss=loss_fn(predict,lbl)\n",
        "\n",
        "    # Update the test loss for this epoch\n",
        "    valid_loss+=loss.item()*img.size(0)\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = predict.argmax(dim=1)\n",
        "\n",
        "    valid_correct += torch.sum(predicted_labels == lbl)\n",
        "  \n",
        "  # Compute the loss and accuracy metrics for this epoch\n",
        "  train_loss=train_loss/len(loaders['train'].sampler) \n",
        "  valid_loss=valid_loss/len(loaders['test'].sampler)\n",
        "\n",
        "  train_acc = train_correct / len(loaders['train'].sampler) \n",
        "  valid_acc = valid_correct / len(loaders['test'].sampler)\n",
        "\n",
        "  print('Epoch:{} Train Loss:{:.4f} valid Loss:{:.4f}; train Acc:{:.4f} valid Acc:{:.4f}'.format(epoch,train_loss,valid_loss, train_acc, valid_acc))\n",
        "\n",
        "  # Log results to tensorboard\n",
        "  writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "  writer.add_scalar('Loss/test', valid_loss, epoch)\n",
        "\n",
        "  writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
        "  writer.add_scalar('Accuracy/test', valid_acc, epoch)\n",
        "\n",
        "  writer.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvnuPMPjjl5f"
      },
      "source": [
        "## Tensorboard\n",
        "\n",
        "We will also use tensorboard to visualize the training results. \n",
        "Use the scalars and/or time series tab to inspect the learning curves of the model. The graphs tab shows a diagram of the model architecture where you can double-click on the nodes to see more details.\n",
        "\n",
        "If you get a 403 error in the tensorboard view, you have to enable third-party cookies/turn off tracking protection. See [here](https://stackoverflow.com/questions/64218755/getting-error-403-in-google-colab-with-tensorboard-with-firefox).\n",
        "\n",
        "To refresh tensorboard either click on the refresh button in the top right, or rerun this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICGwKx7sjk_O"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMcpuZ9rnKvT"
      },
      "source": [
        "## Visualizing predictions\n",
        "\n",
        "The following code shows the predicted and actual labels of 10 random images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36PJhwx2P0lo"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "import random\n",
        "\n",
        "correct = 0\n",
        "\n",
        "data_test[0][0].shape\n",
        "\n",
        "# Randomly select 10 indices from the test data\n",
        "random_indices = random.sample(range(len(data_test)), k=10)\n",
        "\n",
        "for i in random_indices:\n",
        "  img = data_test[i][0]\n",
        "  label = data_test[i][1]\n",
        "\n",
        "  input = img.reshape(-1, 1, 28, 28)\n",
        "\n",
        "  prediction = model(input.to(device))\n",
        "\n",
        "  predicted_label = prediction.argmax()\n",
        "\n",
        "  is_correct = label == predicted_label\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(f\"{is_correct}, actual label: {label}, predicted label: {predicted_label}\", color=\"black\" if is_correct else \"red\")\n",
        "  plt.imshow(input.reshape(28, 28), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY7gAnrXnVZs"
      },
      "source": [
        "## Incorrectly predicted digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "brzk29Lqg431"
      },
      "outputs": [],
      "source": [
        "# Store all incorrectly predicted images from the test set\n",
        "\n",
        "model.eval()\n",
        "\n",
        "incorrect_imgs = []\n",
        "incorrect_labels = []\n",
        "incorrect_predictions = []\n",
        "\n",
        "for imgs, labels in loaders[\"test\"]:\n",
        "\n",
        "  imgs, labels = imgs.to(device), labels.to(device)\n",
        "  \n",
        "  predictions = model(imgs.to(device))\n",
        "\n",
        "  predictions = predictions.argmax(dim=1)\n",
        "\n",
        "  correct_indices = predictions == labels\n",
        "  incorrect_indices = ~ correct_indices\n",
        "\n",
        "\n",
        "  incorrect_imgs.append(imgs[incorrect_indices].cpu())\n",
        "  incorrect_labels.append(labels[incorrect_indices].cpu())\n",
        "  incorrect_predictions.append(predictions[incorrect_indices].cpu())\n",
        "\n",
        "incorrect_imgs = torch.cat(incorrect_imgs, dim=0)\n",
        "incorrect_labels = torch.cat(incorrect_labels, dim=0)\n",
        "incorrect_predictions = torch.cat(incorrect_predictions, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uhar3IgZkwuf"
      },
      "outputs": [],
      "source": [
        "for i in range(min(10, len(incorrect_labels))):\n",
        "  is_correct = False\n",
        "\n",
        "  plt.figure()\n",
        "  plt.title(f\"{is_correct}, actual label: {incorrect_labels[i]}, predicted label: {incorrect_predictions[i]}\", color=\"black\" if is_correct else \"red\")\n",
        "  plt.imshow(incorrect_imgs[i].reshape(28, 28), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up6OR-eBYcEz"
      },
      "source": [
        "## Access Google Drive on Google Colab\n",
        "\n",
        "If you uploaded your handdrawn digits to google drive you can access them by mounting your google drive as a folder.\n",
        "\n",
        "To see what's in your drive you can run `!ls /content/gdrive` to list the files. You can also find the folder where you stored your images by using the file explorer on the left side of colab. After mounting there should be a folder called gdrive.\n",
        "\n",
        "Note that if you want to directly load and save data in your GD space, you need to give access to Google colab to access your drive otherwise use publicly accessable storage space to read/write data from/to the notebook. \n",
        "\n",
        "\n",
        "\n",
        "<!-- This notebook is running remotely on the Google Colab platform, therefore to save and access this notebook in your personal (local or remote) Google space you need to give access to Google to control your Google drive (gdrive).  To have local access, a virtual drive is used on your computer to save and access this notebook. You can make a directory on your gdrive to also save images that are read or written, by colab, in your drive. The following code snippet will mount the gdrive.  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wc3ex0buYajZ"
      },
      "outputs": [],
      "source": [
        "# You need to give access to your google drive to mount the virtual drive here\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf_torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
