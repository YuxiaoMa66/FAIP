{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file from new_df_8.csv to new_df_12.csv\n",
    "df_new = []\n",
    "for i in range(8, 13):\n",
    "    df_new.append(pd.read_csv(f'new_df_{i}.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "Number of columns left for unique_types: 36\n"
     ]
    }
   ],
   "source": [
    "# read unique_types.csv into a list\n",
    "unique_types = pd.read_csv('unique_types.csv')\n",
    "unique_types = unique_types['type'].tolist()\n",
    "print(len(unique_types))\n",
    "# # delete the unique_types columns in new_df if the number of the type is less than 100 that not 0\n",
    "# for col in unique_types:\n",
    "#     if (new_df[col] != 0).sum() < 500:\n",
    "#         new_df = new_df.drop(columns=[col])\n",
    "#         # delete the type in the list\n",
    "#         unique_types.remove(col)\n",
    "        \n",
    "print(f\"Number of columns left for unique_types: {len(unique_types)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 0: 71.91%\n"
     ]
    }
   ],
   "source": [
    "new_df = df_new[2]\n",
    "# Calculate the frequency of the number 0 across all unique_types columns\n",
    "zero_count = (new_df[unique_types] == 0).sum().sum()\n",
    "\n",
    "# Calculate the total count of all numbers in unique_types columns\n",
    "total_count = len(new_df) * len(unique_types)\n",
    "\n",
    "# Calculate the overall percentage of the number 0\n",
    "zero_percentage = (zero_count / total_count) * 100\n",
    "\n",
    "# Print the percentage of the number 0\n",
    "print(f\"Percentage of 0: {zero_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replce the number of all the outliers in 5 dataset in df_new if the it is larger than 99.99% quantile in the unique_types to the 99.99% quantile\n",
    "for i in range(5):\n",
    "    for col in unique_types:\n",
    "        if df_new[i][col].quantile(0.999) < df_new[i][col].max():\n",
    "            df_new[i].loc[df_new[i][col] > df_new[i][col].quantile(0.999), col] = df_new[i][col].quantile(0.999)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value of Noise - Park - Loud Music/Party: 65\n",
      "Max value of Noise - Residential - Loud Music/Party: 417.86800000001676\n",
      "Max value of Noise - Street/Sidewalk - Loud Talking: 138.43400000000838\n",
      "Max value of Noise - Vehicle - Car/Truck Music: 229.43400000000838\n",
      "Max value of Noise - Helicopter - Other: 354.1700000000419\n",
      "Max value of Noise - Residential - Banging/Pounding: 491.86800000001676\n",
      "Max value of Noise - Street/Sidewalk - Loud Music/Party: 601.7360000000335\n",
      "Max value of Noise - Commercial - Loud Music/Party: 284.30200000002515\n",
      "Max value of Noise - Commercial - Loud Talking: 35\n",
      "Max value of Noise - Residential - Loud Talking: 113.73600000003353\n",
      "Max value of Noise - Vehicle - Car/Truck Horn: 29\n",
      "Max value of Noise - Commercial - Banging/Pounding: 30\n",
      "Max value of Noise - Noise: Construction Before/After Hours (NM1): 55.43400000000838\n",
      "Max value of Noise - Noise, Barking Dog (NR5): 26.434000000008382\n",
      "Max value of Noise - Noise: Jack Hammering (NC2): 10\n",
      "Max value of Noise - Residential - Loud Television: 36\n",
      "Max value of Noise - Vehicle - Engine Idling: 58\n",
      "Max value of Noise - Noise: Construction Equipment (NC1): 23\n",
      "Max value of Noise - Noise: Alarms (NR3): 9\n",
      "Max value of Noise - Commercial - Car/Truck Horn: 6\n",
      "Max value of Noise - Noise: Private Carting Noise (NQ1): 7\n",
      "Max value of Noise - Noise: air condition/ventilation equipment (NV1): 20\n",
      "Max value of Noise - Noise, Other Animals (NR6): 3\n",
      "Max value of Noise - Noise:  lawn care equipment (NCL): 7\n",
      "Max value of Noise - House of Worship - Loud Music/Party: 5\n",
      "Max value of Noise - Commercial - Loud Television: 1\n",
      "Max value of Noise - Helicopter - NYPD: 4\n",
      "Max value of Collection Truck Noise - 21 Collection Truck Noise: 1\n",
      "Max value of Noise - Commercial - Car/Truck Music: 15\n",
      "Max value of Noise - Park - Loud Talking: 10\n",
      "Max value of Noise - Noise, Ice Cream Truck (NR4): 11\n",
      "Max value of Noise - Noise: Boat(Engine,Music,Etc) (NR10): 4\n",
      "Max value of Noise - Noise: Manufacturing Noise (NK1): 2\n",
      "Max value of Noise - House of Worship - Loud Talking: 2\n",
      "Max value of Noise - Helicopter - News Gathering: 4\n",
      "Max value of Noise - House of Worship - Banging/Pounding: 1\n"
     ]
    }
   ],
   "source": [
    "# print the max value of the unique_types\n",
    "for col in unique_types:\n",
    "    print(f\"Max value of {col}: {df_new[3][col].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted columns: ['Noise - Park - Loud Music/Party', 'Noise - Helicopter - Other', 'Noise - Commercial - Loud Talking', 'Noise - Commercial - Car/Truck Horn', 'Noise - Noise: Private Carting Noise (NQ1)', 'Noise - Noise, Other Animals (NR6)', 'Noise - Noise:  lawn care equipment (NCL)', 'Noise - House of Worship - Loud Music/Party', 'Noise - Commercial - Loud Television', 'Noise - Helicopter - NYPD', 'Collection Truck Noise - 21 Collection Truck Noise', 'Noise - Commercial - Car/Truck Music', 'Noise - Park - Loud Talking', 'Noise - Noise, Ice Cream Truck (NR4)', 'Noise - Noise: Boat(Engine,Music,Etc) (NR10)', 'Noise - Noise: Manufacturing Noise (NK1)', 'Noise - House of Worship - Loud Talking', 'Noise - Helicopter - News Gathering', 'Noise - House of Worship - Banging/Pounding']\n"
     ]
    }
   ],
   "source": [
    "# zero_frequencies = (new_df[unique_types] == 0).sum() / len(new_df)\n",
    "\n",
    "# # >80% columns with 0\n",
    "# columns_to_drop = zero_frequencies[zero_frequencies > 0.8].index\n",
    "\n",
    "# # Drop the columns\n",
    "# new_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# # Print the columns that were dropped\n",
    "# print(f\"Deleted columns: {list(columns_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Noise - Park - Loud Music/Party', 'Noise - Helicopter - Other', 'Noise - Commercial - Loud Talking', 'Noise - Commercial - Car/Truck Horn', 'Noise - Noise: Private Carting Noise (NQ1)', 'Noise - Noise, Other Animals (NR6)', 'Noise - Noise:  lawn care equipment (NCL)', 'Noise - House of Worship - Loud Music/Party', 'Noise - Commercial - Loud Television', 'Noise - Helicopter - NYPD', 'Collection Truck Noise - 21 Collection Truck Noise', 'Noise - Commercial - Car/Truck Music', 'Noise - Park - Loud Talking', 'Noise - Noise, Ice Cream Truck (NR4)', 'Noise - Noise: Boat(Engine,Music,Etc) (NR10)', 'Noise - Noise: Manufacturing Noise (NK1)', 'Noise - House of Worship - Loud Talking', 'Noise - Helicopter - News Gathering', 'Noise - House of Worship - Banging/Pounding'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_115192\\2783824653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_types\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32md:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Noise - Park - Loud Music/Party', 'Noise - Helicopter - Other', 'Noise - Commercial - Loud Talking', 'Noise - Commercial - Car/Truck Horn', 'Noise - Noise: Private Carting Noise (NQ1)', 'Noise - Noise, Other Animals (NR6)', 'Noise - Noise:  lawn care equipment (NCL)', 'Noise - House of Worship - Loud Music/Party', 'Noise - Commercial - Loud Television', 'Noise - Helicopter - NYPD', 'Collection Truck Noise - 21 Collection Truck Noise', 'Noise - Commercial - Car/Truck Music', 'Noise - Park - Loud Talking', 'Noise - Noise, Ice Cream Truck (NR4)', 'Noise - Noise: Boat(Engine,Music,Etc) (NR10)', 'Noise - Noise: Manufacturing Noise (NK1)', 'Noise - House of Worship - Loud Talking', 'Noise - Helicopter - News Gathering', 'Noise - House of Worship - Banging/Pounding'] not in index\""
     ]
    }
   ],
   "source": [
    "new_df[unique_types].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def calculate_weighted_boundaries_4_classes(df_list, unique_types):\n",
    "#     boundaries_per_dataset = []\n",
    "\n",
    "#     for df in df_list:\n",
    "#         # Step 1: Calculate total complaint count per row\n",
    "#         df['total_complaint_count'] = df[unique_types].sum(axis=1)\n",
    "        \n",
    "#         # Step 2: Calculate 4 quantile boundaries based on the total complaint count\n",
    "#         total_boundaries = {\n",
    "#             0: 0,  # No complaints\n",
    "#             1: df['total_complaint_count'].quantile(0.001),  # Low complaints\n",
    "#             2: df['total_complaint_count'].quantile(0.5),   # Moderate complaints\n",
    "#             3: df['total_complaint_count'].quantile(0.9)   # High complaints\n",
    "#         }\n",
    "\n",
    "#         # Step 3: Calculate weights for each unique_types column (e.g., based on mean or sum)\n",
    "#         column_weights = {col: df[col].mean() for col in unique_types}  # Example: use mean as weight\n",
    "\n",
    "#         # Initialize dictionary to store adjusted boundaries for each column\n",
    "#         boundaries_per_type = {}\n",
    "\n",
    "#         # Step 4: Adjust boundaries for each unique_types column based on weights\n",
    "#         for col in unique_types:\n",
    "#             # Use the total boundaries scaled by the weight of the column\n",
    "#             col_weight = column_weights[col]\n",
    "#             max_weight = max(column_weights.values())\n",
    "#             boundaries_per_type[col] = {\n",
    "#                 level: total_boundaries[level] * col_weight / max_weight\n",
    "#                 for level in total_boundaries\n",
    "#             }\n",
    "\n",
    "#             # Debug: Print weighted boundaries for each column\n",
    "#             # print(f\"Weighted boundaries for {col}: {boundaries_per_type[col]}\")\n",
    "\n",
    "#         # Append boundaries for the current dataset to the list\n",
    "#         boundaries_per_dataset.append(boundaries_per_type)\n",
    "    \n",
    "#     return boundaries_per_dataset\n",
    "\n",
    "# # Function to categorize values in unique_types columns based on weighted boundaries\n",
    "# def apply_weighted_boundaries_4_classes(df, unique_types, boundaries):\n",
    "#     def categorize(value, col_boundaries):\n",
    "#         # Assign category based on adjusted boundaries for 4 classes\n",
    "#         for category in range(3):\n",
    "#             if col_boundaries[category] <= value < col_boundaries[category + 1]:\n",
    "#                 return category\n",
    "#         return 3  # Assign the highest category if the value is above the last boundary\n",
    "\n",
    "#     for col in unique_types:\n",
    "#         col_boundaries = boundaries[col]  # Get specific boundaries for the current column\n",
    "#         df[col] = df[col].apply(lambda x: categorize(x, col_boundaries))\n",
    "\n",
    "# # Example usage\n",
    "# boundaries_per_dataset = calculate_weighted_boundaries_4_classes(df_new, unique_types)  # Calculate weighted boundaries with 4 classes\n",
    "\n",
    "# for i, df in enumerate(df_new):\n",
    "#     apply_weighted_boundaries_4_classes(df, unique_types, boundaries_per_dataset[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noise - Park - Loud Music/Party</th>\n",
       "      <th>Noise - Residential - Loud Music/Party</th>\n",
       "      <th>Noise - Street/Sidewalk - Loud Talking</th>\n",
       "      <th>Noise - Vehicle - Car/Truck Music</th>\n",
       "      <th>Noise - Helicopter - Other</th>\n",
       "      <th>Noise - Residential - Banging/Pounding</th>\n",
       "      <th>Noise - Street/Sidewalk - Loud Music/Party</th>\n",
       "      <th>Noise - Commercial - Loud Music/Party</th>\n",
       "      <th>Noise - Commercial - Loud Talking</th>\n",
       "      <th>Noise - Residential - Loud Talking</th>\n",
       "      <th>...</th>\n",
       "      <th>Noise - Helicopter - NYPD</th>\n",
       "      <th>Collection Truck Noise - 21 Collection Truck Noise</th>\n",
       "      <th>Noise - Commercial - Car/Truck Music</th>\n",
       "      <th>Noise - Park - Loud Talking</th>\n",
       "      <th>Noise - Noise, Ice Cream Truck (NR4)</th>\n",
       "      <th>Noise - Noise: Boat(Engine,Music,Etc) (NR10)</th>\n",
       "      <th>Noise - Noise: Manufacturing Noise (NK1)</th>\n",
       "      <th>Noise - House of Worship - Loud Talking</th>\n",
       "      <th>Noise - Helicopter - News Gathering</th>\n",
       "      <th>Noise - House of Worship - Banging/Pounding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.00000</td>\n",
       "      <td>2719.000000</td>\n",
       "      <td>2719.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.630379</td>\n",
       "      <td>1.203751</td>\n",
       "      <td>1.013976</td>\n",
       "      <td>1.047812</td>\n",
       "      <td>0.421478</td>\n",
       "      <td>1.113645</td>\n",
       "      <td>1.141228</td>\n",
       "      <td>0.905112</td>\n",
       "      <td>0.596543</td>\n",
       "      <td>1.068408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322177</td>\n",
       "      <td>0.213314</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>0.410077</td>\n",
       "      <td>0.562339</td>\n",
       "      <td>0.219198</td>\n",
       "      <td>0.247150</td>\n",
       "      <td>0.24053</td>\n",
       "      <td>0.212578</td>\n",
       "      <td>0.156675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.767614</td>\n",
       "      <td>0.527089</td>\n",
       "      <td>0.644062</td>\n",
       "      <td>0.601624</td>\n",
       "      <td>0.622424</td>\n",
       "      <td>0.597974</td>\n",
       "      <td>0.521703</td>\n",
       "      <td>0.729772</td>\n",
       "      <td>0.785353</td>\n",
       "      <td>0.653647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780505</td>\n",
       "      <td>0.686857</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.781916</td>\n",
       "      <td>0.811793</td>\n",
       "      <td>0.664278</td>\n",
       "      <td>0.711494</td>\n",
       "      <td>0.70128</td>\n",
       "      <td>0.654730</td>\n",
       "      <td>0.594077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Noise - Park - Loud Music/Party  \\\n",
       "count                      2719.000000   \n",
       "mean                          0.630379   \n",
       "std                           0.767614   \n",
       "min                           0.000000   \n",
       "25%                           0.000000   \n",
       "50%                           0.000000   \n",
       "75%                           1.000000   \n",
       "max                           3.000000   \n",
       "\n",
       "       Noise - Residential - Loud Music/Party  \\\n",
       "count                             2719.000000   \n",
       "mean                                 1.203751   \n",
       "std                                  0.527089   \n",
       "min                                  0.000000   \n",
       "25%                                  1.000000   \n",
       "50%                                  1.000000   \n",
       "75%                                  2.000000   \n",
       "max                                  3.000000   \n",
       "\n",
       "       Noise - Street/Sidewalk - Loud Talking  \\\n",
       "count                             2719.000000   \n",
       "mean                                 1.013976   \n",
       "std                                  0.644062   \n",
       "min                                  0.000000   \n",
       "25%                                  1.000000   \n",
       "50%                                  1.000000   \n",
       "75%                                  1.000000   \n",
       "max                                  3.000000   \n",
       "\n",
       "       Noise - Vehicle - Car/Truck Music  Noise - Helicopter - Other  \\\n",
       "count                        2719.000000                 2719.000000   \n",
       "mean                            1.047812                    0.421478   \n",
       "std                             0.601624                    0.622424   \n",
       "min                             0.000000                    0.000000   \n",
       "25%                             1.000000                    0.000000   \n",
       "50%                             1.000000                    0.000000   \n",
       "75%                             1.000000                    1.000000   \n",
       "max                             3.000000                    3.000000   \n",
       "\n",
       "       Noise - Residential - Banging/Pounding  \\\n",
       "count                             2719.000000   \n",
       "mean                                 1.113645   \n",
       "std                                  0.597974   \n",
       "min                                  0.000000   \n",
       "25%                                  1.000000   \n",
       "50%                                  1.000000   \n",
       "75%                                  1.000000   \n",
       "max                                  3.000000   \n",
       "\n",
       "       Noise - Street/Sidewalk - Loud Music/Party  \\\n",
       "count                                 2719.000000   \n",
       "mean                                     1.141228   \n",
       "std                                      0.521703   \n",
       "min                                      0.000000   \n",
       "25%                                      1.000000   \n",
       "50%                                      1.000000   \n",
       "75%                                      1.000000   \n",
       "max                                      3.000000   \n",
       "\n",
       "       Noise - Commercial - Loud Music/Party  \\\n",
       "count                            2719.000000   \n",
       "mean                                0.905112   \n",
       "std                                 0.729772   \n",
       "min                                 0.000000   \n",
       "25%                                 0.000000   \n",
       "50%                                 1.000000   \n",
       "75%                                 1.000000   \n",
       "max                                 3.000000   \n",
       "\n",
       "       Noise - Commercial - Loud Talking  Noise - Residential - Loud Talking  \\\n",
       "count                        2719.000000                         2719.000000   \n",
       "mean                            0.596543                            1.068408   \n",
       "std                             0.785353                            0.653647   \n",
       "min                             0.000000                            0.000000   \n",
       "25%                             0.000000                            1.000000   \n",
       "50%                             0.000000                            1.000000   \n",
       "75%                             1.000000                            1.000000   \n",
       "max                             3.000000                            3.000000   \n",
       "\n",
       "       ...  Noise - Helicopter - NYPD  \\\n",
       "count  ...                2719.000000   \n",
       "mean   ...                   0.322177   \n",
       "std    ...                   0.780505   \n",
       "min    ...                   0.000000   \n",
       "25%    ...                   0.000000   \n",
       "50%    ...                   0.000000   \n",
       "75%    ...                   0.000000   \n",
       "max    ...                   3.000000   \n",
       "\n",
       "       Collection Truck Noise - 21 Collection Truck Noise  \\\n",
       "count                                        2719.000000    \n",
       "mean                                            0.213314    \n",
       "std                                             0.686857    \n",
       "min                                             0.000000    \n",
       "25%                                             0.000000    \n",
       "50%                                             0.000000    \n",
       "75%                                             0.000000    \n",
       "max                                             3.000000    \n",
       "\n",
       "       Noise - Commercial - Car/Truck Music  Noise - Park - Loud Talking  \\\n",
       "count                           2719.000000                  2719.000000   \n",
       "mean                               0.621552                     0.410077   \n",
       "std                                0.802768                     0.781916   \n",
       "min                                0.000000                     0.000000   \n",
       "25%                                0.000000                     0.000000   \n",
       "50%                                0.000000                     0.000000   \n",
       "75%                                1.000000                     0.000000   \n",
       "max                                3.000000                     3.000000   \n",
       "\n",
       "       Noise - Noise, Ice Cream Truck (NR4)  \\\n",
       "count                           2719.000000   \n",
       "mean                               0.562339   \n",
       "std                                0.811793   \n",
       "min                                0.000000   \n",
       "25%                                0.000000   \n",
       "50%                                0.000000   \n",
       "75%                                1.000000   \n",
       "max                                3.000000   \n",
       "\n",
       "       Noise - Noise: Boat(Engine,Music,Etc) (NR10)  \\\n",
       "count                                   2719.000000   \n",
       "mean                                       0.219198   \n",
       "std                                        0.664278   \n",
       "min                                        0.000000   \n",
       "25%                                        0.000000   \n",
       "50%                                        0.000000   \n",
       "75%                                        0.000000   \n",
       "max                                        3.000000   \n",
       "\n",
       "       Noise - Noise: Manufacturing Noise (NK1)  \\\n",
       "count                               2719.000000   \n",
       "mean                                   0.247150   \n",
       "std                                    0.711494   \n",
       "min                                    0.000000   \n",
       "25%                                    0.000000   \n",
       "50%                                    0.000000   \n",
       "75%                                    0.000000   \n",
       "max                                    3.000000   \n",
       "\n",
       "       Noise - House of Worship - Loud Talking  \\\n",
       "count                               2719.00000   \n",
       "mean                                   0.24053   \n",
       "std                                    0.70128   \n",
       "min                                    0.00000   \n",
       "25%                                    0.00000   \n",
       "50%                                    0.00000   \n",
       "75%                                    0.00000   \n",
       "max                                    3.00000   \n",
       "\n",
       "       Noise - Helicopter - News Gathering  \\\n",
       "count                          2719.000000   \n",
       "mean                              0.212578   \n",
       "std                               0.654730   \n",
       "min                               0.000000   \n",
       "25%                               0.000000   \n",
       "50%                               0.000000   \n",
       "75%                               0.000000   \n",
       "max                               3.000000   \n",
       "\n",
       "       Noise - House of Worship - Banging/Pounding  \n",
       "count                                  2719.000000  \n",
       "mean                                      0.156675  \n",
       "std                                       0.594077  \n",
       "min                                       0.000000  \n",
       "25%                                       0.000000  \n",
       "50%                                       0.000000  \n",
       "75%                                       0.000000  \n",
       "max                                       3.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[1][unique_types].describe()\n",
    "# df_new[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the 5 dataset to hex8.csv to hex12.csv\n",
    "for i in range(5):\n",
    "    df_new[i].to_csv(f'hex{i+8}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the hex8.csv to hex12.csv\n",
    "df_new = []\n",
    "for i in range(8, 13):\n",
    "    df_new.append(pd.read_csv(f'hex{i}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h3_index</th>\n",
       "      <th>density</th>\n",
       "      <th>stripclub</th>\n",
       "      <th>sports_centre</th>\n",
       "      <th>gatehouse</th>\n",
       "      <th>block</th>\n",
       "      <th>beauty_school</th>\n",
       "      <th>data_center</th>\n",
       "      <th>Noise - Noise: Construction Before/After Hours (NM1)</th>\n",
       "      <th>crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>industrial</th>\n",
       "      <th>carport</th>\n",
       "      <th>Noise - Park - Loud Talking</th>\n",
       "      <th>music</th>\n",
       "      <th>bowling</th>\n",
       "      <th>public_bookcase</th>\n",
       "      <th>dog_toilet</th>\n",
       "      <th>summer_camp</th>\n",
       "      <th>Noise - Vehicle - Car/Truck Music</th>\n",
       "      <th>total_complaint_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89f05aa4177ffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89f05aa65a3ffff</td>\n",
       "      <td>3.202530e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89f05ab4c77ffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89f05aa44cfffff</td>\n",
       "      <td>1.339004e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89f05ab4b0bffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>89f05869467ffff</td>\n",
       "      <td>9.094340e+01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>89f058453bbffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>89f05aa4c07ffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>89f05aa42c7ffff</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>89f05ab6ea3ffff</td>\n",
       "      <td>6.588970e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2719 rows × 493 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             h3_index       density  stripclub  sports_centre  gatehouse  \\\n",
       "0     89f05aa4177ffff  0.000000e+00          0              0          0   \n",
       "1     89f05aa65a3ffff  3.202530e+07          0              0          0   \n",
       "2     89f05ab4c77ffff  0.000000e+00          0              0          0   \n",
       "3     89f05aa44cfffff  1.339004e+07          0              0          0   \n",
       "4     89f05ab4b0bffff  0.000000e+00          0              0          0   \n",
       "...               ...           ...        ...            ...        ...   \n",
       "2714  89f05869467ffff  9.094340e+01          0              0          0   \n",
       "2715  89f058453bbffff  0.000000e+00          0              0          0   \n",
       "2716  89f05aa4c07ffff  0.000000e+00          0              0          0   \n",
       "2717  89f05aa42c7ffff  0.000000e+00          0              0          0   \n",
       "2718  89f05ab6ea3ffff  6.588970e+04          0              0          0   \n",
       "\n",
       "      block  beauty_school  data_center  \\\n",
       "0         0              0            0   \n",
       "1         0              0            0   \n",
       "2         0              0            0   \n",
       "3         0              0            0   \n",
       "4         0              0            0   \n",
       "...     ...            ...          ...   \n",
       "2714      2              0            0   \n",
       "2715      0              0            0   \n",
       "2716      0              0            0   \n",
       "2717      0              0            0   \n",
       "2718      0              0            0   \n",
       "\n",
       "      Noise - Noise: Construction Before/After Hours (NM1)  crossing  ...  \\\n",
       "0                                                     1           20  ...   \n",
       "1                                                     1           88  ...   \n",
       "2                                                     2           98  ...   \n",
       "3                                                     1           16  ...   \n",
       "4                                                     1           74  ...   \n",
       "...                                                 ...          ...  ...   \n",
       "2714                                                  0            2  ...   \n",
       "2715                                                  0            1  ...   \n",
       "2716                                                  0            4  ...   \n",
       "2717                                                  0            4  ...   \n",
       "2718                                                  0            0  ...   \n",
       "\n",
       "      industrial  carport  Noise - Park - Loud Talking  music  bowling  \\\n",
       "0              0        0                            1      0        0   \n",
       "1              0        0                            0      0        0   \n",
       "2              0        0                            1      0        0   \n",
       "3              0        0                            0      0        0   \n",
       "4              1        0                            2      0        0   \n",
       "...          ...      ...                          ...    ...      ...   \n",
       "2714           0        0                            0      0        0   \n",
       "2715           3        0                            0      0        0   \n",
       "2716           0        0                            0      0        0   \n",
       "2717           0        0                            0      0        0   \n",
       "2718           0        0                            0      0        0   \n",
       "\n",
       "      public_bookcase  dog_toilet  summer_camp  \\\n",
       "0                   0           0            0   \n",
       "1                   0           0            0   \n",
       "2                   0           0            0   \n",
       "3                   0           0            0   \n",
       "4                   0           0            0   \n",
       "...               ...         ...          ...   \n",
       "2714                0           0            0   \n",
       "2715                0           0            0   \n",
       "2716                0           0            0   \n",
       "2717                0           0            0   \n",
       "2718                0           0            0   \n",
       "\n",
       "      Noise - Vehicle - Car/Truck Music  total_complaint_count  \n",
       "0                                     1                  247.0  \n",
       "1                                     2                 2042.0  \n",
       "2                                     2                 4983.0  \n",
       "3                                     1                 1658.0  \n",
       "4                                     1                 1717.0  \n",
       "...                                 ...                    ...  \n",
       "2714                                  0                    1.0  \n",
       "2715                                  0                    1.0  \n",
       "2716                                  0                    3.0  \n",
       "2717                                  0                    1.0  \n",
       "2718                                  0                    1.0  \n",
       "\n",
       "[2719 rows x 493 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df_new[1]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent Number: 0, Percentage: 52.07%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the frequency of each number (0, 1, 2, 3) across all unique_types columns\n",
    "number_counts = {num: (new_df[unique_types] == num).sum().sum() for num in range(4)}\n",
    "\n",
    "# Find the number with the highest frequency\n",
    "most_frequent_number = max(number_counts, key=number_counts.get)\n",
    "total_frequency = number_counts[most_frequent_number]\n",
    "\n",
    "# Calculate the total count of all numbers in unique_types columns\n",
    "total_count = len(new_df) * len(unique_types)\n",
    "\n",
    "# Calculate the overall percentage\n",
    "overall_percentage = (total_frequency / total_count) * 100\n",
    "\n",
    "# Print the most frequent number and its percentage\n",
    "print(f\"Most Frequent Number: {most_frequent_number}, Percentage: {overall_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a model (try on hex11)\n",
    "\n",
    "features that need to be predict are in 'unique_types' columns in dataframe\n",
    "\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features and target\n",
    "X = new_df.drop(columns=[\"h3_index\"] + unique_types)  # Features (excluding 'h3_index' and target columns)\n",
    "y = new_df[unique_types]  # Multi-column target variables (each column is a 4-class target)\n",
    "\n",
    "# Train-test split (we'll further split train into train/val)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=46)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=46)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize base XGBoost classifier\n",
    "base_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',  # Treat each class as a separate binary problem\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Wrap the base model in OneVsRestClassifier inside MultiOutputClassifier\n",
    "model = MultiOutputClassifier(OneVsRestClassifier(base_model, n_jobs=1), n_jobs=-1)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_rounds = 10\n",
    "best_val_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n",
    "# Lists to store overall training and validation loss and accuracy\n",
    "overall_train_losses = []\n",
    "overall_train_accuracies = []\n",
    "overall_val_losses = []\n",
    "overall_val_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 2: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 3: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 4: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 5: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 6: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 7: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 8: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 9: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 10: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Epoch 11: Train Accuracy: 0.9351, Train Loss: 0.2141, Val Accuracy: 0.8205, Val Loss: 0.4752\n",
      "Early stopping on epoch 11\n"
     ]
    }
   ],
   "source": [
    "# Training with early stopping\n",
    "for epoch in range(1, 101):  # Max 100 epochs\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Training set predictions and metrics\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train.values.flatten(), y_train_pred.flatten())\n",
    "    overall_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    train_loss = 0\n",
    "    for i, estimator in enumerate(model.estimators_):\n",
    "        train_loss += log_loss(y_train.iloc[:, i], estimator.predict_proba(X_train))\n",
    "    overall_train_losses.append(train_loss / len(model.estimators_))\n",
    "\n",
    "    # Validation set predictions and metrics\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val.values.flatten(), y_val_pred.flatten())\n",
    "    overall_val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    val_loss = 0\n",
    "    for i, estimator in enumerate(model.estimators_):\n",
    "        val_loss += log_loss(y_val.iloc[:, i], estimator.predict_proba(X_val))\n",
    "    val_loss /= len(model.estimators_)\n",
    "    overall_val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Accuracy: {train_accuracy:.4f}, Train Loss: {overall_train_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_rounds = 0  # Reset counter if we see improvement\n",
    "    else:\n",
    "        no_improve_rounds += 1\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(f\"Early stopping on epoch {epoch}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy across all target columns: 0.8180\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set evaluation after early stopping\n",
    "y_test_pred = model.predict(X_test)\n",
    "overall_test_accuracy = accuracy_score(y_test.values.flatten(), y_test_pred.flatten())\n",
    "print(f\"\\nOverall Test Accuracy across all target columns: {overall_test_accuracy:.4f}\")\n",
    "\n",
    "# Plot loss curve and accuracy curve for train and validation sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(overall_train_losses, label=\"Train Loss\")\n",
    "plt.plot(overall_val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss Curve\")\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(overall_train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(overall_val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall RMSE across all target variables: 72.21\n",
      "Overall MAPE across all target variables: 207.23%\n",
      "Overall SMAPE across all target variables: 170.77%\n"
     ]
    }
   ],
   "source": [
    "overall_mse = []\n",
    "overall_mape = []\n",
    "overall_smape = []\n",
    "\n",
    "for target in unique_types:\n",
    "    # Generate predictions\n",
    "    y_test_target = y_test[target]\n",
    "    y_pred = models[target].predict(xgb.DMatrix(X_test))\n",
    "    \n",
    "    # Mean Squared Error for RMSE\n",
    "    mse = mean_squared_error(y_test_target, y_pred)\n",
    "    overall_mse.append(mse)\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE), ignoring zero actual values\n",
    "    nonzero_indices = y_test_target != 0  # Exclude zero values to avoid division by zero\n",
    "    mape = np.mean(np.abs((y_test_target[nonzero_indices] - y_pred[nonzero_indices]) / y_test_target[nonzero_indices])) * 100\n",
    "    overall_mape.append(mape)\n",
    "    \n",
    "    # Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    smape = np.mean(2 * np.abs(y_test_target - y_pred) / (np.abs(y_test_target) + np.abs(y_pred))) * 100\n",
    "    overall_smape.append(smape)\n",
    "\n",
    "# Calculate overall metrics\n",
    "overall_rmse = np.sqrt(np.mean(overall_mse))\n",
    "overall_mape = np.mean(overall_mape)\n",
    "overall_smape = np.mean(overall_smape)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nOverall RMSE across all target variables: {overall_rmse:.2f}\")\n",
    "print(f\"Overall MAPE across all target variables: {overall_mape:.2f}%\")\n",
    "print(f\"Overall SMAPE across all target variables: {overall_smape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics:\n",
    "\n",
    "- **Overall RMSE of 72.21**: The model’s predictions, on average, are about 72 units off from the actual counts. This can be interpreted as a moderately high error, especially if the counts are typically low (for instance, if most actual counts are below 100). RMSE being high relative to the range of actual counts often indicates that the model struggles with accurate predictions.\n",
    "\n",
    "- **Overall MAPE of 207.23%**: This very high MAPE indicates that, on average, the model’s predictions deviate by over 200% from the actual values. MAPE is useful for interpreting error relative to actual counts, so an average deviation of over 200% signals a large discrepancy. It suggests the model is significantly under- or over-estimating counts, especially for lower count values.\n",
    "\n",
    "- **Overall SMAPE of 170.77%**: SMAPE, while somewhat more robust to zero values, is still very high, confirming that there’s considerable error even when accounting for both actual and predicted values. This means that both over-predictions and under-predictions are widespread and substantial.\n",
    "\n",
    "### Conclusions and Next Steps:\n",
    "\n",
    "1. **Model Underperformance**: The high MAPE and SMAPE indicate that the model is not accurately capturing the distribution of counts, likely making large errors relative to the actual values.\n",
    "  \n",
    "2. **Explore Data Patterns and Features**: Check if certain features are poorly correlated with the target or if additional relevant features are missing. You could examine feature importance or correlation to assess which features might not be contributing effectively.\n",
    "\n",
    "3. **Try Different Models or Tuning**: XGBoost may not be ideal for all count prediction tasks, especially if the data has a high variance in counts. Testing other models (like linear regression, Poisson regression for count data, or even simpler tree-based models) could reveal better fits, particularly if the counts have certain patterns or if the data is sparse.\n",
    "\n",
    "4. **Consider Log Transformation**: If the counts vary widely, applying a log transformation to the target variable might help the model learn better relationships, reducing the scale of large errors. You could then back-transform predictions to the original scale.\n",
    "\n",
    "5. **Segmented Modeling**: If certain categories of `unique_types` have vastly different distributions, building separate models for each segment (rather than one model per type) could improve accuracy for each segment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders for Feature Extraction + Neural Network Regression\n",
    "\n",
    "Framework Overview\n",
    "\n",
    "1. Autoencoder for Dimensionality Reduction: The autoencoder learns a compressed representation of the features.\n",
    "2. Neural Network Regression Model: The compressed features are then fed into a regression network to predict counts for each type in unique_types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features and target\n",
    "X = new_df.drop(columns=[\"h3_index\"] + unique_types)  # Features (excluding 'h3_index' and target columns)\n",
    "y = new_df[unique_types]  # Multi-column target variables (each column is a 4-class target)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=46)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=46)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "# Define Autoencoder Architecture with Fewer Neurons and Smaller Learning Rate\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define dimensions\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "latent_dim = 16  # Dimension of compressed space (reduced from 32 to 16)\n",
    "\n",
    "# Initialize autoencoder and optimizer with a smaller learning rate\n",
    "autoencoder = Autoencoder(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "criterion_ae = nn.MSELoss()\n",
    "optimizer_ae = optim.Adam(autoencoder.parameters(), lr=0.0005)  # Reduced learning rate\n",
    "\n",
    "# Train Autoencoder with early stopping\n",
    "epochs_ae = 1000\n",
    "early_stopping_rounds = 2\n",
    "tolerance = 1e-4\n",
    "train_losses_ae, val_losses_ae = [], []\n",
    "best_train_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Autoencoder:  11%|█         | 109/1000 [01:12<09:51,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping for Autoencoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs_ae), desc=\"Training Autoencoder\"):\n",
    "    autoencoder.train()\n",
    "    epoch_train_loss = 0\n",
    "    for X_batch, _ in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        \n",
    "        _, decoded = autoencoder(X_batch)\n",
    "        loss = criterion_ae(decoded, X_batch)  # Reconstruction loss\n",
    "\n",
    "        optimizer_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(autoencoder.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer_ae.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses_ae.append(avg_train_loss)\n",
    "\n",
    "    # Early stopping based on tolerance\n",
    "    if abs(avg_train_loss - best_train_loss) < tolerance:\n",
    "        no_improve_rounds += 1\n",
    "    else:\n",
    "        no_improve_rounds = 0\n",
    "    best_train_loss = min(best_train_loss, avg_train_loss)\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(\"Early stopping for Autoencoder.\")\n",
    "        break\n",
    "\n",
    "    # Validation loss (optional, only for monitoring)\n",
    "    autoencoder.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            _, decoded = autoencoder(X_batch)\n",
    "            val_loss += criterion_ae(decoded, X_batch).item()\n",
    "    val_losses_ae.append(val_loss / len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compressed features using trained autoencoder\n",
    "autoencoder.eval()\n",
    "X_train_compressed = autoencoder.encoder(X_train_tensor.to(device)).detach()\n",
    "X_val_compressed = autoencoder.encoder(X_val_tensor.to(device)).detach()\n",
    "X_test_compressed = autoencoder.encoder(X_test_tensor.to(device)).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Regression Model:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Regression Model:   6%|▌         | 56/1000 [00:19<05:35,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping for Regression Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Regression Model using compressed features\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.regressor(x)\n",
    "\n",
    "output_dim = y_train.shape[1] * 4  # Number of targets as one-hot for each column\n",
    "regression_model = RegressionModel(latent_dim=latent_dim, output_dim=output_dim).to(device)\n",
    "criterion_reg = nn.CrossEntropyLoss()\n",
    "optimizer_reg = optim.Adam(regression_model.parameters(), lr=0.0005)  # Smaller learning rate\n",
    "\n",
    "# Training the Regression Model with early stopping\n",
    "epochs_reg = 1000\n",
    "train_losses_reg, val_losses_reg = [], []\n",
    "best_train_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs_reg), desc=\"Training Regression Model\"):\n",
    "    regression_model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        encoded_batch = autoencoder.encoder(X_batch)\n",
    "        outputs = regression_model(encoded_batch)\n",
    "        loss = criterion_reg(outputs.view(-1, 4), y_batch.view(-1))  # CrossEntropy loss\n",
    "\n",
    "        optimizer_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(regression_model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer_reg.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses_reg.append(avg_train_loss)\n",
    "\n",
    "    # Early stopping based on tolerance\n",
    "    if abs(avg_train_loss - best_train_loss) < tolerance:\n",
    "        no_improve_rounds += 1\n",
    "    else:\n",
    "        no_improve_rounds = 0\n",
    "    best_train_loss = min(best_train_loss, avg_train_loss)\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(\"Early stopping for Regression Model.\")\n",
    "        break\n",
    "\n",
    "    # Validation loss (optional, only for monitoring)\n",
    "    regression_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            encoded_batch = autoencoder.encoder(X_batch)\n",
    "            outputs = regression_model(encoded_batch)\n",
    "            val_loss += criterion_reg(outputs.view(-1, 4), y_batch.view(-1)).item()\n",
    "    val_losses_reg.append(val_loss / len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy across all target columns: 0.7955\n"
     ]
    }
   ],
   "source": [
    "# predict the test data\n",
    "regression_model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_test = autoencoder.encoder(X_test_tensor.to(device))\n",
    "    outputs_test = regression_model(encoded_test)\n",
    "    y_pred = outputs_test.view(-1, 4).argmax(dim=1).cpu().numpy()\n",
    "    \n",
    "# Calculate overall accuracy\n",
    "y_true = y_test.values.flatten()\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Test Accuracy across all target columns: {overall_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Loss Curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Autoencoder Loss Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_ae, label=\"Autoencoder Train Loss\")\n",
    "plt.plot(val_losses_ae, label=\"Autoencoder Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Autoencoder Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Regression Model Loss Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses_reg, label=\"Regression Train Loss\")\n",
    "plt.plot(val_losses_reg, label=\"Regression Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Regression Model Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improvement**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Autoencoder: 100%|██████████| 1000/1000 [06:39<00:00,  2.50it/s]\n",
      "Training Regression Model:   8%|▊         | 83/1000 [00:30<05:35,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping for Regression Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features and target\n",
    "X = new_df.drop(columns=[\"h3_index\"] + unique_types)  # Features (excluding 'h3_index' and target columns)\n",
    "y = new_df[unique_types]  # Multi-column target variables (each column is a 4-class target)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=46)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=46)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Optimized Autoencoder Architecture with Dropout and Lower Learning Rate\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder with dropout\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define dimensions\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "latent_dim = 16  # Dimension of compressed space\n",
    "\n",
    "# Initialize autoencoder and optimizer with a smaller learning rate\n",
    "autoencoder = Autoencoder(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "criterion_ae = nn.MSELoss()\n",
    "optimizer_ae = optim.Adam(autoencoder.parameters(), lr=0.0001)  # Further reduced learning rate\n",
    "\n",
    "# Train Autoencoder with early stopping\n",
    "epochs_ae = 1000\n",
    "early_stopping_rounds = 3\n",
    "tolerance = 1e-4\n",
    "train_losses_ae, val_losses_ae = [], []\n",
    "train_accuracies_ae, val_accuracies_ae = [], []  # Record accuracies\n",
    "best_train_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs_ae), desc=\"Training Autoencoder\"):\n",
    "    autoencoder.train()\n",
    "    epoch_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for X_batch, _ in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        \n",
    "        _, decoded = autoencoder(X_batch)\n",
    "        loss = criterion_ae(decoded, X_batch)  # Reconstruction loss\n",
    "\n",
    "        optimizer_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(autoencoder.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer_ae.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses_ae.append(avg_train_loss)\n",
    "\n",
    "    # Early stopping based on tolerance\n",
    "    if abs(avg_train_loss - best_train_loss) < tolerance:\n",
    "        no_improve_rounds += 1\n",
    "    else:\n",
    "        no_improve_rounds = 0\n",
    "    best_train_loss = min(best_train_loss, avg_train_loss)\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(\"Early stopping for Autoencoder.\")\n",
    "        break\n",
    "\n",
    "    # Validation loss (optional, only for monitoring)\n",
    "    autoencoder.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, _ in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            _, decoded = autoencoder(X_batch)\n",
    "            val_loss += criterion_ae(decoded, X_batch).item()\n",
    "    val_losses_ae.append(val_loss / len(val_loader))\n",
    "\n",
    "# Extract compressed features using trained autoencoder\n",
    "autoencoder.eval()\n",
    "X_train_compressed = autoencoder.encoder(X_train_tensor.to(device)).detach()\n",
    "X_val_compressed = autoencoder.encoder(X_val_tensor.to(device)).detach()\n",
    "X_test_compressed = autoencoder.encoder(X_test_tensor.to(device)).detach()\n",
    "\n",
    "# Define Regression Model using compressed features\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.regressor(x)\n",
    "\n",
    "output_dim = y_train.shape[1] * 4  # Number of targets as one-hot for each column\n",
    "regression_model = RegressionModel(latent_dim=latent_dim, output_dim=output_dim).to(device)\n",
    "criterion_reg = nn.CrossEntropyLoss()\n",
    "optimizer_reg = optim.Adam(regression_model.parameters(), lr=0.0005)  # Smaller learning rate\n",
    "\n",
    "# Training the Regression Model with early stopping and accuracy recording\n",
    "epochs_reg = 1000\n",
    "train_losses_reg, val_losses_reg = [], []\n",
    "train_accuracies_reg, val_accuracies_reg = [], []\n",
    "best_train_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs_reg), desc=\"Training Regression Model\"):\n",
    "    regression_model.train()\n",
    "    epoch_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        encoded_batch = autoencoder.encoder(X_batch)\n",
    "        outputs = regression_model(encoded_batch)\n",
    "        loss = criterion_reg(outputs.view(-1, 4), y_batch.view(-1))  # CrossEntropy loss\n",
    "\n",
    "        optimizer_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(regression_model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer_reg.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = outputs.view(-1, 4).max(1)\n",
    "        correct_train += (predicted == y_batch.view(-1)).sum().item()\n",
    "        total_train += y_batch.view(-1).size(0)\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses_reg.append(avg_train_loss)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_accuracies_reg.append(train_accuracy)\n",
    "\n",
    "    # Early stopping based on tolerance\n",
    "    if abs(avg_train_loss - best_train_loss) < tolerance:\n",
    "        no_improve_rounds += 1\n",
    "    else:\n",
    "        no_improve_rounds = 0\n",
    "    best_train_loss = min(best_train_loss, avg_train_loss)\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(\"Early stopping for Regression Model.\")\n",
    "        break\n",
    "\n",
    "    # Validation loss and accuracy\n",
    "    regression_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            encoded_batch = autoencoder.encoder(X_batch)\n",
    "            outputs = regression_model(encoded_batch)\n",
    "            val_loss += criterion_reg(outputs.view(-1, 4), y_batch.view(-1)).item()\n",
    "\n",
    "            _, predicted = outputs.view(-1, 4).max(1)\n",
    "            correct_val += (predicted == y_batch.view(-1)).sum().item()\n",
    "            total_val += y_batch.view(-1).size(0)\n",
    "\n",
    "    val_losses_reg.append(val_loss / len(val_loader))\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_accuracies_reg.append(val_accuracy)\n",
    "\n",
    "# Plot Loss and Accuracy Curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Autoencoder Loss Curve\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_losses_ae, label=\"Autoencoder Train Loss\")\n",
    "plt.plot(val_losses_ae, label=\"Autoencoder Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Autoencoder Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Regression Model Loss Curve\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_losses_reg, label=\"Regression Train Loss\")\n",
    "plt.plot(val_losses_reg, label=\"Regression Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Regression Model Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Regression Model Accuracy Curve\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_accuracies_reg, label=\"Regression Train Accuracy\")\n",
    "plt.plot(val_accuracies_reg, label=\"Regression Val Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Regression Model Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy across all target columns: 0.7987\n"
     ]
    }
   ],
   "source": [
    "# print the test accuracy\n",
    "regression_model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_test = autoencoder.encoder(X_test_tensor.to(device))\n",
    "    outputs_test = regression_model(encoded_test)\n",
    "    y_pred = outputs_test.view(-1, 4).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# Calculate overall accuracy\n",
    "y_true = y_test.values.flatten()\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Test Accuracy across all target columns: {overall_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the latest results with the previous metrics:\n",
    "\n",
    "1. **Overall RMSE**: \n",
    "   - **Previous**: 72.21\n",
    "   - **Current**: 67.33\n",
    "   - **Analysis**: The reduction in RMSE indicates that the model’s predictions are closer to the actual values, with the average deviation decreasing by about 5 units. This suggests that using the autoencoder’s compressed features may have helped capture the underlying patterns in the data better, leading to improved overall accuracy.\n",
    "\n",
    "2. **Overall MAPE**:\n",
    "   - **Previous**: 207.23%\n",
    "   - **Current**: 143.18%\n",
    "   - **Analysis**: The MAPE has decreased significantly, from over 200% to around 143%. This metric provides a percentage-based error relative to actual values, so this reduction indicates that the model’s predictions are now less drastically off when compared to the actual counts, especially for lower count values. The autoencoder’s feature extraction seems to help the regression model make more stable predictions, reducing large errors relative to the actual counts.\n",
    "\n",
    "3. **Overall SMAPE**:\n",
    "   - **Previous**: 170.77%\n",
    "   - **Current**: 181.21%\n",
    "   - **Analysis**: The SMAPE has slightly increased, indicating that while the model improved overall accuracy (RMSE) and reduced large relative errors (MAPE), there may still be some large differences for certain categories. Since SMAPE is less sensitive to zeros but considers both actual and predicted values, this could indicate that the model still struggles to predict certain categories accurately, especially those with high counts or more variability.\n",
    "\n",
    "### Summary and Insights\n",
    "\n",
    "- **Improved Predictive Accuracy**: The reduction in RMSE and MAPE suggests that the autoencoder-based feature extraction helped reduce the overall prediction error, making the model more robust.\n",
    "- **Remaining Challenges**: The slight increase in SMAPE might suggest specific categories or values where the model still struggles. Examining outliers or categories with large residuals could provide insight into why the model has difficulty accurately predicting these cases.\n",
    "\n",
    "Overall, the model shows better generalization and reduced error on average, but further tuning or segment-specific modeling may help address variability in certain categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features and target\n",
    "X = new_df.drop(columns=[\"h3_index\"] + unique_types)  # Features (excluding 'h3_index' and target columns)\n",
    "y = new_df[unique_types]  # Multi-column target variables (each column is a 4-class target)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=46)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=46)\n",
    "\n",
    "# Convert targets to numpy arrays for TabNet\n",
    "y_train_np = y_train.values\n",
    "y_val_np = y_val.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.28769 | val_0_rmse: 1.09195 | val_1_rmse: 0.97424 |  0:00:01s\n",
      "epoch 1  | loss: 1.48101 | val_0_rmse: 1.03514 | val_1_rmse: 1.06168 |  0:00:02s\n",
      "epoch 2  | loss: 1.01471 | val_0_rmse: 1.30112 | val_1_rmse: 1.0706  |  0:00:02s\n",
      "epoch 3  | loss: 0.78324 | val_0_rmse: 1.02843 | val_1_rmse: 0.90406 |  0:00:03s\n",
      "epoch 4  | loss: 0.66718 | val_0_rmse: 1.03338 | val_1_rmse: 0.83366 |  0:00:04s\n",
      "epoch 5  | loss: 0.61334 | val_0_rmse: 0.81636 | val_1_rmse: 0.80956 |  0:00:05s\n",
      "epoch 6  | loss: 0.57919 | val_0_rmse: 0.78463 | val_1_rmse: 0.75173 |  0:00:06s\n",
      "epoch 7  | loss: 0.53532 | val_0_rmse: 0.71622 | val_1_rmse: 0.68501 |  0:00:07s\n",
      "epoch 8  | loss: 0.49485 | val_0_rmse: 0.73016 | val_1_rmse: 0.89082 |  0:00:08s\n",
      "epoch 9  | loss: 0.48947 | val_0_rmse: 0.72229 | val_1_rmse: 0.72334 |  0:00:09s\n",
      "epoch 10 | loss: 0.48062 | val_0_rmse: 0.70732 | val_1_rmse: 0.67294 |  0:00:09s\n",
      "epoch 11 | loss: 0.46174 | val_0_rmse: 0.70295 | val_1_rmse: 0.76583 |  0:00:10s\n",
      "epoch 12 | loss: 0.46067 | val_0_rmse: 0.73337 | val_1_rmse: 0.80538 |  0:00:11s\n",
      "epoch 13 | loss: 0.45671 | val_0_rmse: 0.76758 | val_1_rmse: 0.79384 |  0:00:12s\n",
      "epoch 14 | loss: 0.4517  | val_0_rmse: 0.71994 | val_1_rmse: 0.70966 |  0:00:13s\n",
      "epoch 15 | loss: 0.44731 | val_0_rmse: 0.73893 | val_1_rmse: 0.88344 |  0:00:14s\n",
      "epoch 16 | loss: 0.44847 | val_0_rmse: 0.74074 | val_1_rmse: 0.91096 |  0:00:15s\n",
      "epoch 17 | loss: 0.44664 | val_0_rmse: 0.75384 | val_1_rmse: 0.68534 |  0:00:15s\n",
      "epoch 18 | loss: 0.44771 | val_0_rmse: 0.79485 | val_1_rmse: 0.67958 |  0:00:16s\n",
      "epoch 19 | loss: 0.44708 | val_0_rmse: 0.75876 | val_1_rmse: 0.68203 |  0:00:17s\n",
      "epoch 20 | loss: 0.44811 | val_0_rmse: 0.75632 | val_1_rmse: 0.72    |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_1_rmse = 0.67294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Define TabNet model\n",
    "tabnet_params = {\n",
    "    \"n_d\": 16,  # Dimension of decision prediction layer\n",
    "    \"n_a\": 16,  # Dimension of attention embedding\n",
    "    \"n_steps\": 5,\n",
    "    \"gamma\": 1.5,\n",
    "    \"n_independent\": 2,\n",
    "    \"n_shared\": 2,\n",
    "    \"momentum\": 0.02,\n",
    "    \"lambda_sparse\": 0.0001,\n",
    "    \"optimizer_fn\": optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=0.02),\n",
    "    \"mask_type\": \"entmax\"  # Use sparsemax or entmax\n",
    "}\n",
    "\n",
    "# Initialize TabNet model\n",
    "tabnet_model = TabNetRegressor(**tabnet_params)\n",
    "\n",
    "# Train TabNet model\n",
    "epochs_tabnet = 1000\n",
    "early_stopping_rounds = 10\n",
    "tabnet_model.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_np,\n",
    "    eval_set=[(X_train, y_train_np), (X_val, y_val_np)],\n",
    "    max_epochs=epochs_tabnet,\n",
    "    patience=early_stopping_rounds,\n",
    "    eval_metric=['rmse'],\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from TabNet\n",
    "X_train_compressed = tabnet_model.predict(X_train)\n",
    "X_val_compressed = tabnet_model.predict(X_val)\n",
    "X_test_compressed = tabnet_model.predict(X_test)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train_compressed, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_compressed, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_compressed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Regression Model:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Regression Model:  18%|█▊        | 179/1000 [00:44<03:24,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping for Regression Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义回归模型\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.regressor(x)\n",
    "\n",
    "# 使用 TabNet 提取的特征维度\n",
    "input_dim = X_train_compressed.shape[1]\n",
    "output_dim = y_train.shape[1] * 4  # Number of targets as one-hot for each column\n",
    "\n",
    "# 初始化模型\n",
    "regression_model = RegressionModel(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "criterion_reg = nn.CrossEntropyLoss()\n",
    "optimizer_reg = optim.Adam(regression_model.parameters(), lr=0.0005)\n",
    "\n",
    "# 训练神经网络回归模型，包含 early stopping 和准确率记录\n",
    "epochs_reg = 1000\n",
    "train_losses_reg, val_losses_reg = [], []\n",
    "train_accuracies_reg, val_accuracies_reg = [], []\n",
    "best_val_loss = float(\"inf\")\n",
    "no_improve_rounds = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs_reg), desc=\"Training Regression Model\"):\n",
    "    regression_model.train()\n",
    "    epoch_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        outputs = regression_model(X_batch)\n",
    "        loss = criterion_reg(outputs.view(-1, 4), y_batch.view(-1))  # CrossEntropy loss\n",
    "\n",
    "        optimizer_reg.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_reg.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = outputs.view(-1, 4).max(1)\n",
    "        correct_train += (predicted == y_batch.view(-1)).sum().item()\n",
    "        total_train += y_batch.view(-1).size(0)\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses_reg.append(avg_train_loss)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_accuracies_reg.append(train_accuracy)\n",
    "\n",
    "    # Validation loss and accuracy\n",
    "    regression_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = regression_model(X_batch)\n",
    "            val_loss += criterion_reg(outputs.view(-1, 4), y_batch.view(-1)).item()\n",
    "\n",
    "            _, predicted = outputs.view(-1, 4).max(1)\n",
    "            correct_val += (predicted == y_batch.view(-1)).sum().item()\n",
    "            total_val += y_batch.view(-1).size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses_reg.append(avg_val_loss)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_accuracies_reg.append(val_accuracy)\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improve_rounds = 0\n",
    "    else:\n",
    "        no_improve_rounds += 1\n",
    "\n",
    "    if no_improve_rounds >= early_stopping_rounds:\n",
    "        print(\"Early stopping for Regression Model.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss and Accuracy Curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Regression Model Loss Curve\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_losses_reg, label=\"Regression Train Loss\")\n",
    "plt.plot(val_losses_reg, label=\"Regression Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Regression Model Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Regression Model Accuracy Curve\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_accuracies_reg, label=\"Regression Train Accuracy\")\n",
    "plt.plot(val_accuracies_reg, label=\"Regression Val Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Regression Model Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy across all target columns: 0.8119\n"
     ]
    }
   ],
   "source": [
    "# print the test accuracy\n",
    "regression_model.eval()\n",
    "with torch.no_grad():\n",
    "    encoded_test = tabnet_model.predict(X_test)\n",
    "    outputs_test = regression_model(torch.tensor(encoded_test, dtype=torch.float32).to(device))\n",
    "    y_pred = outputs_test.view(-1, 4).argmax(dim=1).cpu().numpy()\n",
    "    \n",
    "# Calculate overall accuracy\n",
    "y_true = y_test.values.flatten()\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Test Accuracy across all target columns: {overall_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.72243 | val_0_rmse: 0.99062 | val_1_rmse: 0.93827 |  0:00:00s\n",
      "epoch 1  | loss: 1.58595 | val_0_rmse: 1.09538 | val_1_rmse: 0.94119 |  0:00:01s\n",
      "epoch 2  | loss: 1.16049 | val_0_rmse: 1.22073 | val_1_rmse: 0.97042 |  0:00:02s\n",
      "epoch 3  | loss: 0.98096 | val_0_rmse: 1.48273 | val_1_rmse: 0.92334 |  0:00:02s\n",
      "epoch 4  | loss: 0.87489 | val_0_rmse: 1.10174 | val_1_rmse: 0.87927 |  0:00:03s\n",
      "epoch 5  | loss: 0.77497 | val_0_rmse: 0.87871 | val_1_rmse: 0.81521 |  0:00:03s\n",
      "epoch 6  | loss: 0.66079 | val_0_rmse: 1.25747 | val_1_rmse: 2.05761 |  0:00:04s\n",
      "epoch 7  | loss: 0.58978 | val_0_rmse: 0.95394 | val_1_rmse: 1.40268 |  0:00:05s\n",
      "epoch 8  | loss: 0.53987 | val_0_rmse: 0.83091 | val_1_rmse: 1.44153 |  0:00:05s\n",
      "epoch 9  | loss: 0.50251 | val_0_rmse: 0.90802 | val_1_rmse: 1.33813 |  0:00:06s\n",
      "epoch 10 | loss: 0.48973 | val_0_rmse: 0.87355 | val_1_rmse: 1.18476 |  0:00:07s\n",
      "epoch 11 | loss: 0.48371 | val_0_rmse: 1.32711 | val_1_rmse: 2.35095 |  0:00:07s\n",
      "epoch 12 | loss: 0.47566 | val_0_rmse: 1.33538 | val_1_rmse: 2.38672 |  0:00:08s\n",
      "epoch 13 | loss: 0.47134 | val_0_rmse: 0.68561 | val_1_rmse: 0.67852 |  0:00:09s\n",
      "epoch 14 | loss: 0.46629 | val_0_rmse: 0.69897 | val_1_rmse: 0.67413 |  0:00:09s\n",
      "epoch 15 | loss: 0.46487 | val_0_rmse: 0.69411 | val_1_rmse: 0.67291 |  0:00:10s\n",
      "epoch 16 | loss: 0.46246 | val_0_rmse: 0.72137 | val_1_rmse: 0.69684 |  0:00:11s\n",
      "epoch 17 | loss: 0.45924 | val_0_rmse: 0.70243 | val_1_rmse: 0.73792 |  0:00:11s\n",
      "epoch 18 | loss: 0.45602 | val_0_rmse: 0.70639 | val_1_rmse: 0.67033 |  0:00:12s\n",
      "epoch 19 | loss: 0.45364 | val_0_rmse: 0.67033 | val_1_rmse: 0.66717 |  0:00:13s\n",
      "epoch 20 | loss: 0.44897 | val_0_rmse: 0.67139 | val_1_rmse: 0.66997 |  0:00:13s\n",
      "epoch 21 | loss: 0.44736 | val_0_rmse: 0.68417 | val_1_rmse: 0.66154 |  0:00:14s\n",
      "epoch 22 | loss: 0.44275 | val_0_rmse: 0.66498 | val_1_rmse: 0.66104 |  0:00:15s\n",
      "epoch 23 | loss: 0.44376 | val_0_rmse: 0.66288 | val_1_rmse: 0.65945 |  0:00:15s\n",
      "epoch 24 | loss: 0.44066 | val_0_rmse: 0.66206 | val_1_rmse: 0.65728 |  0:00:16s\n",
      "epoch 25 | loss: 0.439   | val_0_rmse: 0.66158 | val_1_rmse: 0.65796 |  0:00:17s\n",
      "epoch 26 | loss: 0.43726 | val_0_rmse: 0.66344 | val_1_rmse: 0.65999 |  0:00:18s\n",
      "epoch 27 | loss: 0.43538 | val_0_rmse: 0.66655 | val_1_rmse: 0.65903 |  0:00:18s\n",
      "epoch 28 | loss: 0.43581 | val_0_rmse: 0.66194 | val_1_rmse: 0.65674 |  0:00:19s\n",
      "epoch 29 | loss: 0.43506 | val_0_rmse: 0.66381 | val_1_rmse: 0.6573  |  0:00:20s\n",
      "epoch 30 | loss: 0.43437 | val_0_rmse: 0.66351 | val_1_rmse: 0.65469 |  0:00:22s\n",
      "epoch 31 | loss: 0.43416 | val_0_rmse: 0.66859 | val_1_rmse: 0.6539  |  0:00:23s\n",
      "epoch 32 | loss: 0.43177 | val_0_rmse: 0.66919 | val_1_rmse: 0.65256 |  0:00:24s\n",
      "epoch 33 | loss: 0.43054 | val_0_rmse: 0.67422 | val_1_rmse: 0.6535  |  0:00:25s\n",
      "epoch 34 | loss: 0.43084 | val_0_rmse: 0.67434 | val_1_rmse: 0.65271 |  0:00:26s\n",
      "epoch 35 | loss: 0.43042 | val_0_rmse: 0.66927 | val_1_rmse: 0.6504  |  0:00:27s\n",
      "epoch 36 | loss: 0.42921 | val_0_rmse: 0.66376 | val_1_rmse: 0.65038 |  0:00:28s\n",
      "epoch 37 | loss: 0.42964 | val_0_rmse: 0.65991 | val_1_rmse: 0.65066 |  0:00:29s\n",
      "epoch 38 | loss: 0.4286  | val_0_rmse: 0.65679 | val_1_rmse: 0.6495  |  0:00:30s\n",
      "epoch 39 | loss: 0.42853 | val_0_rmse: 0.6559  | val_1_rmse: 0.65026 |  0:00:31s\n",
      "epoch 40 | loss: 0.42645 | val_0_rmse: 0.65635 | val_1_rmse: 0.65145 |  0:00:31s\n",
      "epoch 41 | loss: 0.42708 | val_0_rmse: 0.65444 | val_1_rmse: 0.65012 |  0:00:32s\n",
      "epoch 42 | loss: 0.42667 | val_0_rmse: 0.65416 | val_1_rmse: 0.65008 |  0:00:33s\n",
      "epoch 43 | loss: 0.42736 | val_0_rmse: 0.65422 | val_1_rmse: 0.64969 |  0:00:34s\n",
      "epoch 44 | loss: 0.4275  | val_0_rmse: 0.65426 | val_1_rmse: 0.65086 |  0:00:34s\n",
      "epoch 45 | loss: 0.4259  | val_0_rmse: 0.65302 | val_1_rmse: 0.6499  |  0:00:35s\n",
      "epoch 46 | loss: 0.42466 | val_0_rmse: 0.6528  | val_1_rmse: 0.64947 |  0:00:36s\n",
      "epoch 47 | loss: 0.42437 | val_0_rmse: 0.65359 | val_1_rmse: 0.64836 |  0:00:36s\n",
      "epoch 48 | loss: 0.42582 | val_0_rmse: 0.6539  | val_1_rmse: 0.6504  |  0:00:37s\n",
      "epoch 49 | loss: 0.42503 | val_0_rmse: 0.65311 | val_1_rmse: 0.64989 |  0:00:38s\n",
      "epoch 50 | loss: 0.42427 | val_0_rmse: 0.65119 | val_1_rmse: 0.64781 |  0:00:38s\n",
      "epoch 51 | loss: 0.42489 | val_0_rmse: 0.65235 | val_1_rmse: 0.64986 |  0:00:39s\n",
      "epoch 52 | loss: 0.42359 | val_0_rmse: 0.65045 | val_1_rmse: 0.64761 |  0:00:40s\n",
      "epoch 53 | loss: 0.42283 | val_0_rmse: 0.65027 | val_1_rmse: 0.64707 |  0:00:40s\n",
      "epoch 54 | loss: 0.42218 | val_0_rmse: 0.6512  | val_1_rmse: 0.64795 |  0:00:41s\n",
      "epoch 55 | loss: 0.42273 | val_0_rmse: 0.65318 | val_1_rmse: 0.64984 |  0:00:42s\n",
      "epoch 56 | loss: 0.42252 | val_0_rmse: 0.65279 | val_1_rmse: 0.64925 |  0:00:43s\n",
      "epoch 57 | loss: 0.4221  | val_0_rmse: 0.65175 | val_1_rmse: 0.64847 |  0:00:43s\n",
      "epoch 58 | loss: 0.42245 | val_0_rmse: 0.65108 | val_1_rmse: 0.64853 |  0:00:44s\n",
      "epoch 59 | loss: 0.42229 | val_0_rmse: 0.65076 | val_1_rmse: 0.64801 |  0:00:45s\n",
      "epoch 60 | loss: 0.42134 | val_0_rmse: 0.65031 | val_1_rmse: 0.64772 |  0:00:45s\n",
      "epoch 61 | loss: 0.42132 | val_0_rmse: 0.65101 | val_1_rmse: 0.6482  |  0:00:46s\n",
      "epoch 62 | loss: 0.42033 | val_0_rmse: 0.6498  | val_1_rmse: 0.64655 |  0:00:47s\n",
      "epoch 63 | loss: 0.42104 | val_0_rmse: 0.64988 | val_1_rmse: 0.64694 |  0:00:48s\n",
      "epoch 64 | loss: 0.41968 | val_0_rmse: 0.64839 | val_1_rmse: 1.71488 |  0:00:49s\n",
      "epoch 65 | loss: 0.42182 | val_0_rmse: 0.64763 | val_1_rmse: 1.6754  |  0:00:50s\n",
      "epoch 66 | loss: 0.4206  | val_0_rmse: 0.64921 | val_1_rmse: 0.73094 |  0:00:51s\n",
      "epoch 67 | loss: 0.41831 | val_0_rmse: 0.64826 | val_1_rmse: 2.06043 |  0:00:52s\n",
      "epoch 68 | loss: 0.42007 | val_0_rmse: 0.6485  | val_1_rmse: 0.64707 |  0:00:53s\n",
      "epoch 69 | loss: 0.4201  | val_0_rmse: 0.64813 | val_1_rmse: 0.64619 |  0:00:53s\n",
      "epoch 70 | loss: 0.42086 | val_0_rmse: 0.64723 | val_1_rmse: 0.64478 |  0:00:54s\n",
      "epoch 71 | loss: 0.4211  | val_0_rmse: 0.64859 | val_1_rmse: 2.44219 |  0:00:55s\n",
      "epoch 72 | loss: 0.41961 | val_0_rmse: 0.64815 | val_1_rmse: 0.64784 |  0:00:56s\n",
      "epoch 73 | loss: 0.41843 | val_0_rmse: 0.66598 | val_1_rmse: 0.66428 |  0:00:57s\n",
      "epoch 74 | loss: 0.41804 | val_0_rmse: 0.64642 | val_1_rmse: 0.64916 |  0:00:57s\n",
      "epoch 75 | loss: 0.41756 | val_0_rmse: 0.64635 | val_1_rmse: 0.6461  |  0:00:58s\n",
      "epoch 76 | loss: 0.41794 | val_0_rmse: 0.64863 | val_1_rmse: 3.2185  |  0:00:59s\n",
      "epoch 77 | loss: 0.41821 | val_0_rmse: 0.64767 | val_1_rmse: 0.64828 |  0:00:59s\n",
      "epoch 78 | loss: 0.41858 | val_0_rmse: 0.64571 | val_1_rmse: 3.81839 |  0:01:00s\n",
      "epoch 79 | loss: 0.41715 | val_0_rmse: 0.6455  | val_1_rmse: 0.69427 |  0:01:01s\n",
      "epoch 80 | loss: 0.41769 | val_0_rmse: 0.64487 | val_1_rmse: 0.70116 |  0:01:01s\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 70 and best_val_1_rmse = 0.64478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4189, Val Loss: 0.4157, RMSE: 0.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.8802  | val_0_rmse: 0.94929 | val_1_rmse: 0.93818 |  0:00:00s\n",
      "epoch 1  | loss: 1.73109 | val_0_rmse: 1.00654 | val_1_rmse: 0.96256 |  0:00:01s\n",
      "epoch 2  | loss: 1.22846 | val_0_rmse: 1.09209 | val_1_rmse: 0.96104 |  0:00:01s\n",
      "epoch 3  | loss: 1.01356 | val_0_rmse: 1.02517 | val_1_rmse: 0.97716 |  0:00:02s\n",
      "epoch 4  | loss: 0.90323 | val_0_rmse: 1.2382  | val_1_rmse: 1.03422 |  0:00:03s\n",
      "epoch 5  | loss: 0.81391 | val_0_rmse: 1.07986 | val_1_rmse: 0.90178 |  0:00:03s\n",
      "epoch 6  | loss: 0.71543 | val_0_rmse: 1.11444 | val_1_rmse: 0.82601 |  0:00:04s\n",
      "epoch 7  | loss: 0.65656 | val_0_rmse: 1.14453 | val_1_rmse: 0.78259 |  0:00:05s\n",
      "epoch 8  | loss: 0.60288 | val_0_rmse: 0.99088 | val_1_rmse: 0.74266 |  0:00:05s\n",
      "epoch 9  | loss: 0.55315 | val_0_rmse: 0.71793 | val_1_rmse: 0.70952 |  0:00:06s\n",
      "epoch 10 | loss: 0.51951 | val_0_rmse: 0.84279 | val_1_rmse: 0.69794 |  0:00:06s\n",
      "epoch 11 | loss: 0.49321 | val_0_rmse: 0.95729 | val_1_rmse: 0.68323 |  0:00:07s\n",
      "epoch 12 | loss: 0.47826 | val_0_rmse: 0.96071 | val_1_rmse: 0.67297 |  0:00:08s\n",
      "epoch 13 | loss: 0.46707 | val_0_rmse: 0.97075 | val_1_rmse: 0.66865 |  0:00:08s\n",
      "epoch 14 | loss: 0.45959 | val_0_rmse: 0.97051 | val_1_rmse: 0.66345 |  0:00:09s\n",
      "epoch 15 | loss: 0.45587 | val_0_rmse: 0.87618 | val_1_rmse: 0.6609  |  0:00:10s\n",
      "epoch 16 | loss: 0.45311 | val_0_rmse: 0.75355 | val_1_rmse: 0.66472 |  0:00:10s\n",
      "epoch 17 | loss: 0.44802 | val_0_rmse: 0.70572 | val_1_rmse: 0.65585 |  0:00:11s\n",
      "epoch 18 | loss: 0.44759 | val_0_rmse: 0.66206 | val_1_rmse: 0.65522 |  0:00:11s\n",
      "epoch 19 | loss: 0.44555 | val_0_rmse: 0.66071 | val_1_rmse: 0.6572  |  0:00:12s\n",
      "epoch 20 | loss: 0.44899 | val_0_rmse: 0.65886 | val_1_rmse: 0.65938 |  0:00:13s\n",
      "epoch 21 | loss: 0.44606 | val_0_rmse: 0.66276 | val_1_rmse: 0.66271 |  0:00:13s\n",
      "epoch 22 | loss: 0.44211 | val_0_rmse: 0.65963 | val_1_rmse: 0.66337 |  0:00:14s\n",
      "epoch 23 | loss: 0.44106 | val_0_rmse: 0.65851 | val_1_rmse: 0.66176 |  0:00:15s\n",
      "epoch 24 | loss: 0.44126 | val_0_rmse: 0.66329 | val_1_rmse: 0.67279 |  0:00:15s\n",
      "epoch 25 | loss: 0.43798 | val_0_rmse: 0.65954 | val_1_rmse: 0.6993  |  0:00:16s\n",
      "epoch 26 | loss: 0.4363  | val_0_rmse: 0.65793 | val_1_rmse: 0.69677 |  0:00:16s\n",
      "epoch 27 | loss: 0.43601 | val_0_rmse: 0.65646 | val_1_rmse: 0.70344 |  0:00:17s\n",
      "epoch 28 | loss: 0.43656 | val_0_rmse: 0.65611 | val_1_rmse: 0.69043 |  0:00:18s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_1_rmse = 0.65522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4383, Val Loss: 0.4293, RMSE: 0.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.11468 | val_0_rmse: 1.02025 | val_1_rmse: 0.96109 |  0:00:00s\n",
      "epoch 1  | loss: 2.91129 | val_0_rmse: 1.05294 | val_1_rmse: 1.11461 |  0:00:01s\n",
      "epoch 2  | loss: 1.92305 | val_0_rmse: 1.16171 | val_1_rmse: 1.02974 |  0:00:02s\n",
      "epoch 3  | loss: 1.37255 | val_0_rmse: 1.41121 | val_1_rmse: 1.05125 |  0:00:03s\n",
      "epoch 4  | loss: 1.13064 | val_0_rmse: 1.23081 | val_1_rmse: 0.99823 |  0:00:04s\n",
      "epoch 5  | loss: 0.97381 | val_0_rmse: 1.08727 | val_1_rmse: 0.98014 |  0:00:05s\n",
      "epoch 6  | loss: 0.86079 | val_0_rmse: 1.09185 | val_1_rmse: 0.89872 |  0:00:06s\n",
      "epoch 7  | loss: 0.73538 | val_0_rmse: 0.84635 | val_1_rmse: 0.7957  |  0:00:06s\n",
      "epoch 8  | loss: 0.6503  | val_0_rmse: 0.75221 | val_1_rmse: 0.72706 |  0:00:07s\n",
      "epoch 9  | loss: 0.58777 | val_0_rmse: 0.87463 | val_1_rmse: 0.71677 |  0:00:08s\n",
      "epoch 10 | loss: 0.55828 | val_0_rmse: 0.75298 | val_1_rmse: 0.8494  |  0:00:09s\n",
      "epoch 11 | loss: 0.53262 | val_0_rmse: 0.70718 | val_1_rmse: 0.7099  |  0:00:10s\n",
      "epoch 12 | loss: 0.51932 | val_0_rmse: 0.69485 | val_1_rmse: 0.68913 |  0:00:11s\n",
      "epoch 13 | loss: 0.50469 | val_0_rmse: 0.68492 | val_1_rmse: 0.68794 |  0:00:12s\n",
      "epoch 14 | loss: 0.50348 | val_0_rmse: 0.68981 | val_1_rmse: 0.6839  |  0:00:13s\n",
      "epoch 15 | loss: 0.49753 | val_0_rmse: 0.6872  | val_1_rmse: 0.68278 |  0:00:13s\n",
      "epoch 16 | loss: 0.49536 | val_0_rmse: 0.68422 | val_1_rmse: 0.69183 |  0:00:14s\n",
      "epoch 17 | loss: 0.49045 | val_0_rmse: 0.68809 | val_1_rmse: 0.68429 |  0:00:15s\n",
      "epoch 18 | loss: 0.48967 | val_0_rmse: 0.69364 | val_1_rmse: 0.69859 |  0:00:16s\n",
      "epoch 19 | loss: 0.48725 | val_0_rmse: 0.68914 | val_1_rmse: 0.68212 |  0:00:17s\n",
      "epoch 20 | loss: 0.48336 | val_0_rmse: 0.68507 | val_1_rmse: 0.67997 |  0:00:18s\n",
      "epoch 21 | loss: 0.48257 | val_0_rmse: 0.69521 | val_1_rmse: 0.68667 |  0:00:19s\n",
      "epoch 22 | loss: 0.4784  | val_0_rmse: 0.73049 | val_1_rmse: 0.68377 |  0:00:19s\n",
      "epoch 23 | loss: 0.47937 | val_0_rmse: 0.70161 | val_1_rmse: 0.67394 |  0:00:20s\n",
      "epoch 24 | loss: 0.48056 | val_0_rmse: 0.70053 | val_1_rmse: 0.67648 |  0:00:21s\n",
      "epoch 25 | loss: 0.47568 | val_0_rmse: 0.6845  | val_1_rmse: 1.09749 |  0:00:22s\n",
      "epoch 26 | loss: 0.47357 | val_0_rmse: 0.68528 | val_1_rmse: 0.70736 |  0:00:23s\n",
      "epoch 27 | loss: 0.4698  | val_0_rmse: 0.69033 | val_1_rmse: 0.88132 |  0:00:24s\n",
      "epoch 28 | loss: 0.4738  | val_0_rmse: 0.71451 | val_1_rmse: 0.72981 |  0:00:25s\n",
      "epoch 29 | loss: 0.46849 | val_0_rmse: 0.69416 | val_1_rmse: 0.67849 |  0:00:25s\n",
      "epoch 30 | loss: 0.46764 | val_0_rmse: 0.68096 | val_1_rmse: 0.70909 |  0:00:26s\n",
      "epoch 31 | loss: 0.46103 | val_0_rmse: 0.68119 | val_1_rmse: 0.67177 |  0:00:27s\n",
      "epoch 32 | loss: 0.45975 | val_0_rmse: 0.68484 | val_1_rmse: 0.67741 |  0:00:28s\n",
      "epoch 33 | loss: 0.45839 | val_0_rmse: 0.68755 | val_1_rmse: 0.67413 |  0:00:29s\n",
      "epoch 34 | loss: 0.45617 | val_0_rmse: 0.68287 | val_1_rmse: 0.67926 |  0:00:30s\n",
      "epoch 35 | loss: 0.4564  | val_0_rmse: 0.68408 | val_1_rmse: 0.68202 |  0:00:31s\n",
      "epoch 36 | loss: 0.45417 | val_0_rmse: 0.67844 | val_1_rmse: 0.67679 |  0:00:31s\n",
      "epoch 37 | loss: 0.45296 | val_0_rmse: 0.69132 | val_1_rmse: 0.68703 |  0:00:32s\n",
      "epoch 38 | loss: 0.45462 | val_0_rmse: 0.67958 | val_1_rmse: 0.67182 |  0:00:33s\n",
      "epoch 39 | loss: 0.45314 | val_0_rmse: 0.68024 | val_1_rmse: 0.67315 |  0:00:34s\n",
      "epoch 40 | loss: 0.45339 | val_0_rmse: 0.6838  | val_1_rmse: 0.6778  |  0:00:35s\n",
      "epoch 41 | loss: 0.4494  | val_0_rmse: 0.68694 | val_1_rmse: 0.67611 |  0:00:36s\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_1_rmse = 0.67177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4640, Val Loss: 0.4513, RMSE: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.98947 | val_0_rmse: 1.07033 | val_1_rmse: 0.97745 |  0:00:00s\n",
      "epoch 1  | loss: 3.07218 | val_0_rmse: 1.12804 | val_1_rmse: 0.9917  |  0:00:01s\n",
      "epoch 2  | loss: 1.96876 | val_0_rmse: 1.11065 | val_1_rmse: 1.02191 |  0:00:02s\n",
      "epoch 3  | loss: 1.48848 | val_0_rmse: 1.16357 | val_1_rmse: 1.01359 |  0:00:03s\n",
      "epoch 4  | loss: 1.19589 | val_0_rmse: 1.14069 | val_1_rmse: 1.03473 |  0:00:04s\n",
      "epoch 5  | loss: 1.03634 | val_0_rmse: 0.98567 | val_1_rmse: 1.1389  |  0:00:05s\n",
      "epoch 6  | loss: 0.90435 | val_0_rmse: 1.01746 | val_1_rmse: 1.2255  |  0:00:05s\n",
      "epoch 7  | loss: 0.81497 | val_0_rmse: 0.85448 | val_1_rmse: 0.89793 |  0:00:06s\n",
      "epoch 8  | loss: 0.71209 | val_0_rmse: 0.9782  | val_1_rmse: 0.79375 |  0:00:07s\n",
      "epoch 9  | loss: 0.63537 | val_0_rmse: 0.77807 | val_1_rmse: 0.72445 |  0:00:08s\n",
      "epoch 10 | loss: 0.58219 | val_0_rmse: 0.74963 | val_1_rmse: 0.71085 |  0:00:09s\n",
      "epoch 11 | loss: 0.54332 | val_0_rmse: 0.74229 | val_1_rmse: 0.71992 |  0:00:10s\n",
      "epoch 12 | loss: 0.52355 | val_0_rmse: 0.73741 | val_1_rmse: 0.77649 |  0:00:11s\n",
      "epoch 13 | loss: 0.51141 | val_0_rmse: 0.75569 | val_1_rmse: 0.76185 |  0:00:12s\n",
      "epoch 14 | loss: 0.5005  | val_0_rmse: 0.73619 | val_1_rmse: 0.73606 |  0:00:13s\n",
      "epoch 15 | loss: 0.49679 | val_0_rmse: 0.78854 | val_1_rmse: 0.71039 |  0:00:14s\n",
      "epoch 16 | loss: 0.49553 | val_0_rmse: 0.71591 | val_1_rmse: 0.69387 |  0:00:14s\n",
      "epoch 17 | loss: 0.49119 | val_0_rmse: 0.699   | val_1_rmse: 0.68602 |  0:00:15s\n",
      "epoch 18 | loss: 0.48912 | val_0_rmse: 0.69745 | val_1_rmse: 0.69475 |  0:00:16s\n",
      "epoch 19 | loss: 0.47873 | val_0_rmse: 0.69613 | val_1_rmse: 0.70275 |  0:00:17s\n",
      "epoch 20 | loss: 0.47777 | val_0_rmse: 0.69189 | val_1_rmse: 0.70493 |  0:00:18s\n",
      "epoch 21 | loss: 0.47832 | val_0_rmse: 0.6889  | val_1_rmse: 0.68743 |  0:00:19s\n",
      "epoch 22 | loss: 0.47406 | val_0_rmse: 0.69296 | val_1_rmse: 0.69172 |  0:00:20s\n",
      "epoch 23 | loss: 0.47049 | val_0_rmse: 0.70152 | val_1_rmse: 0.81677 |  0:00:21s\n",
      "epoch 24 | loss: 0.46942 | val_0_rmse: 0.71737 | val_1_rmse: 0.67622 |  0:00:21s\n",
      "epoch 25 | loss: 0.46927 | val_0_rmse: 0.70526 | val_1_rmse: 0.67455 |  0:00:22s\n",
      "epoch 26 | loss: 0.46602 | val_0_rmse: 0.71716 | val_1_rmse: 0.68782 |  0:00:23s\n",
      "epoch 27 | loss: 0.46633 | val_0_rmse: 0.74273 | val_1_rmse: 1.06789 |  0:00:24s\n",
      "epoch 28 | loss: 0.46494 | val_0_rmse: 0.73258 | val_1_rmse: 1.1282  |  0:00:25s\n",
      "epoch 29 | loss: 0.46332 | val_0_rmse: 0.73598 | val_1_rmse: 0.72056 |  0:00:26s\n",
      "epoch 30 | loss: 0.46112 | val_0_rmse: 0.71706 | val_1_rmse: 1.03034 |  0:00:27s\n",
      "epoch 31 | loss: 0.45742 | val_0_rmse: 0.72438 | val_1_rmse: 0.89901 |  0:00:27s\n",
      "epoch 32 | loss: 0.45824 | val_0_rmse: 0.67996 | val_1_rmse: 0.79873 |  0:00:28s\n",
      "epoch 33 | loss: 0.45538 | val_0_rmse: 0.68368 | val_1_rmse: 0.7139  |  0:00:29s\n",
      "epoch 34 | loss: 0.45341 | val_0_rmse: 0.69613 | val_1_rmse: 0.67467 |  0:00:30s\n",
      "epoch 35 | loss: 0.45534 | val_0_rmse: 0.67547 | val_1_rmse: 0.68422 |  0:00:31s\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_1_rmse = 0.67455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4974, Val Loss: 0.4550, RMSE: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 14.14602| val_0_rmse: 2.17341 | val_1_rmse: 1.10813 |  0:00:01s\n",
      "epoch 1  | loss: 13.78497| val_0_rmse: 2.74599 | val_1_rmse: 1.86348 |  0:00:03s\n",
      "epoch 2  | loss: 13.1452 | val_0_rmse: 2.40563 | val_1_rmse: 2.80998 |  0:00:04s\n",
      "epoch 3  | loss: 12.55406| val_0_rmse: 2.53711 | val_1_rmse: 5.07747 |  0:00:05s\n",
      "epoch 4  | loss: 11.05043| val_0_rmse: 3.68934 | val_1_rmse: 4.02576 |  0:00:07s\n",
      "epoch 5  | loss: 10.30177| val_0_rmse: 4.33473 | val_1_rmse: 6.30369 |  0:00:09s\n",
      "epoch 6  | loss: 8.92808 | val_0_rmse: 4.37422 | val_1_rmse: 3.68926 |  0:00:11s\n",
      "epoch 7  | loss: 7.09529 | val_0_rmse: 2.86965 | val_1_rmse: 3.18527 |  0:00:14s\n",
      "epoch 8  | loss: 5.4471  | val_0_rmse: 3.11476 | val_1_rmse: 2.61924 |  0:00:17s\n",
      "epoch 9  | loss: 4.36378 | val_0_rmse: 2.44408 | val_1_rmse: 2.81061 |  0:00:20s\n",
      "epoch 10 | loss: 3.26088 | val_0_rmse: 2.49669 | val_1_rmse: 3.15334 |  0:00:25s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.10813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 4.7237, Val Loss: 1.2280, RMSE: 1.1081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 14.44683| val_0_rmse: 1.11344 | val_1_rmse: 1.21176 |  0:00:06s\n",
      "epoch 1  | loss: 13.89028| val_0_rmse: 1.71811 | val_1_rmse: 1.71109 |  0:00:12s\n",
      "epoch 2  | loss: 13.23585| val_0_rmse: 2.54999 | val_1_rmse: 2.97642 |  0:00:18s\n",
      "epoch 3  | loss: 12.64772| val_0_rmse: 3.36241 | val_1_rmse: 2.99227 |  0:00:23s\n",
      "epoch 4  | loss: 11.17602| val_0_rmse: 3.79979 | val_1_rmse: 3.94636 |  0:00:29s\n",
      "epoch 5  | loss: 9.94344 | val_0_rmse: 2.72641 | val_1_rmse: 3.60254 |  0:00:35s\n",
      "epoch 6  | loss: 8.94832 | val_0_rmse: 3.08225 | val_1_rmse: 2.78393 |  0:00:40s\n",
      "epoch 7  | loss: 7.67759 | val_0_rmse: 2.98583 | val_1_rmse: 2.11133 |  0:00:46s\n",
      "epoch 8  | loss: 6.35506 | val_0_rmse: 2.47853 | val_1_rmse: 2.06287 |  0:00:51s\n",
      "epoch 9  | loss: 5.00357 | val_0_rmse: 2.17118 | val_1_rmse: 3.6304  |  0:00:57s\n",
      "epoch 10 | loss: 4.13156 | val_0_rmse: 2.49377 | val_1_rmse: 4.14862 |  0:01:03s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.21176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.2397, Val Loss: 1.4684, RMSE: 1.2118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.43113 | val_0_rmse: 0.98771 | val_1_rmse: 1.09209 |  0:00:02s\n",
      "epoch 1  | loss: 1.50453 | val_0_rmse: 0.99611 | val_1_rmse: 1.21498 |  0:00:04s\n",
      "epoch 2  | loss: 1.1695  | val_0_rmse: 1.00353 | val_1_rmse: 1.4712  |  0:00:07s\n",
      "epoch 3  | loss: 1.0015  | val_0_rmse: 1.57732 | val_1_rmse: 1.06238 |  0:00:09s\n",
      "epoch 4  | loss: 0.91822 | val_0_rmse: 1.77979 | val_1_rmse: 1.06363 |  0:00:11s\n",
      "epoch 5  | loss: 0.83271 | val_0_rmse: 1.15938 | val_1_rmse: 0.95733 |  0:00:14s\n",
      "epoch 6  | loss: 0.71662 | val_0_rmse: 0.91852 | val_1_rmse: 0.77863 |  0:00:16s\n",
      "epoch 7  | loss: 0.61597 | val_0_rmse: 0.76215 | val_1_rmse: 0.72372 |  0:00:18s\n",
      "epoch 8  | loss: 0.56396 | val_0_rmse: 0.72244 | val_1_rmse: 0.71132 |  0:00:20s\n",
      "epoch 9  | loss: 0.53136 | val_0_rmse: 0.70525 | val_1_rmse: 0.69898 |  0:00:22s\n",
      "epoch 10 | loss: 0.50735 | val_0_rmse: 0.7081  | val_1_rmse: 0.69697 |  0:00:24s\n",
      "epoch 11 | loss: 0.4897  | val_0_rmse: 0.69098 | val_1_rmse: 0.68525 |  0:00:26s\n",
      "epoch 12 | loss: 0.48226 | val_0_rmse: 1.01446 | val_1_rmse: 0.69099 |  0:00:28s\n",
      "epoch 13 | loss: 0.47706 | val_0_rmse: 0.73671 | val_1_rmse: 0.67472 |  0:00:30s\n",
      "epoch 14 | loss: 0.46892 | val_0_rmse: 0.81604 | val_1_rmse: 0.67336 |  0:00:32s\n",
      "epoch 15 | loss: 0.46391 | val_0_rmse: 0.69446 | val_1_rmse: 0.67373 |  0:00:34s\n",
      "epoch 16 | loss: 0.46162 | val_0_rmse: 0.68421 | val_1_rmse: 0.66852 |  0:00:36s\n",
      "epoch 17 | loss: 0.45834 | val_0_rmse: 0.68047 | val_1_rmse: 0.66453 |  0:00:38s\n",
      "epoch 18 | loss: 0.45762 | val_0_rmse: 0.68242 | val_1_rmse: 0.66925 |  0:00:40s\n",
      "epoch 19 | loss: 0.45172 | val_0_rmse: 0.67592 | val_1_rmse: 0.66367 |  0:00:42s\n",
      "epoch 20 | loss: 0.45002 | val_0_rmse: 0.67101 | val_1_rmse: 0.66351 |  0:00:44s\n",
      "epoch 21 | loss: 0.45056 | val_0_rmse: 0.67106 | val_1_rmse: 0.66257 |  0:00:46s\n",
      "epoch 22 | loss: 0.44616 | val_0_rmse: 0.67571 | val_1_rmse: 0.6611  |  0:00:48s\n",
      "epoch 23 | loss: 0.44775 | val_0_rmse: 0.67646 | val_1_rmse: 0.66209 |  0:00:50s\n",
      "epoch 24 | loss: 0.44556 | val_0_rmse: 0.66655 | val_1_rmse: 0.66143 |  0:00:52s\n",
      "epoch 25 | loss: 0.44417 | val_0_rmse: 0.66723 | val_1_rmse: 0.66127 |  0:00:54s\n",
      "epoch 26 | loss: 0.44551 | val_0_rmse: 0.66644 | val_1_rmse: 0.66018 |  0:00:56s\n",
      "epoch 27 | loss: 0.44359 | val_0_rmse: 0.66497 | val_1_rmse: 0.6603  |  0:00:58s\n",
      "epoch 28 | loss: 0.44445 | val_0_rmse: 0.6651  | val_1_rmse: 0.66033 |  0:01:00s\n",
      "epoch 29 | loss: 0.44329 | val_0_rmse: 0.66412 | val_1_rmse: 0.66082 |  0:01:02s\n",
      "epoch 30 | loss: 0.44323 | val_0_rmse: 0.66405 | val_1_rmse: 0.66168 |  0:01:04s\n",
      "epoch 31 | loss: 0.44335 | val_0_rmse: 0.67359 | val_1_rmse: 0.66721 |  0:01:06s\n",
      "epoch 32 | loss: 0.43972 | val_0_rmse: 0.67    | val_1_rmse: 0.66305 |  0:01:08s\n",
      "epoch 33 | loss: 0.44108 | val_0_rmse: 0.66759 | val_1_rmse: 0.66024 |  0:01:10s\n",
      "epoch 34 | loss: 0.44068 | val_0_rmse: 0.66894 | val_1_rmse: 0.66328 |  0:01:12s\n",
      "epoch 35 | loss: 0.43902 | val_0_rmse: 0.66793 | val_1_rmse: 0.65832 |  0:01:14s\n",
      "epoch 36 | loss: 0.43926 | val_0_rmse: 0.67166 | val_1_rmse: 0.66214 |  0:01:16s\n",
      "epoch 37 | loss: 0.44023 | val_0_rmse: 0.68775 | val_1_rmse: 0.65976 |  0:01:18s\n",
      "epoch 38 | loss: 0.43852 | val_0_rmse: 0.6966  | val_1_rmse: 0.6583  |  0:01:20s\n",
      "epoch 39 | loss: 0.43877 | val_0_rmse: 0.6942  | val_1_rmse: 0.66141 |  0:01:22s\n",
      "epoch 40 | loss: 0.43826 | val_0_rmse: 0.69749 | val_1_rmse: 0.6636  |  0:01:24s\n",
      "epoch 41 | loss: 0.4369  | val_0_rmse: 0.66374 | val_1_rmse: 0.66032 |  0:01:26s\n",
      "epoch 42 | loss: 0.43745 | val_0_rmse: 0.66529 | val_1_rmse: 0.66204 |  0:01:28s\n",
      "epoch 43 | loss: 0.43692 | val_0_rmse: 0.66537 | val_1_rmse: 0.66216 |  0:01:30s\n",
      "epoch 44 | loss: 0.43669 | val_0_rmse: 0.66018 | val_1_rmse: 0.66457 |  0:01:32s\n",
      "epoch 45 | loss: 0.43414 | val_0_rmse: 0.66043 | val_1_rmse: 0.67583 |  0:01:34s\n",
      "epoch 46 | loss: 0.43459 | val_0_rmse: 0.66013 | val_1_rmse: 0.67548 |  0:01:36s\n",
      "epoch 47 | loss: 0.43519 | val_0_rmse: 0.66328 | val_1_rmse: 0.67571 |  0:01:38s\n",
      "epoch 48 | loss: 0.43498 | val_0_rmse: 0.6604  | val_1_rmse: 0.6634  |  0:01:40s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_1_rmse = 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4853, Val Loss: 0.4334, RMSE: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.36507 | val_0_rmse: 0.97595 | val_1_rmse: 1.02693 |  0:00:01s\n",
      "epoch 1  | loss: 1.5203  | val_0_rmse: 1.10939 | val_1_rmse: 1.03682 |  0:00:04s\n",
      "epoch 2  | loss: 1.15681 | val_0_rmse: 1.22698 | val_1_rmse: 1.04135 |  0:00:05s\n",
      "epoch 3  | loss: 0.98909 | val_0_rmse: 1.2988  | val_1_rmse: 1.01036 |  0:00:07s\n",
      "epoch 4  | loss: 0.90391 | val_0_rmse: 1.11681 | val_1_rmse: 0.98016 |  0:00:10s\n",
      "epoch 5  | loss: 0.78604 | val_0_rmse: 0.97315 | val_1_rmse: 0.82601 |  0:00:12s\n",
      "epoch 6  | loss: 0.67649 | val_0_rmse: 0.85994 | val_1_rmse: 0.77757 |  0:00:14s\n",
      "epoch 7  | loss: 0.59101 | val_0_rmse: 0.84734 | val_1_rmse: 0.72003 |  0:00:16s\n",
      "epoch 8  | loss: 0.54093 | val_0_rmse: 0.74062 | val_1_rmse: 0.70047 |  0:00:18s\n",
      "epoch 9  | loss: 0.50948 | val_0_rmse: 0.70829 | val_1_rmse: 0.69059 |  0:00:20s\n",
      "epoch 10 | loss: 0.49819 | val_0_rmse: 0.69466 | val_1_rmse: 0.67997 |  0:00:22s\n",
      "epoch 11 | loss: 0.48006 | val_0_rmse: 0.68819 | val_1_rmse: 0.67167 |  0:00:24s\n",
      "epoch 12 | loss: 0.47142 | val_0_rmse: 0.6769  | val_1_rmse: 0.66602 |  0:00:26s\n",
      "epoch 13 | loss: 0.46478 | val_0_rmse: 0.67378 | val_1_rmse: 0.66589 |  0:00:28s\n",
      "epoch 14 | loss: 0.45843 | val_0_rmse: 0.66969 | val_1_rmse: 0.66318 |  0:00:30s\n",
      "epoch 15 | loss: 0.45314 | val_0_rmse: 0.66879 | val_1_rmse: 0.66423 |  0:00:32s\n",
      "epoch 16 | loss: 0.44983 | val_0_rmse: 0.66846 | val_1_rmse: 0.66205 |  0:00:34s\n",
      "epoch 17 | loss: 0.44695 | val_0_rmse: 0.67594 | val_1_rmse: 0.65862 |  0:00:37s\n",
      "epoch 18 | loss: 0.4448  | val_0_rmse: 0.67679 | val_1_rmse: 0.65928 |  0:00:39s\n",
      "epoch 19 | loss: 0.44451 | val_0_rmse: 0.67303 | val_1_rmse: 0.65783 |  0:00:41s\n",
      "epoch 20 | loss: 0.44262 | val_0_rmse: 0.67229 | val_1_rmse: 0.65618 |  0:00:43s\n",
      "epoch 21 | loss: 0.44297 | val_0_rmse: 0.66628 | val_1_rmse: 0.65558 |  0:00:45s\n",
      "epoch 22 | loss: 0.4406  | val_0_rmse: 0.6659  | val_1_rmse: 0.65558 |  0:00:47s\n",
      "epoch 23 | loss: 0.43955 | val_0_rmse: 0.66676 | val_1_rmse: 0.65711 |  0:00:49s\n",
      "epoch 24 | loss: 0.43984 | val_0_rmse: 0.66509 | val_1_rmse: 0.65467 |  0:00:51s\n",
      "epoch 25 | loss: 0.43894 | val_0_rmse: 0.66373 | val_1_rmse: 0.65388 |  0:00:53s\n",
      "epoch 26 | loss: 0.43897 | val_0_rmse: 0.6628  | val_1_rmse: 0.65395 |  0:00:55s\n",
      "epoch 27 | loss: 0.43794 | val_0_rmse: 0.6627  | val_1_rmse: 0.65406 |  0:00:58s\n",
      "epoch 28 | loss: 0.43809 | val_0_rmse: 0.66232 | val_1_rmse: 0.65272 |  0:01:00s\n",
      "epoch 29 | loss: 0.43686 | val_0_rmse: 0.6636  | val_1_rmse: 0.65452 |  0:01:02s\n",
      "epoch 30 | loss: 0.43749 | val_0_rmse: 0.66236 | val_1_rmse: 0.65337 |  0:01:04s\n",
      "epoch 31 | loss: 0.43829 | val_0_rmse: 0.66454 | val_1_rmse: 0.65419 |  0:01:06s\n",
      "epoch 32 | loss: 0.43661 | val_0_rmse: 0.66597 | val_1_rmse: 0.65237 |  0:01:08s\n",
      "epoch 33 | loss: 0.43704 | val_0_rmse: 0.67031 | val_1_rmse: 0.65225 |  0:01:10s\n",
      "epoch 34 | loss: 0.43573 | val_0_rmse: 0.66663 | val_1_rmse: 0.65363 |  0:01:12s\n",
      "epoch 35 | loss: 0.43652 | val_0_rmse: 0.66213 | val_1_rmse: 0.65305 |  0:01:14s\n",
      "epoch 36 | loss: 0.43651 | val_0_rmse: 0.66238 | val_1_rmse: 0.65196 |  0:01:16s\n",
      "epoch 37 | loss: 0.43508 | val_0_rmse: 0.66587 | val_1_rmse: 0.65236 |  0:01:18s\n",
      "epoch 38 | loss: 0.43479 | val_0_rmse: 0.66488 | val_1_rmse: 0.65339 |  0:01:20s\n",
      "epoch 39 | loss: 0.43389 | val_0_rmse: 0.66121 | val_1_rmse: 0.65176 |  0:01:22s\n",
      "epoch 40 | loss: 0.43324 | val_0_rmse: 0.66176 | val_1_rmse: 0.65212 |  0:01:23s\n",
      "epoch 41 | loss: 0.43368 | val_0_rmse: 0.66328 | val_1_rmse: 0.65257 |  0:01:25s\n",
      "epoch 42 | loss: 0.43415 | val_0_rmse: 0.66176 | val_1_rmse: 0.65314 |  0:01:27s\n",
      "epoch 43 | loss: 0.43288 | val_0_rmse: 0.66284 | val_1_rmse: 0.65365 |  0:01:29s\n",
      "epoch 44 | loss: 0.43326 | val_0_rmse: 0.66033 | val_1_rmse: 0.6522  |  0:01:31s\n",
      "epoch 45 | loss: 0.43194 | val_0_rmse: 0.66088 | val_1_rmse: 0.65122 |  0:01:33s\n",
      "epoch 46 | loss: 0.43253 | val_0_rmse: 0.66423 | val_1_rmse: 0.6534  |  0:01:35s\n",
      "epoch 47 | loss: 0.43318 | val_0_rmse: 0.66099 | val_1_rmse: 0.65315 |  0:01:37s\n",
      "epoch 48 | loss: 0.43325 | val_0_rmse: 0.65989 | val_1_rmse: 0.65146 |  0:01:39s\n",
      "epoch 49 | loss: 0.4337  | val_0_rmse: 0.65985 | val_1_rmse: 0.65123 |  0:01:40s\n",
      "epoch 50 | loss: 0.43249 | val_0_rmse: 0.66113 | val_1_rmse: 0.65338 |  0:01:42s\n",
      "epoch 51 | loss: 0.43087 | val_0_rmse: 0.65921 | val_1_rmse: 0.6514  |  0:01:44s\n",
      "epoch 52 | loss: 0.43105 | val_0_rmse: 0.65853 | val_1_rmse: 0.65108 |  0:01:46s\n",
      "epoch 53 | loss: 0.43131 | val_0_rmse: 0.65825 | val_1_rmse: 0.6514  |  0:01:48s\n",
      "epoch 54 | loss: 0.43065 | val_0_rmse: 0.66019 | val_1_rmse: 0.65227 |  0:01:50s\n",
      "epoch 55 | loss: 0.43059 | val_0_rmse: 0.65871 | val_1_rmse: 0.65178 |  0:01:52s\n",
      "epoch 56 | loss: 0.43051 | val_0_rmse: 0.66075 | val_1_rmse: 0.65196 |  0:01:53s\n",
      "epoch 57 | loss: 0.42951 | val_0_rmse: 0.66096 | val_1_rmse: 0.65168 |  0:01:55s\n",
      "epoch 58 | loss: 0.42928 | val_0_rmse: 0.65991 | val_1_rmse: 0.6511  |  0:01:56s\n",
      "epoch 59 | loss: 0.43059 | val_0_rmse: 0.65997 | val_1_rmse: 0.65094 |  0:01:57s\n",
      "epoch 60 | loss: 0.43012 | val_0_rmse: 0.66022 | val_1_rmse: 0.65085 |  0:01:57s\n",
      "epoch 61 | loss: 0.42883 | val_0_rmse: 0.65999 | val_1_rmse: 0.64944 |  0:01:58s\n",
      "epoch 62 | loss: 0.43055 | val_0_rmse: 0.66065 | val_1_rmse: 0.65175 |  0:01:58s\n",
      "epoch 63 | loss: 0.43001 | val_0_rmse: 0.66213 | val_1_rmse: 0.65224 |  0:01:59s\n",
      "epoch 64 | loss: 0.42964 | val_0_rmse: 0.66196 | val_1_rmse: 0.65087 |  0:02:00s\n",
      "epoch 65 | loss: 0.42919 | val_0_rmse: 0.66203 | val_1_rmse: 0.65345 |  0:02:00s\n",
      "epoch 66 | loss: 0.42907 | val_0_rmse: 0.65958 | val_1_rmse: 0.65077 |  0:02:01s\n",
      "epoch 67 | loss: 0.42984 | val_0_rmse: 0.65979 | val_1_rmse: 0.65147 |  0:02:01s\n",
      "epoch 68 | loss: 0.42862 | val_0_rmse: 0.65881 | val_1_rmse: 0.6501  |  0:02:02s\n",
      "epoch 69 | loss: 0.42961 | val_0_rmse: 0.66317 | val_1_rmse: 0.6511  |  0:02:03s\n",
      "epoch 70 | loss: 0.42755 | val_0_rmse: 0.66857 | val_1_rmse: 0.65127 |  0:02:03s\n",
      "epoch 71 | loss: 0.42892 | val_0_rmse: 0.66479 | val_1_rmse: 0.65053 |  0:02:04s\n",
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 61 and best_val_1_rmse = 0.64944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4356, Val Loss: 0.4218, RMSE: 0.6494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.14573 | val_0_rmse: 1.09997 | val_1_rmse: 1.02534 |  0:00:00s\n",
      "epoch 1  | loss: 2.02792 | val_0_rmse: 1.12435 | val_1_rmse: 1.07008 |  0:00:01s\n",
      "epoch 2  | loss: 1.5644  | val_0_rmse: 1.26245 | val_1_rmse: 1.04248 |  0:00:02s\n",
      "epoch 3  | loss: 1.28844 | val_0_rmse: 1.39368 | val_1_rmse: 1.17453 |  0:00:03s\n",
      "epoch 4  | loss: 1.11757 | val_0_rmse: 1.07505 | val_1_rmse: 1.05708 |  0:00:04s\n",
      "epoch 5  | loss: 0.95033 | val_0_rmse: 1.01502 | val_1_rmse: 0.97667 |  0:00:05s\n",
      "epoch 6  | loss: 0.8384  | val_0_rmse: 0.94015 | val_1_rmse: 1.03656 |  0:00:06s\n",
      "epoch 7  | loss: 0.75453 | val_0_rmse: 0.9135  | val_1_rmse: 0.86609 |  0:00:06s\n",
      "epoch 8  | loss: 0.69478 | val_0_rmse: 0.86279 | val_1_rmse: 0.80568 |  0:00:07s\n",
      "epoch 9  | loss: 0.64621 | val_0_rmse: 0.79186 | val_1_rmse: 0.75904 |  0:00:08s\n",
      "epoch 10 | loss: 0.60496 | val_0_rmse: 0.72576 | val_1_rmse: 0.71192 |  0:00:09s\n",
      "epoch 11 | loss: 0.56886 | val_0_rmse: 0.71479 | val_1_rmse: 0.71175 |  0:00:10s\n",
      "epoch 12 | loss: 0.53587 | val_0_rmse: 0.70595 | val_1_rmse: 0.69058 |  0:00:11s\n",
      "epoch 13 | loss: 0.52055 | val_0_rmse: 0.69983 | val_1_rmse: 0.69815 |  0:00:11s\n",
      "epoch 14 | loss: 0.50657 | val_0_rmse: 0.69339 | val_1_rmse: 0.69036 |  0:00:12s\n",
      "epoch 15 | loss: 0.49893 | val_0_rmse: 0.69562 | val_1_rmse: 0.68619 |  0:00:13s\n",
      "epoch 16 | loss: 0.49857 | val_0_rmse: 0.70887 | val_1_rmse: 1.17422 |  0:00:14s\n",
      "epoch 17 | loss: 0.48726 | val_0_rmse: 0.69899 | val_1_rmse: 0.92923 |  0:00:15s\n",
      "epoch 18 | loss: 0.48212 | val_0_rmse: 0.6934  | val_1_rmse: 0.83891 |  0:00:16s\n",
      "epoch 19 | loss: 0.4794  | val_0_rmse: 0.69449 | val_1_rmse: 0.70113 |  0:00:16s\n",
      "epoch 20 | loss: 0.47529 | val_0_rmse: 0.69762 | val_1_rmse: 0.69345 |  0:00:17s\n",
      "epoch 21 | loss: 0.47524 | val_0_rmse: 0.70777 | val_1_rmse: 0.71051 |  0:00:18s\n",
      "epoch 22 | loss: 0.47347 | val_0_rmse: 0.68475 | val_1_rmse: 0.7222  |  0:00:19s\n",
      "epoch 23 | loss: 0.46939 | val_0_rmse: 0.6795  | val_1_rmse: 0.76979 |  0:00:20s\n",
      "epoch 24 | loss: 0.46793 | val_0_rmse: 0.68115 | val_1_rmse: 1.942   |  0:00:21s\n",
      "epoch 25 | loss: 0.46581 | val_0_rmse: 0.68119 | val_1_rmse: 1.72376 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_1_rmse = 0.68619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4839, Val Loss: 0.4709, RMSE: 0.6862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.02624 | val_0_rmse: 1.04959 | val_1_rmse: 0.95102 |  0:00:00s\n",
      "epoch 1  | loss: 1.94899 | val_0_rmse: 1.62954 | val_1_rmse: 1.12255 |  0:00:01s\n",
      "epoch 2  | loss: 1.3963  | val_0_rmse: 1.56429 | val_1_rmse: 1.12889 |  0:00:02s\n",
      "epoch 3  | loss: 1.14508 | val_0_rmse: 1.47419 | val_1_rmse: 0.95648 |  0:00:03s\n",
      "epoch 4  | loss: 0.9795  | val_0_rmse: 1.01444 | val_1_rmse: 0.89679 |  0:00:04s\n",
      "epoch 5  | loss: 0.85881 | val_0_rmse: 0.97042 | val_1_rmse: 0.87856 |  0:00:04s\n",
      "epoch 6  | loss: 0.75991 | val_0_rmse: 0.89662 | val_1_rmse: 0.83446 |  0:00:05s\n",
      "epoch 7  | loss: 0.70522 | val_0_rmse: 0.90823 | val_1_rmse: 0.95018 |  0:00:06s\n",
      "epoch 8  | loss: 0.67406 | val_0_rmse: 0.82853 | val_1_rmse: 0.9248  |  0:00:07s\n",
      "epoch 9  | loss: 0.64795 | val_0_rmse: 0.82869 | val_1_rmse: 0.88448 |  0:00:08s\n",
      "epoch 10 | loss: 0.63325 | val_0_rmse: 0.7833  | val_1_rmse: 0.78548 |  0:00:09s\n",
      "epoch 11 | loss: 0.61754 | val_0_rmse: 0.79173 | val_1_rmse: 0.80573 |  0:00:09s\n",
      "epoch 12 | loss: 0.6026  | val_0_rmse: 0.77893 | val_1_rmse: 0.76487 |  0:00:10s\n",
      "epoch 13 | loss: 0.59749 | val_0_rmse: 0.78186 | val_1_rmse: 0.84732 |  0:00:11s\n",
      "epoch 14 | loss: 0.5914  | val_0_rmse: 0.77667 | val_1_rmse: 0.77641 |  0:00:12s\n",
      "epoch 15 | loss: 0.57471 | val_0_rmse: 0.73825 | val_1_rmse: 0.74268 |  0:00:13s\n",
      "epoch 16 | loss: 0.54226 | val_0_rmse: 0.71272 | val_1_rmse: 0.71632 |  0:00:13s\n",
      "epoch 17 | loss: 0.5121  | val_0_rmse: 0.7033  | val_1_rmse: 0.71473 |  0:00:14s\n",
      "epoch 18 | loss: 0.49321 | val_0_rmse: 0.69321 | val_1_rmse: 0.70317 |  0:00:15s\n",
      "epoch 19 | loss: 0.48569 | val_0_rmse: 0.68449 | val_1_rmse: 0.70081 |  0:00:16s\n",
      "epoch 20 | loss: 0.47707 | val_0_rmse: 0.68793 | val_1_rmse: 0.68933 |  0:00:17s\n",
      "epoch 21 | loss: 0.47625 | val_0_rmse: 0.69405 | val_1_rmse: 0.67922 |  0:00:18s\n",
      "epoch 22 | loss: 0.47205 | val_0_rmse: 0.69909 | val_1_rmse: 0.678   |  0:00:18s\n",
      "epoch 23 | loss: 0.47249 | val_0_rmse: 0.68741 | val_1_rmse: 0.68854 |  0:00:19s\n",
      "epoch 24 | loss: 0.47594 | val_0_rmse: 0.69197 | val_1_rmse: 0.68577 |  0:00:20s\n",
      "epoch 25 | loss: 0.47547 | val_0_rmse: 0.69361 | val_1_rmse: 0.6785  |  0:00:21s\n",
      "epoch 26 | loss: 0.47286 | val_0_rmse: 0.68573 | val_1_rmse: 0.6766  |  0:00:22s\n",
      "epoch 27 | loss: 0.46568 | val_0_rmse: 0.68431 | val_1_rmse: 0.68457 |  0:00:23s\n",
      "epoch 28 | loss: 0.4625  | val_0_rmse: 0.68552 | val_1_rmse: 0.69418 |  0:00:23s\n",
      "epoch 29 | loss: 0.46325 | val_0_rmse: 0.69313 | val_1_rmse: 0.69156 |  0:00:24s\n",
      "epoch 30 | loss: 0.46132 | val_0_rmse: 0.68166 | val_1_rmse: 0.67572 |  0:00:25s\n",
      "epoch 31 | loss: 0.45573 | val_0_rmse: 0.68658 | val_1_rmse: 0.67182 |  0:00:26s\n",
      "epoch 32 | loss: 0.45506 | val_0_rmse: 0.69493 | val_1_rmse: 0.67342 |  0:00:27s\n",
      "epoch 33 | loss: 0.45353 | val_0_rmse: 0.68379 | val_1_rmse: 0.67095 |  0:00:28s\n",
      "epoch 34 | loss: 0.45173 | val_0_rmse: 0.6757  | val_1_rmse: 0.66725 |  0:00:28s\n",
      "epoch 35 | loss: 0.45105 | val_0_rmse: 0.67441 | val_1_rmse: 0.67067 |  0:00:29s\n",
      "epoch 36 | loss: 0.44975 | val_0_rmse: 0.6733  | val_1_rmse: 0.67491 |  0:00:30s\n",
      "epoch 37 | loss: 0.44983 | val_0_rmse: 0.67172 | val_1_rmse: 0.67678 |  0:00:31s\n",
      "epoch 38 | loss: 0.44938 | val_0_rmse: 0.66821 | val_1_rmse: 0.66344 |  0:00:32s\n",
      "epoch 39 | loss: 0.44823 | val_0_rmse: 0.66834 | val_1_rmse: 0.6626  |  0:00:33s\n",
      "epoch 40 | loss: 0.44632 | val_0_rmse: 0.66498 | val_1_rmse: 0.66042 |  0:00:33s\n",
      "epoch 41 | loss: 0.44656 | val_0_rmse: 0.66492 | val_1_rmse: 0.66026 |  0:00:34s\n",
      "epoch 42 | loss: 0.44453 | val_0_rmse: 0.69282 | val_1_rmse: 0.76395 |  0:00:35s\n",
      "epoch 43 | loss: 0.44327 | val_0_rmse: 0.66975 | val_1_rmse: 0.71453 |  0:00:36s\n",
      "epoch 44 | loss: 0.44142 | val_0_rmse: 0.66565 | val_1_rmse: 0.66661 |  0:00:37s\n",
      "epoch 45 | loss: 0.44199 | val_0_rmse: 0.66575 | val_1_rmse: 0.6733  |  0:00:37s\n",
      "epoch 46 | loss: 0.44221 | val_0_rmse: 0.66549 | val_1_rmse: 0.95306 |  0:00:38s\n",
      "epoch 47 | loss: 0.44098 | val_0_rmse: 0.67567 | val_1_rmse: 0.86991 |  0:00:39s\n",
      "epoch 48 | loss: 0.44189 | val_0_rmse: 0.67663 | val_1_rmse: 0.82639 |  0:00:40s\n",
      "epoch 49 | loss: 0.44014 | val_0_rmse: 0.66639 | val_1_rmse: 0.79322 |  0:00:41s\n",
      "epoch 50 | loss: 0.44058 | val_0_rmse: 0.66886 | val_1_rmse: 1.00941 |  0:00:42s\n",
      "epoch 51 | loss: 0.43843 | val_0_rmse: 0.66432 | val_1_rmse: 0.6598  |  0:00:42s\n",
      "epoch 52 | loss: 0.43742 | val_0_rmse: 0.66661 | val_1_rmse: 0.96998 |  0:00:43s\n",
      "epoch 53 | loss: 0.43725 | val_0_rmse: 0.6693  | val_1_rmse: 1.40394 |  0:00:44s\n",
      "epoch 54 | loss: 0.43785 | val_0_rmse: 0.66823 | val_1_rmse: 1.14263 |  0:00:45s\n",
      "epoch 55 | loss: 0.43681 | val_0_rmse: 0.66753 | val_1_rmse: 0.92568 |  0:00:46s\n",
      "epoch 56 | loss: 0.43705 | val_0_rmse: 0.67218 | val_1_rmse: 1.40217 |  0:00:46s\n",
      "epoch 57 | loss: 0.4354  | val_0_rmse: 0.6752  | val_1_rmse: 0.80059 |  0:00:47s\n",
      "epoch 58 | loss: 0.43468 | val_0_rmse: 0.68042 | val_1_rmse: 0.89246 |  0:00:48s\n",
      "epoch 59 | loss: 0.43405 | val_0_rmse: 0.6632  | val_1_rmse: 3.70987 |  0:00:49s\n",
      "epoch 60 | loss: 0.4328  | val_0_rmse: 0.66351 | val_1_rmse: 5.70519 |  0:00:50s\n",
      "epoch 61 | loss: 0.43447 | val_0_rmse: 0.66286 | val_1_rmse: 6.52486 |  0:00:51s\n",
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_1_rmse = 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4413, Val Loss: 0.4353, RMSE: 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.3268  | val_0_rmse: 1.09319 | val_1_rmse: 1.16033 |  0:00:01s\n",
      "epoch 1  | loss: 8.83082 | val_0_rmse: 1.428   | val_1_rmse: 2.90074 |  0:00:02s\n",
      "epoch 2  | loss: 8.25686 | val_0_rmse: 2.98821 | val_1_rmse: 2.92591 |  0:00:04s\n",
      "epoch 3  | loss: 7.78353 | val_0_rmse: 3.22978 | val_1_rmse: 2.06412 |  0:00:05s\n",
      "epoch 4  | loss: 6.91792 | val_0_rmse: 2.26904 | val_1_rmse: 2.91756 |  0:00:07s\n",
      "epoch 5  | loss: 5.78763 | val_0_rmse: 4.06489 | val_1_rmse: 2.39807 |  0:00:08s\n",
      "epoch 6  | loss: 5.03283 | val_0_rmse: 2.88649 | val_1_rmse: 5.62706 |  0:00:09s\n",
      "epoch 7  | loss: 4.38436 | val_0_rmse: 2.52457 | val_1_rmse: 2.04425 |  0:00:11s\n",
      "epoch 8  | loss: 4.09198 | val_0_rmse: 2.61695 | val_1_rmse: 1.79682 |  0:00:12s\n",
      "epoch 9  | loss: 3.66636 | val_0_rmse: 1.82186 | val_1_rmse: 3.66563 |  0:00:13s\n",
      "epoch 10 | loss: 3.29374 | val_0_rmse: 1.90157 | val_1_rmse: 2.59422 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.16033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.1951, Val Loss: 1.3464, RMSE: 1.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.40761 | val_0_rmse: 1.19748 | val_1_rmse: 1.05945 |  0:00:01s\n",
      "epoch 1  | loss: 8.90596 | val_0_rmse: 1.83561 | val_1_rmse: 1.50743 |  0:00:02s\n",
      "epoch 2  | loss: 8.43974 | val_0_rmse: 1.69209 | val_1_rmse: 2.21063 |  0:00:04s\n",
      "epoch 3  | loss: 7.86699 | val_0_rmse: 2.25022 | val_1_rmse: 1.87789 |  0:00:05s\n",
      "epoch 4  | loss: 6.79815 | val_0_rmse: 2.59152 | val_1_rmse: 2.06551 |  0:00:06s\n",
      "epoch 5  | loss: 6.18493 | val_0_rmse: 2.71216 | val_1_rmse: 3.55181 |  0:00:08s\n",
      "epoch 6  | loss: 5.42046 | val_0_rmse: 2.83783 | val_1_rmse: 2.73497 |  0:00:09s\n",
      "epoch 7  | loss: 4.77321 | val_0_rmse: 3.18856 | val_1_rmse: 2.41239 |  0:00:11s\n",
      "epoch 8  | loss: 4.14312 | val_0_rmse: 3.58298 | val_1_rmse: 3.02826 |  0:00:12s\n",
      "epoch 9  | loss: 3.65235 | val_0_rmse: 1.94073 | val_1_rmse: 3.13526 |  0:00:13s\n",
      "epoch 10 | loss: 3.07896 | val_0_rmse: 2.84448 | val_1_rmse: 2.48379 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.05945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.4339, Val Loss: 1.1224, RMSE: 1.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.17778 | val_0_rmse: 1.04376 | val_1_rmse: 0.99996 |  0:00:00s\n",
      "epoch 1  | loss: 1.43005 | val_0_rmse: 1.10401 | val_1_rmse: 1.53778 |  0:00:01s\n",
      "epoch 2  | loss: 1.14178 | val_0_rmse: 0.9704  | val_1_rmse: 0.94231 |  0:00:01s\n",
      "epoch 3  | loss: 0.91619 | val_0_rmse: 0.96661 | val_1_rmse: 0.90776 |  0:00:02s\n",
      "epoch 4  | loss: 0.78216 | val_0_rmse: 0.85092 | val_1_rmse: 1.03372 |  0:00:02s\n",
      "epoch 5  | loss: 0.67994 | val_0_rmse: 0.8283  | val_1_rmse: 1.18194 |  0:00:03s\n",
      "epoch 6  | loss: 0.60039 | val_0_rmse: 0.78016 | val_1_rmse: 1.189   |  0:00:04s\n",
      "epoch 7  | loss: 0.54571 | val_0_rmse: 0.71955 | val_1_rmse: 1.01546 |  0:00:04s\n",
      "epoch 8  | loss: 0.51087 | val_0_rmse: 0.70152 | val_1_rmse: 1.04001 |  0:00:05s\n",
      "epoch 9  | loss: 0.49122 | val_0_rmse: 0.69362 | val_1_rmse: 0.99425 |  0:00:05s\n",
      "epoch 10 | loss: 0.48047 | val_0_rmse: 0.69345 | val_1_rmse: 0.8276  |  0:00:06s\n",
      "epoch 11 | loss: 0.47164 | val_0_rmse: 0.68322 | val_1_rmse: 0.72583 |  0:00:07s\n",
      "epoch 12 | loss: 0.46389 | val_0_rmse: 0.67661 | val_1_rmse: 0.70556 |  0:00:07s\n",
      "epoch 13 | loss: 0.45882 | val_0_rmse: 0.67401 | val_1_rmse: 0.67856 |  0:00:08s\n",
      "epoch 14 | loss: 0.45738 | val_0_rmse: 0.67087 | val_1_rmse: 0.67045 |  0:00:08s\n",
      "epoch 15 | loss: 0.45348 | val_0_rmse: 0.66891 | val_1_rmse: 0.67264 |  0:00:09s\n",
      "epoch 16 | loss: 0.4489  | val_0_rmse: 0.66531 | val_1_rmse: 0.66558 |  0:00:10s\n",
      "epoch 17 | loss: 0.44428 | val_0_rmse: 0.66298 | val_1_rmse: 0.66299 |  0:00:10s\n",
      "epoch 18 | loss: 0.44323 | val_0_rmse: 0.66617 | val_1_rmse: 0.66958 |  0:00:11s\n",
      "epoch 19 | loss: 0.44035 | val_0_rmse: 0.66221 | val_1_rmse: 0.66586 |  0:00:11s\n",
      "epoch 20 | loss: 0.44079 | val_0_rmse: 0.66284 | val_1_rmse: 0.66731 |  0:00:12s\n",
      "epoch 21 | loss: 0.43791 | val_0_rmse: 0.66026 | val_1_rmse: 0.65896 |  0:00:13s\n",
      "epoch 22 | loss: 0.43772 | val_0_rmse: 0.66105 | val_1_rmse: 0.65777 |  0:00:13s\n",
      "epoch 23 | loss: 0.43583 | val_0_rmse: 0.65706 | val_1_rmse: 0.65458 |  0:00:14s\n",
      "epoch 24 | loss: 0.43277 | val_0_rmse: 0.65847 | val_1_rmse: 0.65521 |  0:00:14s\n",
      "epoch 25 | loss: 0.43164 | val_0_rmse: 0.65534 | val_1_rmse: 0.65266 |  0:00:15s\n",
      "epoch 26 | loss: 0.4307  | val_0_rmse: 0.65492 | val_1_rmse: 0.65231 |  0:00:15s\n",
      "epoch 27 | loss: 0.43166 | val_0_rmse: 0.65455 | val_1_rmse: 0.65147 |  0:00:16s\n",
      "epoch 28 | loss: 0.43031 | val_0_rmse: 0.65458 | val_1_rmse: 0.65214 |  0:00:17s\n",
      "epoch 29 | loss: 0.42973 | val_0_rmse: 0.67006 | val_1_rmse: 0.65161 |  0:00:17s\n",
      "epoch 30 | loss: 0.42941 | val_0_rmse: 0.6859  | val_1_rmse: 0.65218 |  0:00:18s\n",
      "epoch 31 | loss: 0.4278  | val_0_rmse: 0.71282 | val_1_rmse: 0.65232 |  0:00:19s\n",
      "epoch 32 | loss: 0.42883 | val_0_rmse: 0.71352 | val_1_rmse: 0.65208 |  0:00:19s\n",
      "epoch 33 | loss: 0.42831 | val_0_rmse: 0.83582 | val_1_rmse: 0.65072 |  0:00:20s\n",
      "epoch 34 | loss: 0.42867 | val_0_rmse: 0.75242 | val_1_rmse: 0.65    |  0:00:20s\n",
      "epoch 35 | loss: 0.42765 | val_0_rmse: 0.69965 | val_1_rmse: 0.65229 |  0:00:21s\n",
      "epoch 36 | loss: 0.42949 | val_0_rmse: 0.8124  | val_1_rmse: 0.65518 |  0:00:21s\n",
      "epoch 37 | loss: 0.42798 | val_0_rmse: 0.78992 | val_1_rmse: 0.65131 |  0:00:22s\n",
      "epoch 38 | loss: 0.42895 | val_0_rmse: 0.77748 | val_1_rmse: 0.65123 |  0:00:23s\n",
      "epoch 39 | loss: 0.4288  | val_0_rmse: 0.72576 | val_1_rmse: 0.65313 |  0:00:23s\n",
      "epoch 40 | loss: 0.42729 | val_0_rmse: 0.65645 | val_1_rmse: 0.65063 |  0:00:24s\n",
      "epoch 41 | loss: 0.42877 | val_0_rmse: 0.70499 | val_1_rmse: 0.65164 |  0:00:24s\n",
      "epoch 42 | loss: 0.42716 | val_0_rmse: 0.80877 | val_1_rmse: 0.65303 |  0:00:25s\n",
      "epoch 43 | loss: 0.42729 | val_0_rmse: 0.68552 | val_1_rmse: 0.65228 |  0:00:26s\n",
      "epoch 44 | loss: 0.42672 | val_0_rmse: 0.6521  | val_1_rmse: 0.65123 |  0:00:26s\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_1_rmse = 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.5661, Val Loss: 0.4225, RMSE: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.10652 | val_0_rmse: 1.30593 | val_1_rmse: 0.96917 |  0:00:00s\n",
      "epoch 1  | loss: 1.37132 | val_0_rmse: 1.05009 | val_1_rmse: 0.95735 |  0:00:01s\n",
      "epoch 2  | loss: 1.0473  | val_0_rmse: 1.35204 | val_1_rmse: 1.25638 |  0:00:01s\n",
      "epoch 3  | loss: 0.91306 | val_0_rmse: 1.39729 | val_1_rmse: 1.4793  |  0:00:02s\n",
      "epoch 4  | loss: 0.79781 | val_0_rmse: 1.07386 | val_1_rmse: 1.0768  |  0:00:02s\n",
      "epoch 5  | loss: 0.71777 | val_0_rmse: 0.89792 | val_1_rmse: 0.86215 |  0:00:03s\n",
      "epoch 6  | loss: 0.64417 | val_0_rmse: 0.78328 | val_1_rmse: 0.77431 |  0:00:04s\n",
      "epoch 7  | loss: 0.5907  | val_0_rmse: 0.73543 | val_1_rmse: 0.71913 |  0:00:04s\n",
      "epoch 8  | loss: 0.5395  | val_0_rmse: 0.72647 | val_1_rmse: 0.71389 |  0:00:05s\n",
      "epoch 9  | loss: 0.50705 | val_0_rmse: 0.71693 | val_1_rmse: 0.69387 |  0:00:05s\n",
      "epoch 10 | loss: 0.49286 | val_0_rmse: 0.71424 | val_1_rmse: 0.7217  |  0:00:06s\n",
      "epoch 11 | loss: 0.48083 | val_0_rmse: 0.7044  | val_1_rmse: 1.01169 |  0:00:07s\n",
      "epoch 12 | loss: 0.47413 | val_0_rmse: 0.69349 | val_1_rmse: 0.96797 |  0:00:07s\n",
      "epoch 13 | loss: 0.46372 | val_0_rmse: 0.70318 | val_1_rmse: 1.26863 |  0:00:08s\n",
      "epoch 14 | loss: 0.45894 | val_0_rmse: 0.68329 | val_1_rmse: 0.99643 |  0:00:09s\n",
      "epoch 15 | loss: 0.45298 | val_0_rmse: 0.6786  | val_1_rmse: 1.18343 |  0:00:09s\n",
      "epoch 16 | loss: 0.44949 | val_0_rmse: 0.67712 | val_1_rmse: 1.37843 |  0:00:10s\n",
      "epoch 17 | loss: 0.44995 | val_0_rmse: 0.68014 | val_1_rmse: 0.6666  |  0:00:10s\n",
      "epoch 18 | loss: 0.44783 | val_0_rmse: 0.67886 | val_1_rmse: 0.66284 |  0:00:11s\n",
      "epoch 19 | loss: 0.44367 | val_0_rmse: 0.68761 | val_1_rmse: 0.67255 |  0:00:12s\n",
      "epoch 20 | loss: 0.44302 | val_0_rmse: 0.69168 | val_1_rmse: 1.07124 |  0:00:12s\n",
      "epoch 21 | loss: 0.44142 | val_0_rmse: 0.68633 | val_1_rmse: 0.91366 |  0:00:13s\n",
      "epoch 22 | loss: 0.43868 | val_0_rmse: 0.67562 | val_1_rmse: 0.94686 |  0:00:13s\n",
      "epoch 23 | loss: 0.4388  | val_0_rmse: 0.67175 | val_1_rmse: 0.84573 |  0:00:14s\n",
      "epoch 24 | loss: 0.43795 | val_0_rmse: 0.66998 | val_1_rmse: 0.87741 |  0:00:15s\n",
      "epoch 25 | loss: 0.43586 | val_0_rmse: 0.67673 | val_1_rmse: 0.72053 |  0:00:15s\n",
      "epoch 26 | loss: 0.4343  | val_0_rmse: 0.68953 | val_1_rmse: 1.68116 |  0:00:16s\n",
      "epoch 27 | loss: 0.43485 | val_0_rmse: 0.69724 | val_1_rmse: 1.98064 |  0:00:16s\n",
      "epoch 28 | loss: 0.43282 | val_0_rmse: 0.68185 | val_1_rmse: 1.02385 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_1_rmse = 0.66284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4608, Val Loss: 0.4394, RMSE: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.48907 | val_0_rmse: 0.98125 | val_1_rmse: 0.95431 |  0:00:00s\n",
      "epoch 1  | loss: 2.59792 | val_0_rmse: 1.09066 | val_1_rmse: 0.97944 |  0:00:01s\n",
      "epoch 2  | loss: 1.73603 | val_0_rmse: 1.19035 | val_1_rmse: 1.01257 |  0:00:02s\n",
      "epoch 3  | loss: 1.35327 | val_0_rmse: 1.1687  | val_1_rmse: 1.41022 |  0:00:03s\n",
      "epoch 4  | loss: 1.11802 | val_0_rmse: 1.30043 | val_1_rmse: 1.57434 |  0:00:04s\n",
      "epoch 5  | loss: 0.96667 | val_0_rmse: 1.12306 | val_1_rmse: 1.35123 |  0:00:05s\n",
      "epoch 6  | loss: 0.85198 | val_0_rmse: 0.97926 | val_1_rmse: 1.2242  |  0:00:05s\n",
      "epoch 7  | loss: 0.77016 | val_0_rmse: 0.88548 | val_1_rmse: 0.84095 |  0:00:06s\n",
      "epoch 8  | loss: 0.70085 | val_0_rmse: 0.82404 | val_1_rmse: 0.81329 |  0:00:07s\n",
      "epoch 9  | loss: 0.66067 | val_0_rmse: 0.90643 | val_1_rmse: 0.80981 |  0:00:08s\n",
      "epoch 10 | loss: 0.63922 | val_0_rmse: 0.79365 | val_1_rmse: 0.7995  |  0:00:09s\n",
      "epoch 11 | loss: 0.62518 | val_0_rmse: 0.79295 | val_1_rmse: 0.78881 |  0:00:10s\n",
      "epoch 12 | loss: 0.61503 | val_0_rmse: 0.80521 | val_1_rmse: 0.7887  |  0:00:10s\n",
      "epoch 13 | loss: 0.61501 | val_0_rmse: 0.79154 | val_1_rmse: 0.78006 |  0:00:11s\n",
      "epoch 14 | loss: 0.60562 | val_0_rmse: 0.78859 | val_1_rmse: 0.79301 |  0:00:12s\n",
      "epoch 15 | loss: 0.60656 | val_0_rmse: 0.79603 | val_1_rmse: 0.83    |  0:00:13s\n",
      "epoch 16 | loss: 0.60885 | val_0_rmse: 0.80367 | val_1_rmse: 0.80502 |  0:00:14s\n",
      "epoch 17 | loss: 0.59816 | val_0_rmse: 0.77974 | val_1_rmse: 0.77154 |  0:00:14s\n",
      "epoch 18 | loss: 0.58961 | val_0_rmse: 0.76692 | val_1_rmse: 0.78531 |  0:00:15s\n",
      "epoch 19 | loss: 0.58242 | val_0_rmse: 0.78103 | val_1_rmse: 0.75681 |  0:00:16s\n",
      "epoch 20 | loss: 0.56459 | val_0_rmse: 0.76326 | val_1_rmse: 0.75907 |  0:00:17s\n",
      "epoch 21 | loss: 0.50663 | val_0_rmse: 0.71371 | val_1_rmse: 0.71782 |  0:00:18s\n",
      "epoch 22 | loss: 0.47772 | val_0_rmse: 0.70208 | val_1_rmse: 0.69057 |  0:00:19s\n",
      "epoch 23 | loss: 0.4699  | val_0_rmse: 0.69032 | val_1_rmse: 0.68689 |  0:00:19s\n",
      "epoch 24 | loss: 0.46785 | val_0_rmse: 0.69578 | val_1_rmse: 0.69823 |  0:00:20s\n",
      "epoch 25 | loss: 0.46612 | val_0_rmse: 0.68673 | val_1_rmse: 0.68721 |  0:00:21s\n",
      "epoch 26 | loss: 0.46164 | val_0_rmse: 0.70073 | val_1_rmse: 0.68583 |  0:00:22s\n",
      "epoch 27 | loss: 0.45927 | val_0_rmse: 0.68838 | val_1_rmse: 0.67814 |  0:00:23s\n",
      "epoch 28 | loss: 0.4559  | val_0_rmse: 0.68555 | val_1_rmse: 0.6757  |  0:00:24s\n",
      "epoch 29 | loss: 0.45492 | val_0_rmse: 0.69557 | val_1_rmse: 0.67309 |  0:00:24s\n",
      "epoch 30 | loss: 0.45352 | val_0_rmse: 0.68763 | val_1_rmse: 0.66832 |  0:00:25s\n",
      "epoch 31 | loss: 0.45255 | val_0_rmse: 0.68514 | val_1_rmse: 0.6718  |  0:00:26s\n",
      "epoch 32 | loss: 0.4525  | val_0_rmse: 0.68126 | val_1_rmse: 0.67447 |  0:00:27s\n",
      "epoch 33 | loss: 0.45306 | val_0_rmse: 0.68065 | val_1_rmse: 0.67111 |  0:00:28s\n",
      "epoch 34 | loss: 0.45123 | val_0_rmse: 0.67953 | val_1_rmse: 0.66976 |  0:00:28s\n",
      "epoch 35 | loss: 0.45162 | val_0_rmse: 0.68143 | val_1_rmse: 0.67608 |  0:00:29s\n",
      "epoch 36 | loss: 0.45102 | val_0_rmse: 0.67725 | val_1_rmse: 0.67343 |  0:00:30s\n",
      "epoch 37 | loss: 0.44957 | val_0_rmse: 0.70354 | val_1_rmse: 0.7011  |  0:00:31s\n",
      "epoch 38 | loss: 0.44977 | val_0_rmse: 0.69069 | val_1_rmse: 0.68617 |  0:00:32s\n",
      "epoch 39 | loss: 0.45129 | val_0_rmse: 0.67153 | val_1_rmse: 0.6671  |  0:00:32s\n",
      "epoch 40 | loss: 0.44884 | val_0_rmse: 0.67129 | val_1_rmse: 0.67028 |  0:00:33s\n",
      "epoch 41 | loss: 0.44914 | val_0_rmse: 0.67052 | val_1_rmse: 0.66787 |  0:00:34s\n",
      "epoch 42 | loss: 0.447   | val_0_rmse: 0.67492 | val_1_rmse: 0.66818 |  0:00:35s\n",
      "epoch 43 | loss: 0.44557 | val_0_rmse: 0.69953 | val_1_rmse: 0.67835 |  0:00:36s\n",
      "epoch 44 | loss: 0.44537 | val_0_rmse: 0.68302 | val_1_rmse: 0.67123 |  0:00:37s\n",
      "epoch 45 | loss: 0.44575 | val_0_rmse: 0.67609 | val_1_rmse: 0.66783 |  0:00:37s\n",
      "epoch 46 | loss: 0.44486 | val_0_rmse: 0.67006 | val_1_rmse: 0.66468 |  0:00:38s\n",
      "epoch 47 | loss: 0.44301 | val_0_rmse: 0.66803 | val_1_rmse: 0.66356 |  0:00:39s\n",
      "epoch 48 | loss: 0.44225 | val_0_rmse: 0.66863 | val_1_rmse: 0.66434 |  0:00:40s\n",
      "epoch 49 | loss: 0.44296 | val_0_rmse: 0.6669  | val_1_rmse: 0.66461 |  0:00:41s\n",
      "epoch 50 | loss: 0.44149 | val_0_rmse: 0.66974 | val_1_rmse: 0.66835 |  0:00:42s\n",
      "epoch 51 | loss: 0.4434  | val_0_rmse: 0.6674  | val_1_rmse: 0.66908 |  0:00:42s\n",
      "epoch 52 | loss: 0.44203 | val_0_rmse: 0.66702 | val_1_rmse: 0.66641 |  0:00:43s\n",
      "epoch 53 | loss: 0.44153 | val_0_rmse: 0.66722 | val_1_rmse: 0.66629 |  0:00:44s\n",
      "epoch 54 | loss: 0.43939 | val_0_rmse: 0.66606 | val_1_rmse: 0.66614 |  0:00:45s\n",
      "epoch 55 | loss: 0.44107 | val_0_rmse: 0.6659  | val_1_rmse: 0.66332 |  0:00:46s\n",
      "epoch 56 | loss: 0.44047 | val_0_rmse: 0.66462 | val_1_rmse: 0.66302 |  0:00:46s\n",
      "epoch 57 | loss: 0.43952 | val_0_rmse: 0.66222 | val_1_rmse: 0.65958 |  0:00:47s\n",
      "epoch 58 | loss: 0.43849 | val_0_rmse: 0.66155 | val_1_rmse: 0.65885 |  0:00:48s\n",
      "epoch 59 | loss: 0.4385  | val_0_rmse: 0.6635  | val_1_rmse: 0.66104 |  0:00:49s\n",
      "epoch 60 | loss: 0.43915 | val_0_rmse: 0.6621  | val_1_rmse: 0.6593  |  0:00:50s\n",
      "epoch 61 | loss: 0.44043 | val_0_rmse: 0.66372 | val_1_rmse: 0.66022 |  0:00:51s\n",
      "epoch 62 | loss: 0.43847 | val_0_rmse: 0.66182 | val_1_rmse: 0.65805 |  0:00:51s\n",
      "epoch 63 | loss: 0.44072 | val_0_rmse: 0.664   | val_1_rmse: 0.65973 |  0:00:52s\n",
      "epoch 64 | loss: 0.43767 | val_0_rmse: 0.66256 | val_1_rmse: 0.65927 |  0:00:53s\n",
      "epoch 65 | loss: 0.43796 | val_0_rmse: 0.66253 | val_1_rmse: 0.6589  |  0:00:54s\n",
      "epoch 66 | loss: 0.43697 | val_0_rmse: 0.66241 | val_1_rmse: 0.66135 |  0:00:55s\n",
      "epoch 67 | loss: 0.43656 | val_0_rmse: 0.66262 | val_1_rmse: 0.66045 |  0:00:55s\n",
      "epoch 68 | loss: 0.43665 | val_0_rmse: 0.66158 | val_1_rmse: 0.66043 |  0:00:56s\n",
      "epoch 69 | loss: 0.43615 | val_0_rmse: 0.66335 | val_1_rmse: 0.66185 |  0:00:57s\n",
      "epoch 70 | loss: 0.43718 | val_0_rmse: 0.68938 | val_1_rmse: 0.66009 |  0:00:58s\n",
      "epoch 71 | loss: 0.43595 | val_0_rmse: 0.70787 | val_1_rmse: 0.66002 |  0:00:59s\n",
      "epoch 72 | loss: 0.43552 | val_0_rmse: 0.7023  | val_1_rmse: 0.65943 |  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_1_rmse = 0.65805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4380, Val Loss: 0.4330, RMSE: 0.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.52738 | val_0_rmse: 1.14763 | val_1_rmse: 0.98134 |  0:00:00s\n",
      "epoch 1  | loss: 2.67829 | val_0_rmse: 1.47014 | val_1_rmse: 1.01778 |  0:00:01s\n",
      "epoch 2  | loss: 1.73475 | val_0_rmse: 1.27894 | val_1_rmse: 2.61033 |  0:00:02s\n",
      "epoch 3  | loss: 1.27343 | val_0_rmse: 1.11519 | val_1_rmse: 1.03461 |  0:00:03s\n",
      "epoch 4  | loss: 1.05022 | val_0_rmse: 1.04934 | val_1_rmse: 1.17659 |  0:00:04s\n",
      "epoch 5  | loss: 0.91804 | val_0_rmse: 0.98746 | val_1_rmse: 0.95702 |  0:00:04s\n",
      "epoch 6  | loss: 0.80506 | val_0_rmse: 0.87782 | val_1_rmse: 0.85896 |  0:00:05s\n",
      "epoch 7  | loss: 0.73338 | val_0_rmse: 0.83421 | val_1_rmse: 0.83917 |  0:00:06s\n",
      "epoch 8  | loss: 0.68316 | val_0_rmse: 0.81212 | val_1_rmse: 0.83814 |  0:00:07s\n",
      "epoch 9  | loss: 0.65197 | val_0_rmse: 0.80245 | val_1_rmse: 0.83147 |  0:00:08s\n",
      "epoch 10 | loss: 0.6401  | val_0_rmse: 0.79727 | val_1_rmse: 0.80106 |  0:00:09s\n",
      "epoch 11 | loss: 0.62492 | val_0_rmse: 0.79119 | val_1_rmse: 0.79069 |  0:00:09s\n",
      "epoch 12 | loss: 0.62442 | val_0_rmse: 0.80434 | val_1_rmse: 0.79118 |  0:00:10s\n",
      "epoch 13 | loss: 0.61921 | val_0_rmse: 0.80425 | val_1_rmse: 0.78559 |  0:00:11s\n",
      "epoch 14 | loss: 0.611   | val_0_rmse: 0.78727 | val_1_rmse: 0.81112 |  0:00:12s\n",
      "epoch 15 | loss: 0.61217 | val_0_rmse: 0.77685 | val_1_rmse: 0.8011  |  0:00:13s\n",
      "epoch 16 | loss: 0.60493 | val_0_rmse: 0.77089 | val_1_rmse: 0.7662  |  0:00:13s\n",
      "epoch 17 | loss: 0.59973 | val_0_rmse: 0.7776  | val_1_rmse: 0.77543 |  0:00:14s\n",
      "epoch 18 | loss: 0.60311 | val_0_rmse: 0.78315 | val_1_rmse: 0.78196 |  0:00:15s\n",
      "epoch 19 | loss: 0.59186 | val_0_rmse: 0.77527 | val_1_rmse: 0.75764 |  0:00:16s\n",
      "epoch 20 | loss: 0.58326 | val_0_rmse: 0.76118 | val_1_rmse: 0.75778 |  0:00:17s\n",
      "epoch 21 | loss: 0.57374 | val_0_rmse: 0.76741 | val_1_rmse: 0.79828 |  0:00:18s\n",
      "epoch 22 | loss: 0.57103 | val_0_rmse: 0.76993 | val_1_rmse: 0.75646 |  0:00:18s\n",
      "epoch 23 | loss: 0.56811 | val_0_rmse: 0.75362 | val_1_rmse: 0.75131 |  0:00:19s\n",
      "epoch 24 | loss: 0.56945 | val_0_rmse: 0.75124 | val_1_rmse: 0.74921 |  0:00:20s\n",
      "epoch 25 | loss: 0.56593 | val_0_rmse: 0.75745 | val_1_rmse: 0.95674 |  0:00:21s\n",
      "epoch 26 | loss: 0.56663 | val_0_rmse: 0.7502  | val_1_rmse: 0.74217 |  0:00:22s\n",
      "epoch 27 | loss: 0.55595 | val_0_rmse: 0.7584  | val_1_rmse: 0.72683 |  0:00:22s\n",
      "epoch 28 | loss: 0.52919 | val_0_rmse: 0.70751 | val_1_rmse: 0.69869 |  0:00:23s\n",
      "epoch 29 | loss: 0.50554 | val_0_rmse: 0.6859  | val_1_rmse: 0.68147 |  0:00:24s\n",
      "epoch 30 | loss: 0.48022 | val_0_rmse: 0.67937 | val_1_rmse: 0.68971 |  0:00:25s\n",
      "epoch 31 | loss: 0.47348 | val_0_rmse: 0.67352 | val_1_rmse: 0.69082 |  0:00:26s\n",
      "epoch 32 | loss: 0.46507 | val_0_rmse: 0.67106 | val_1_rmse: 0.74491 |  0:00:27s\n",
      "epoch 33 | loss: 0.4614  | val_0_rmse: 0.67194 | val_1_rmse: 0.6784  |  0:00:27s\n",
      "epoch 34 | loss: 0.45294 | val_0_rmse: 0.66258 | val_1_rmse: 0.67737 |  0:00:28s\n",
      "epoch 35 | loss: 0.45257 | val_0_rmse: 0.66241 | val_1_rmse: 0.66304 |  0:00:29s\n",
      "epoch 36 | loss: 0.44485 | val_0_rmse: 0.66403 | val_1_rmse: 0.6682  |  0:00:30s\n",
      "epoch 37 | loss: 0.44825 | val_0_rmse: 0.66409 | val_1_rmse: 0.67273 |  0:00:31s\n",
      "epoch 38 | loss: 0.44559 | val_0_rmse: 0.66007 | val_1_rmse: 0.66079 |  0:00:32s\n",
      "epoch 39 | loss: 0.44282 | val_0_rmse: 0.65826 | val_1_rmse: 0.66121 |  0:00:32s\n",
      "epoch 40 | loss: 0.44392 | val_0_rmse: 0.65876 | val_1_rmse: 0.77495 |  0:00:33s\n",
      "epoch 41 | loss: 0.44134 | val_0_rmse: 0.65923 | val_1_rmse: 0.6617  |  0:00:34s\n",
      "epoch 42 | loss: 0.44288 | val_0_rmse: 0.65699 | val_1_rmse: 0.6748  |  0:00:35s\n",
      "epoch 43 | loss: 0.43873 | val_0_rmse: 0.65602 | val_1_rmse: 0.66183 |  0:00:36s\n",
      "epoch 44 | loss: 0.4387  | val_0_rmse: 0.65534 | val_1_rmse: 0.66077 |  0:00:37s\n",
      "epoch 45 | loss: 0.43961 | val_0_rmse: 0.65576 | val_1_rmse: 0.65834 |  0:00:37s\n",
      "epoch 46 | loss: 0.43801 | val_0_rmse: 0.65495 | val_1_rmse: 0.65678 |  0:00:38s\n",
      "epoch 47 | loss: 0.43613 | val_0_rmse: 0.65567 | val_1_rmse: 0.67362 |  0:00:39s\n",
      "epoch 48 | loss: 0.43628 | val_0_rmse: 0.6565  | val_1_rmse: 0.67052 |  0:00:40s\n",
      "epoch 49 | loss: 0.4363  | val_0_rmse: 0.65619 | val_1_rmse: 0.66773 |  0:00:41s\n",
      "epoch 50 | loss: 0.4348  | val_0_rmse: 0.659   | val_1_rmse: 0.66552 |  0:00:42s\n",
      "epoch 51 | loss: 0.43362 | val_0_rmse: 0.65697 | val_1_rmse: 0.65653 |  0:00:42s\n",
      "epoch 52 | loss: 0.43482 | val_0_rmse: 0.65716 | val_1_rmse: 0.65659 |  0:00:43s\n",
      "epoch 53 | loss: 0.43364 | val_0_rmse: 0.6573  | val_1_rmse: 0.65586 |  0:00:44s\n",
      "epoch 54 | loss: 0.43433 | val_0_rmse: 0.65775 | val_1_rmse: 0.65584 |  0:00:45s\n",
      "epoch 55 | loss: 0.43412 | val_0_rmse: 0.65613 | val_1_rmse: 0.65653 |  0:00:46s\n",
      "epoch 56 | loss: 0.43547 | val_0_rmse: 0.65442 | val_1_rmse: 0.65379 |  0:00:46s\n",
      "epoch 57 | loss: 0.43337 | val_0_rmse: 0.65537 | val_1_rmse: 0.65523 |  0:00:47s\n",
      "epoch 58 | loss: 0.43289 | val_0_rmse: 0.65555 | val_1_rmse: 0.65787 |  0:00:48s\n",
      "epoch 59 | loss: 0.43288 | val_0_rmse: 0.65486 | val_1_rmse: 0.68495 |  0:00:49s\n",
      "epoch 60 | loss: 0.43164 | val_0_rmse: 0.65458 | val_1_rmse: 0.68708 |  0:00:50s\n",
      "epoch 61 | loss: 0.43446 | val_0_rmse: 0.65512 | val_1_rmse: 0.66075 |  0:00:51s\n",
      "epoch 62 | loss: 0.43409 | val_0_rmse: 0.656   | val_1_rmse: 0.66192 |  0:00:51s\n",
      "epoch 63 | loss: 0.43279 | val_0_rmse: 0.65512 | val_1_rmse: 0.65233 |  0:00:52s\n",
      "epoch 64 | loss: 0.43248 | val_0_rmse: 0.65575 | val_1_rmse: 0.65487 |  0:00:53s\n",
      "epoch 65 | loss: 0.43149 | val_0_rmse: 0.65404 | val_1_rmse: 0.65828 |  0:00:54s\n",
      "epoch 66 | loss: 0.43081 | val_0_rmse: 0.65369 | val_1_rmse: 0.65361 |  0:00:55s\n",
      "epoch 67 | loss: 0.43047 | val_0_rmse: 0.65521 | val_1_rmse: 0.65666 |  0:00:55s\n",
      "epoch 68 | loss: 0.4302  | val_0_rmse: 0.65532 | val_1_rmse: 0.66033 |  0:00:56s\n",
      "epoch 69 | loss: 0.43156 | val_0_rmse: 0.6551  | val_1_rmse: 0.66259 |  0:00:57s\n",
      "epoch 70 | loss: 0.43088 | val_0_rmse: 0.65614 | val_1_rmse: 0.66771 |  0:00:58s\n",
      "epoch 71 | loss: 0.42992 | val_0_rmse: 0.65319 | val_1_rmse: 0.66778 |  0:00:59s\n",
      "epoch 72 | loss: 0.42995 | val_0_rmse: 0.65545 | val_1_rmse: 0.67171 |  0:01:00s\n",
      "epoch 73 | loss: 0.43178 | val_0_rmse: 0.65596 | val_1_rmse: 0.66862 |  0:01:00s\n",
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 63 and best_val_1_rmse = 0.65233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4292, Val Loss: 0.4255, RMSE: 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 13.03148| val_0_rmse: 1.45257 | val_1_rmse: 1.28498 |  0:00:01s\n",
      "epoch 1  | loss: 12.95253| val_0_rmse: 2.36465 | val_1_rmse: 1.59832 |  0:00:02s\n",
      "epoch 2  | loss: 12.3796 | val_0_rmse: 2.94932 | val_1_rmse: 2.09836 |  0:00:04s\n",
      "epoch 3  | loss: 11.11086| val_0_rmse: 3.30482 | val_1_rmse: 3.79613 |  0:00:05s\n",
      "epoch 4  | loss: 9.06843 | val_0_rmse: 3.47262 | val_1_rmse: 7.81836 |  0:00:07s\n",
      "epoch 5  | loss: 7.4627  | val_0_rmse: 2.66072 | val_1_rmse: 3.76563 |  0:00:08s\n",
      "epoch 6  | loss: 6.15929 | val_0_rmse: 2.26791 | val_1_rmse: 3.64902 |  0:00:09s\n",
      "epoch 7  | loss: 5.21925 | val_0_rmse: 2.8897  | val_1_rmse: 5.85533 |  0:00:11s\n",
      "epoch 8  | loss: 4.60304 | val_0_rmse: 2.8924  | val_1_rmse: 2.43779 |  0:00:12s\n",
      "epoch 9  | loss: 3.61703 | val_0_rmse: 2.44542 | val_1_rmse: 2.30019 |  0:00:14s\n",
      "epoch 10 | loss: 2.82618 | val_0_rmse: 2.01759 | val_1_rmse: 1.7009  |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.28498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 2.1100, Val Loss: 1.6512, RMSE: 1.2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 13.19086| val_0_rmse: 1.61267 | val_1_rmse: 2.19869 |  0:00:01s\n",
      "epoch 1  | loss: 12.74614| val_0_rmse: 2.20461 | val_1_rmse: 1.95735 |  0:00:02s\n",
      "epoch 2  | loss: 11.86546| val_0_rmse: 2.66781 | val_1_rmse: 2.19786 |  0:00:04s\n",
      "epoch 3  | loss: 9.97458 | val_0_rmse: 2.72173 | val_1_rmse: 2.43701 |  0:00:05s\n",
      "epoch 4  | loss: 8.45048 | val_0_rmse: 2.69544 | val_1_rmse: 2.34756 |  0:00:06s\n",
      "epoch 5  | loss: 7.43664 | val_0_rmse: 3.1842  | val_1_rmse: 1.58563 |  0:00:08s\n",
      "epoch 6  | loss: 6.76969 | val_0_rmse: 2.70544 | val_1_rmse: 2.56753 |  0:00:09s\n",
      "epoch 7  | loss: 5.72921 | val_0_rmse: 2.51361 | val_1_rmse: 3.0112  |  0:00:11s\n",
      "epoch 8  | loss: 4.5066  | val_0_rmse: 2.64596 | val_1_rmse: 2.58913 |  0:00:12s\n",
      "epoch 9  | loss: 3.58926 | val_0_rmse: 2.99923 | val_1_rmse: 3.31326 |  0:00:13s\n",
      "epoch 10 | loss: 3.07897 | val_0_rmse: 2.29184 | val_1_rmse: 1.91075 |  0:00:15s\n",
      "epoch 11 | loss: 2.42985 | val_0_rmse: 1.85462 | val_1_rmse: 1.5105  |  0:00:16s\n",
      "epoch 12 | loss: 1.89972 | val_0_rmse: 1.78382 | val_1_rmse: 1.52963 |  0:00:18s\n",
      "epoch 13 | loss: 1.60158 | val_0_rmse: 1.60662 | val_1_rmse: 1.2019  |  0:00:19s\n",
      "epoch 14 | loss: 1.38643 | val_0_rmse: 1.24327 | val_1_rmse: 1.39593 |  0:00:20s\n",
      "epoch 15 | loss: 1.17794 | val_0_rmse: 1.18434 | val_1_rmse: 1.09267 |  0:00:22s\n",
      "epoch 16 | loss: 1.06112 | val_0_rmse: 1.14685 | val_1_rmse: 1.11007 |  0:00:23s\n",
      "epoch 17 | loss: 0.93195 | val_0_rmse: 1.11567 | val_1_rmse: 1.02244 |  0:00:25s\n",
      "epoch 18 | loss: 0.80071 | val_0_rmse: 0.98291 | val_1_rmse: 0.95719 |  0:00:26s\n",
      "epoch 19 | loss: 0.72829 | val_0_rmse: 0.89097 | val_1_rmse: 0.8877  |  0:00:28s\n",
      "epoch 20 | loss: 0.6893  | val_0_rmse: 0.86742 | val_1_rmse: 0.90457 |  0:00:29s\n",
      "epoch 21 | loss: 0.6769  | val_0_rmse: 0.85862 | val_1_rmse: 0.89496 |  0:00:30s\n",
      "epoch 22 | loss: 0.67403 | val_0_rmse: 0.83225 | val_1_rmse: 0.82515 |  0:00:32s\n",
      "epoch 23 | loss: 0.67551 | val_0_rmse: 0.81319 | val_1_rmse: 0.80937 |  0:00:33s\n",
      "epoch 24 | loss: 0.67109 | val_0_rmse: 0.82638 | val_1_rmse: 0.81088 |  0:00:35s\n",
      "epoch 25 | loss: 0.75025 | val_0_rmse: 0.88454 | val_1_rmse: 0.90578 |  0:00:36s\n",
      "epoch 26 | loss: 0.66746 | val_0_rmse: 0.83194 | val_1_rmse: 0.83628 |  0:00:37s\n",
      "epoch 27 | loss: 0.68749 | val_0_rmse: 0.82563 | val_1_rmse: 0.81673 |  0:00:39s\n",
      "epoch 28 | loss: 0.65159 | val_0_rmse: 0.81216 | val_1_rmse: 0.87317 |  0:00:40s\n",
      "epoch 29 | loss: 0.63918 | val_0_rmse: 0.827   | val_1_rmse: 0.79617 |  0:00:42s\n",
      "epoch 30 | loss: 0.63555 | val_0_rmse: 0.82955 | val_1_rmse: 0.79605 |  0:00:43s\n",
      "epoch 31 | loss: 0.65538 | val_0_rmse: 0.81237 | val_1_rmse: 1.99813 |  0:00:45s\n",
      "epoch 32 | loss: 0.64106 | val_0_rmse: 0.84886 | val_1_rmse: 1.04731 |  0:00:46s\n",
      "epoch 33 | loss: 0.63788 | val_0_rmse: 0.81282 | val_1_rmse: 0.80087 |  0:00:47s\n",
      "epoch 34 | loss: 0.65575 | val_0_rmse: 0.9594  | val_1_rmse: 0.87429 |  0:00:49s\n",
      "epoch 35 | loss: 0.6562  | val_0_rmse: 0.96483 | val_1_rmse: 0.90843 |  0:00:50s\n",
      "epoch 36 | loss: 0.63179 | val_0_rmse: 0.87157 | val_1_rmse: 0.81699 |  0:00:51s\n",
      "epoch 37 | loss: 0.61805 | val_0_rmse: 0.84375 | val_1_rmse: 1.16708 |  0:00:53s\n",
      "epoch 38 | loss: 0.61463 | val_0_rmse: 0.78028 | val_1_rmse: 0.91563 |  0:00:54s\n",
      "epoch 39 | loss: 0.61806 | val_0_rmse: 0.85199 | val_1_rmse: 0.88607 |  0:00:56s\n",
      "epoch 40 | loss: 0.62936 | val_0_rmse: 0.79788 | val_1_rmse: 0.78652 |  0:00:57s\n",
      "epoch 41 | loss: 0.60553 | val_0_rmse: 0.78804 | val_1_rmse: 0.79334 |  0:00:58s\n",
      "epoch 42 | loss: 0.61989 | val_0_rmse: 0.80711 | val_1_rmse: 2.64168 |  0:01:00s\n",
      "epoch 43 | loss: 0.63092 | val_0_rmse: 0.79468 | val_1_rmse: 0.95177 |  0:01:01s\n",
      "epoch 44 | loss: 0.61855 | val_0_rmse: 0.79449 | val_1_rmse: 0.78958 |  0:01:03s\n",
      "epoch 45 | loss: 0.60321 | val_0_rmse: 0.80521 | val_1_rmse: 1.95612 |  0:01:04s\n",
      "epoch 46 | loss: 0.58089 | val_0_rmse: 0.81521 | val_1_rmse: 0.71717 |  0:01:05s\n",
      "epoch 47 | loss: 0.56944 | val_0_rmse: 0.79236 | val_1_rmse: 0.7883  |  0:01:07s\n",
      "epoch 48 | loss: 0.56068 | val_0_rmse: 0.81787 | val_1_rmse: 0.78763 |  0:01:08s\n",
      "epoch 49 | loss: 0.5413  | val_0_rmse: 0.75968 | val_1_rmse: 0.7087  |  0:01:09s\n",
      "epoch 50 | loss: 0.53258 | val_0_rmse: 0.78314 | val_1_rmse: 0.76805 |  0:01:11s\n",
      "epoch 51 | loss: 0.52258 | val_0_rmse: 0.8348  | val_1_rmse: 0.79954 |  0:01:12s\n",
      "epoch 52 | loss: 0.51245 | val_0_rmse: 0.73895 | val_1_rmse: 0.78545 |  0:01:14s\n",
      "epoch 53 | loss: 0.50515 | val_0_rmse: 0.81766 | val_1_rmse: 0.73567 |  0:01:15s\n",
      "epoch 54 | loss: 0.50024 | val_0_rmse: 0.83956 | val_1_rmse: 0.74253 |  0:01:17s\n",
      "epoch 55 | loss: 0.49269 | val_0_rmse: 0.70007 | val_1_rmse: 0.72791 |  0:01:18s\n",
      "epoch 56 | loss: 0.49497 | val_0_rmse: 0.72418 | val_1_rmse: 0.75289 |  0:01:19s\n",
      "epoch 57 | loss: 0.49117 | val_0_rmse: 0.80903 | val_1_rmse: 0.81132 |  0:01:21s\n",
      "epoch 58 | loss: 0.4868  | val_0_rmse: 0.71361 | val_1_rmse: 0.8808  |  0:01:22s\n",
      "epoch 59 | loss: 0.50164 | val_0_rmse: 0.77416 | val_1_rmse: 1.35333 |  0:01:24s\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 49 and best_val_1_rmse = 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 8, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.5771, Val Loss: 0.5023, RMSE: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.7546  | val_0_rmse: 1.14872 | val_1_rmse: 1.01592 |  0:00:00s\n",
      "epoch 1  | loss: 1.5981  | val_0_rmse: 1.28777 | val_1_rmse: 1.32412 |  0:00:01s\n",
      "epoch 2  | loss: 1.15118 | val_0_rmse: 2.12315 | val_1_rmse: 1.2392  |  0:00:01s\n",
      "epoch 3  | loss: 0.97135 | val_0_rmse: 1.3351  | val_1_rmse: 1.23228 |  0:00:02s\n",
      "epoch 4  | loss: 0.80785 | val_0_rmse: 1.16611 | val_1_rmse: 1.05809 |  0:00:03s\n",
      "epoch 5  | loss: 0.69631 | val_0_rmse: 0.91119 | val_1_rmse: 0.86306 |  0:00:03s\n",
      "epoch 6  | loss: 0.59754 | val_0_rmse: 0.76571 | val_1_rmse: 0.71172 |  0:00:04s\n",
      "epoch 7  | loss: 0.52171 | val_0_rmse: 0.7735  | val_1_rmse: 0.76057 |  0:00:05s\n",
      "epoch 8  | loss: 0.48879 | val_0_rmse: 0.71462 | val_1_rmse: 0.78819 |  0:00:05s\n",
      "epoch 9  | loss: 0.47435 | val_0_rmse: 0.69008 | val_1_rmse: 0.7568  |  0:00:06s\n",
      "epoch 10 | loss: 0.46487 | val_0_rmse: 0.67911 | val_1_rmse: 0.77193 |  0:00:07s\n",
      "epoch 11 | loss: 0.45978 | val_0_rmse: 0.68174 | val_1_rmse: 0.84504 |  0:00:07s\n",
      "epoch 12 | loss: 0.45393 | val_0_rmse: 0.69636 | val_1_rmse: 0.73094 |  0:00:08s\n",
      "epoch 13 | loss: 0.44931 | val_0_rmse: 0.70023 | val_1_rmse: 0.74626 |  0:00:08s\n",
      "epoch 14 | loss: 0.44677 | val_0_rmse: 0.69161 | val_1_rmse: 0.74097 |  0:00:09s\n",
      "epoch 15 | loss: 0.44444 | val_0_rmse: 0.68342 | val_1_rmse: 0.77473 |  0:00:10s\n",
      "epoch 16 | loss: 0.44536 | val_0_rmse: 0.67588 | val_1_rmse: 0.74012 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_1_rmse = 0.71172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.5863, Val Loss: 0.5065, RMSE: 0.7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.72832 | val_0_rmse: 0.98586 | val_1_rmse: 0.94597 |  0:00:00s\n",
      "epoch 1  | loss: 1.53944 | val_0_rmse: 1.53909 | val_1_rmse: 0.96702 |  0:00:01s\n",
      "epoch 2  | loss: 1.11713 | val_0_rmse: 1.05492 | val_1_rmse: 1.47442 |  0:00:01s\n",
      "epoch 3  | loss: 0.91718 | val_0_rmse: 1.37704 | val_1_rmse: 1.60519 |  0:00:02s\n",
      "epoch 4  | loss: 0.78978 | val_0_rmse: 1.05359 | val_1_rmse: 1.25995 |  0:00:03s\n",
      "epoch 5  | loss: 0.70532 | val_0_rmse: 1.05239 | val_1_rmse: 0.89312 |  0:00:03s\n",
      "epoch 6  | loss: 0.65556 | val_0_rmse: 0.81534 | val_1_rmse: 0.88529 |  0:00:04s\n",
      "epoch 7  | loss: 0.62595 | val_0_rmse: 0.79543 | val_1_rmse: 0.79545 |  0:00:05s\n",
      "epoch 8  | loss: 0.60162 | val_0_rmse: 0.76226 | val_1_rmse: 0.77276 |  0:00:05s\n",
      "epoch 9  | loss: 0.55651 | val_0_rmse: 0.7154  | val_1_rmse: 0.71834 |  0:00:06s\n",
      "epoch 10 | loss: 0.51268 | val_0_rmse: 0.69769 | val_1_rmse: 0.71168 |  0:00:06s\n",
      "epoch 11 | loss: 0.49056 | val_0_rmse: 0.71957 | val_1_rmse: 0.71342 |  0:00:07s\n",
      "epoch 12 | loss: 0.48101 | val_0_rmse: 0.69751 | val_1_rmse: 0.6904  |  0:00:08s\n",
      "epoch 13 | loss: 0.47303 | val_0_rmse: 0.67768 | val_1_rmse: 0.70018 |  0:00:08s\n",
      "epoch 14 | loss: 0.46823 | val_0_rmse: 0.67277 | val_1_rmse: 0.67222 |  0:00:09s\n",
      "epoch 15 | loss: 0.46251 | val_0_rmse: 0.66789 | val_1_rmse: 0.66926 |  0:00:09s\n",
      "epoch 16 | loss: 0.46079 | val_0_rmse: 0.66662 | val_1_rmse: 0.66594 |  0:00:10s\n",
      "epoch 17 | loss: 0.45493 | val_0_rmse: 0.66436 | val_1_rmse: 0.66542 |  0:00:11s\n",
      "epoch 18 | loss: 0.45356 | val_0_rmse: 0.66212 | val_1_rmse: 0.66442 |  0:00:11s\n",
      "epoch 19 | loss: 0.44963 | val_0_rmse: 0.66101 | val_1_rmse: 0.66112 |  0:00:12s\n",
      "epoch 20 | loss: 0.44914 | val_0_rmse: 0.66101 | val_1_rmse: 0.66384 |  0:00:12s\n",
      "epoch 21 | loss: 0.44709 | val_0_rmse: 0.66203 | val_1_rmse: 0.66413 |  0:00:13s\n",
      "epoch 22 | loss: 0.44661 | val_0_rmse: 0.65779 | val_1_rmse: 0.65918 |  0:00:14s\n",
      "epoch 23 | loss: 0.44249 | val_0_rmse: 0.65706 | val_1_rmse: 0.65841 |  0:00:14s\n",
      "epoch 24 | loss: 0.44275 | val_0_rmse: 0.65644 | val_1_rmse: 0.65599 |  0:00:15s\n",
      "epoch 25 | loss: 0.43919 | val_0_rmse: 0.65535 | val_1_rmse: 0.65328 |  0:00:15s\n",
      "epoch 26 | loss: 0.43753 | val_0_rmse: 0.65516 | val_1_rmse: 0.65453 |  0:00:16s\n",
      "epoch 27 | loss: 0.43535 | val_0_rmse: 0.65469 | val_1_rmse: 0.6539  |  0:00:17s\n",
      "epoch 28 | loss: 0.43683 | val_0_rmse: 0.65705 | val_1_rmse: 0.65714 |  0:00:17s\n",
      "epoch 29 | loss: 0.43807 | val_0_rmse: 0.65796 | val_1_rmse: 0.6632  |  0:00:18s\n",
      "epoch 30 | loss: 0.43658 | val_0_rmse: 0.65378 | val_1_rmse: 0.65723 |  0:00:18s\n",
      "epoch 31 | loss: 0.43364 | val_0_rmse: 0.65235 | val_1_rmse: 0.65435 |  0:00:19s\n",
      "epoch 32 | loss: 0.43271 | val_0_rmse: 0.65124 | val_1_rmse: 0.65415 |  0:00:19s\n",
      "epoch 33 | loss: 0.43003 | val_0_rmse: 0.65012 | val_1_rmse: 0.65181 |  0:00:20s\n",
      "epoch 34 | loss: 0.43236 | val_0_rmse: 0.65227 | val_1_rmse: 0.65523 |  0:00:21s\n",
      "epoch 35 | loss: 0.43155 | val_0_rmse: 0.65117 | val_1_rmse: 0.65055 |  0:00:21s\n",
      "epoch 36 | loss: 0.43011 | val_0_rmse: 0.6506  | val_1_rmse: 0.64714 |  0:00:22s\n",
      "epoch 37 | loss: 0.42834 | val_0_rmse: 0.6497  | val_1_rmse: 0.64962 |  0:00:22s\n",
      "epoch 38 | loss: 0.42839 | val_0_rmse: 0.64958 | val_1_rmse: 0.64945 |  0:00:23s\n",
      "epoch 39 | loss: 0.42769 | val_0_rmse: 0.64949 | val_1_rmse: 0.64586 |  0:00:24s\n",
      "epoch 40 | loss: 0.42901 | val_0_rmse: 0.65004 | val_1_rmse: 0.64482 |  0:00:24s\n",
      "epoch 41 | loss: 0.42765 | val_0_rmse: 0.65177 | val_1_rmse: 0.64753 |  0:00:25s\n",
      "epoch 42 | loss: 0.42549 | val_0_rmse: 0.64886 | val_1_rmse: 0.64466 |  0:00:25s\n",
      "epoch 43 | loss: 0.42681 | val_0_rmse: 0.64959 | val_1_rmse: 0.64483 |  0:00:26s\n",
      "epoch 44 | loss: 0.42604 | val_0_rmse: 0.64975 | val_1_rmse: 0.64514 |  0:00:27s\n",
      "epoch 45 | loss: 0.42679 | val_0_rmse: 0.64866 | val_1_rmse: 0.64387 |  0:00:27s\n",
      "epoch 46 | loss: 0.42708 | val_0_rmse: 0.64755 | val_1_rmse: 0.64298 |  0:00:28s\n",
      "epoch 47 | loss: 0.42534 | val_0_rmse: 0.64783 | val_1_rmse: 0.64287 |  0:00:28s\n",
      "epoch 48 | loss: 0.42467 | val_0_rmse: 0.6476  | val_1_rmse: 0.64258 |  0:00:29s\n",
      "epoch 49 | loss: 0.42476 | val_0_rmse: 0.64762 | val_1_rmse: 0.64307 |  0:00:29s\n",
      "epoch 50 | loss: 0.42503 | val_0_rmse: 0.64758 | val_1_rmse: 0.64557 |  0:00:30s\n",
      "epoch 51 | loss: 0.42387 | val_0_rmse: 0.64753 | val_1_rmse: 0.64582 |  0:00:31s\n",
      "epoch 52 | loss: 0.42551 | val_0_rmse: 0.65067 | val_1_rmse: 0.64501 |  0:00:31s\n",
      "epoch 53 | loss: 0.4241  | val_0_rmse: 0.65061 | val_1_rmse: 0.64257 |  0:00:32s\n",
      "epoch 54 | loss: 0.42315 | val_0_rmse: 0.64947 | val_1_rmse: 0.64496 |  0:00:32s\n",
      "epoch 55 | loss: 0.42352 | val_0_rmse: 0.64513 | val_1_rmse: 0.64163 |  0:00:33s\n",
      "epoch 56 | loss: 0.42407 | val_0_rmse: 0.64549 | val_1_rmse: 0.64309 |  0:00:33s\n",
      "epoch 57 | loss: 0.42216 | val_0_rmse: 0.64535 | val_1_rmse: 0.64121 |  0:00:34s\n",
      "epoch 58 | loss: 0.42092 | val_0_rmse: 0.64604 | val_1_rmse: 0.64193 |  0:00:35s\n",
      "epoch 59 | loss: 0.42134 | val_0_rmse: 0.64582 | val_1_rmse: 0.64205 |  0:00:35s\n",
      "epoch 60 | loss: 0.42048 | val_0_rmse: 0.64521 | val_1_rmse: 0.64165 |  0:00:36s\n",
      "epoch 61 | loss: 0.42115 | val_0_rmse: 0.64508 | val_1_rmse: 0.64159 |  0:00:36s\n",
      "epoch 62 | loss: 0.42052 | val_0_rmse: 0.64536 | val_1_rmse: 0.64109 |  0:00:37s\n",
      "epoch 63 | loss: 0.41933 | val_0_rmse: 0.64586 | val_1_rmse: 0.64266 |  0:00:38s\n",
      "epoch 64 | loss: 0.41871 | val_0_rmse: 0.64538 | val_1_rmse: 0.64212 |  0:00:38s\n",
      "epoch 65 | loss: 0.41954 | val_0_rmse: 0.64571 | val_1_rmse: 0.6435  |  0:00:39s\n",
      "epoch 66 | loss: 0.41954 | val_0_rmse: 0.6459  | val_1_rmse: 0.64377 |  0:00:39s\n",
      "epoch 67 | loss: 0.41892 | val_0_rmse: 0.64423 | val_1_rmse: 0.64251 |  0:00:40s\n",
      "epoch 68 | loss: 0.41874 | val_0_rmse: 0.64458 | val_1_rmse: 0.64319 |  0:00:40s\n",
      "epoch 69 | loss: 0.41674 | val_0_rmse: 0.64427 | val_1_rmse: 0.64453 |  0:00:41s\n",
      "epoch 70 | loss: 0.41734 | val_0_rmse: 0.64243 | val_1_rmse: 0.64086 |  0:00:42s\n",
      "epoch 71 | loss: 0.41684 | val_0_rmse: 0.6429  | val_1_rmse: 0.64518 |  0:00:42s\n",
      "epoch 72 | loss: 0.41752 | val_0_rmse: 0.64566 | val_1_rmse: 0.64562 |  0:00:43s\n",
      "epoch 73 | loss: 0.41712 | val_0_rmse: 0.64209 | val_1_rmse: 0.6414  |  0:00:43s\n",
      "epoch 74 | loss: 0.41477 | val_0_rmse: 0.64298 | val_1_rmse: 0.64329 |  0:00:44s\n",
      "epoch 75 | loss: 0.41778 | val_0_rmse: 0.64448 | val_1_rmse: 0.6425  |  0:00:44s\n",
      "epoch 76 | loss: 0.41535 | val_0_rmse: 0.64214 | val_1_rmse: 0.64307 |  0:00:45s\n",
      "epoch 77 | loss: 0.41633 | val_0_rmse: 0.64484 | val_1_rmse: 0.64412 |  0:00:46s\n",
      "epoch 78 | loss: 0.41503 | val_0_rmse: 0.64255 | val_1_rmse: 0.63984 |  0:00:46s\n",
      "epoch 79 | loss: 0.41492 | val_0_rmse: 0.64238 | val_1_rmse: 0.64207 |  0:00:47s\n",
      "epoch 80 | loss: 0.41411 | val_0_rmse: 0.64546 | val_1_rmse: 0.64034 |  0:00:47s\n",
      "epoch 81 | loss: 0.41474 | val_0_rmse: 0.64595 | val_1_rmse: 0.6418  |  0:00:48s\n",
      "epoch 82 | loss: 0.4142  | val_0_rmse: 0.64688 | val_1_rmse: 0.64491 |  0:00:49s\n",
      "epoch 83 | loss: 0.41431 | val_0_rmse: 0.64812 | val_1_rmse: 0.65156 |  0:00:49s\n",
      "epoch 84 | loss: 0.4151  | val_0_rmse: 0.64276 | val_1_rmse: 0.64286 |  0:00:50s\n",
      "epoch 85 | loss: 0.41502 | val_0_rmse: 0.6418  | val_1_rmse: 0.64195 |  0:00:50s\n",
      "epoch 86 | loss: 0.41343 | val_0_rmse: 0.64073 | val_1_rmse: 0.6394  |  0:00:51s\n",
      "epoch 87 | loss: 0.4128  | val_0_rmse: 0.64277 | val_1_rmse: 0.6446  |  0:00:51s\n",
      "epoch 88 | loss: 0.41414 | val_0_rmse: 0.64555 | val_1_rmse: 0.64208 |  0:00:52s\n",
      "epoch 89 | loss: 0.41406 | val_0_rmse: 0.64333 | val_1_rmse: 0.64146 |  0:00:53s\n",
      "epoch 90 | loss: 0.41292 | val_0_rmse: 0.64339 | val_1_rmse: 0.64177 |  0:00:53s\n",
      "epoch 91 | loss: 0.41446 | val_0_rmse: 0.65235 | val_1_rmse: 0.64352 |  0:00:54s\n",
      "epoch 92 | loss: 0.41334 | val_0_rmse: 0.64823 | val_1_rmse: 0.64093 |  0:00:54s\n",
      "epoch 93 | loss: 0.41299 | val_0_rmse: 0.64629 | val_1_rmse: 0.64086 |  0:00:55s\n",
      "epoch 94 | loss: 0.4139  | val_0_rmse: 0.64556 | val_1_rmse: 0.64199 |  0:00:55s\n",
      "epoch 95 | loss: 0.41192 | val_0_rmse: 0.64756 | val_1_rmse: 0.63948 |  0:00:56s\n",
      "epoch 96 | loss: 0.41171 | val_0_rmse: 0.64483 | val_1_rmse: 0.64979 |  0:00:57s\n",
      "\n",
      "Early stopping occurred at epoch 96 with best_epoch = 86 and best_val_1_rmse = 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4105, Val Loss: 0.4088, RMSE: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.60947 | val_0_rmse: 0.95506 | val_1_rmse: 0.95669 |  0:00:00s\n",
      "epoch 1  | loss: 2.57405 | val_0_rmse: 1.05103 | val_1_rmse: 1.08654 |  0:00:01s\n",
      "epoch 2  | loss: 1.85286 | val_0_rmse: 1.46217 | val_1_rmse: 1.51085 |  0:00:02s\n",
      "epoch 3  | loss: 1.44227 | val_0_rmse: 2.05827 | val_1_rmse: 1.97803 |  0:00:03s\n",
      "epoch 4  | loss: 1.14652 | val_0_rmse: 1.26612 | val_1_rmse: 1.20973 |  0:00:04s\n",
      "epoch 5  | loss: 0.92958 | val_0_rmse: 0.95539 | val_1_rmse: 0.94962 |  0:00:04s\n",
      "epoch 6  | loss: 0.78619 | val_0_rmse: 0.99234 | val_1_rmse: 0.84175 |  0:00:05s\n",
      "epoch 7  | loss: 0.70818 | val_0_rmse: 0.82115 | val_1_rmse: 0.80849 |  0:00:06s\n",
      "epoch 8  | loss: 0.66329 | val_0_rmse: 0.81074 | val_1_rmse: 0.79233 |  0:00:07s\n",
      "epoch 9  | loss: 0.63173 | val_0_rmse: 0.78607 | val_1_rmse: 0.77839 |  0:00:08s\n",
      "epoch 10 | loss: 0.6148  | val_0_rmse: 0.80822 | val_1_rmse: 0.78283 |  0:00:08s\n",
      "epoch 11 | loss: 0.6014  | val_0_rmse: 0.8063  | val_1_rmse: 0.77854 |  0:00:09s\n",
      "epoch 12 | loss: 0.59788 | val_0_rmse: 0.78609 | val_1_rmse: 0.76444 |  0:00:10s\n",
      "epoch 13 | loss: 0.5967  | val_0_rmse: 0.78429 | val_1_rmse: 0.81323 |  0:00:11s\n",
      "epoch 14 | loss: 0.5932  | val_0_rmse: 0.77328 | val_1_rmse: 0.80316 |  0:00:12s\n",
      "epoch 15 | loss: 0.59408 | val_0_rmse: 0.77421 | val_1_rmse: 0.79197 |  0:00:12s\n",
      "epoch 16 | loss: 0.59049 | val_0_rmse: 0.77839 | val_1_rmse: 0.77603 |  0:00:13s\n",
      "epoch 17 | loss: 0.58844 | val_0_rmse: 0.76681 | val_1_rmse: 0.81773 |  0:00:14s\n",
      "epoch 18 | loss: 0.58075 | val_0_rmse: 0.76833 | val_1_rmse: 0.77042 |  0:00:15s\n",
      "epoch 19 | loss: 0.57809 | val_0_rmse: 0.76212 | val_1_rmse: 0.80807 |  0:00:16s\n",
      "epoch 20 | loss: 0.57859 | val_0_rmse: 0.76372 | val_1_rmse: 0.77369 |  0:00:16s\n",
      "epoch 21 | loss: 0.57305 | val_0_rmse: 0.75702 | val_1_rmse: 0.81297 |  0:00:17s\n",
      "epoch 22 | loss: 0.56678 | val_0_rmse: 0.75536 | val_1_rmse: 0.75401 |  0:00:18s\n",
      "epoch 23 | loss: 0.56461 | val_0_rmse: 0.75611 | val_1_rmse: 0.74289 |  0:00:19s\n",
      "epoch 24 | loss: 0.56436 | val_0_rmse: 0.75118 | val_1_rmse: 0.7452  |  0:00:20s\n",
      "epoch 25 | loss: 0.5613  | val_0_rmse: 0.75492 | val_1_rmse: 0.76802 |  0:00:20s\n",
      "epoch 26 | loss: 0.55916 | val_0_rmse: 0.75149 | val_1_rmse: 0.77635 |  0:00:21s\n",
      "epoch 27 | loss: 0.55622 | val_0_rmse: 0.74449 | val_1_rmse: 0.7419  |  0:00:22s\n",
      "epoch 28 | loss: 0.55602 | val_0_rmse: 0.74559 | val_1_rmse: 0.74531 |  0:00:23s\n",
      "epoch 29 | loss: 0.55305 | val_0_rmse: 0.75093 | val_1_rmse: 0.74091 |  0:00:24s\n",
      "epoch 30 | loss: 0.55023 | val_0_rmse: 0.74271 | val_1_rmse: 0.73902 |  0:00:24s\n",
      "epoch 31 | loss: 0.54711 | val_0_rmse: 0.74026 | val_1_rmse: 0.88274 |  0:00:25s\n",
      "epoch 32 | loss: 0.54264 | val_0_rmse: 0.73973 | val_1_rmse: 0.77097 |  0:00:26s\n",
      "epoch 33 | loss: 0.5388  | val_0_rmse: 0.7399  | val_1_rmse: 0.77778 |  0:00:27s\n",
      "epoch 34 | loss: 0.53743 | val_0_rmse: 0.73804 | val_1_rmse: 0.77147 |  0:00:28s\n",
      "epoch 35 | loss: 0.53381 | val_0_rmse: 0.73487 | val_1_rmse: 0.77123 |  0:00:29s\n",
      "epoch 36 | loss: 0.53068 | val_0_rmse: 0.73825 | val_1_rmse: 0.73648 |  0:00:29s\n",
      "epoch 37 | loss: 0.52696 | val_0_rmse: 0.73417 | val_1_rmse: 0.7295  |  0:00:30s\n",
      "epoch 38 | loss: 0.52207 | val_0_rmse: 0.73078 | val_1_rmse: 0.72735 |  0:00:31s\n",
      "epoch 39 | loss: 0.51411 | val_0_rmse: 0.72536 | val_1_rmse: 0.7208  |  0:00:32s\n",
      "epoch 40 | loss: 0.50334 | val_0_rmse: 0.71511 | val_1_rmse: 0.71249 |  0:00:33s\n",
      "epoch 41 | loss: 0.49321 | val_0_rmse: 0.71017 | val_1_rmse: 0.70635 |  0:00:33s\n",
      "epoch 42 | loss: 0.48289 | val_0_rmse: 0.69743 | val_1_rmse: 0.69114 |  0:00:34s\n",
      "epoch 43 | loss: 0.47231 | val_0_rmse: 0.68567 | val_1_rmse: 0.69159 |  0:00:35s\n",
      "epoch 44 | loss: 0.45854 | val_0_rmse: 0.6747  | val_1_rmse: 0.66627 |  0:00:36s\n",
      "epoch 45 | loss: 0.45126 | val_0_rmse: 0.67638 | val_1_rmse: 0.66351 |  0:00:37s\n",
      "epoch 46 | loss: 0.44366 | val_0_rmse: 0.67253 | val_1_rmse: 0.66188 |  0:00:38s\n",
      "epoch 47 | loss: 0.44137 | val_0_rmse: 0.66615 | val_1_rmse: 0.66234 |  0:00:38s\n",
      "epoch 48 | loss: 0.43781 | val_0_rmse: 0.66414 | val_1_rmse: 0.65923 |  0:00:39s\n",
      "epoch 49 | loss: 0.43719 | val_0_rmse: 0.6637  | val_1_rmse: 0.6655  |  0:00:40s\n",
      "epoch 50 | loss: 0.43727 | val_0_rmse: 0.66027 | val_1_rmse: 0.65764 |  0:00:41s\n",
      "epoch 51 | loss: 0.43647 | val_0_rmse: 0.66096 | val_1_rmse: 0.66724 |  0:00:42s\n",
      "epoch 52 | loss: 0.43394 | val_0_rmse: 0.66087 | val_1_rmse: 0.65687 |  0:00:42s\n",
      "epoch 53 | loss: 0.43184 | val_0_rmse: 0.66095 | val_1_rmse: 0.65623 |  0:00:43s\n",
      "epoch 54 | loss: 0.43336 | val_0_rmse: 0.6583  | val_1_rmse: 0.65398 |  0:00:44s\n",
      "epoch 55 | loss: 0.43121 | val_0_rmse: 0.65675 | val_1_rmse: 0.65464 |  0:00:45s\n",
      "epoch 56 | loss: 0.43128 | val_0_rmse: 0.65581 | val_1_rmse: 0.65934 |  0:00:46s\n",
      "epoch 57 | loss: 0.43075 | val_0_rmse: 0.65655 | val_1_rmse: 0.66059 |  0:00:46s\n",
      "epoch 58 | loss: 0.42962 | val_0_rmse: 0.65581 | val_1_rmse: 0.66159 |  0:00:47s\n",
      "epoch 59 | loss: 0.42921 | val_0_rmse: 0.65506 | val_1_rmse: 0.65718 |  0:00:48s\n",
      "epoch 60 | loss: 0.42796 | val_0_rmse: 0.65735 | val_1_rmse: 0.65396 |  0:00:49s\n",
      "epoch 61 | loss: 0.42946 | val_0_rmse: 0.65701 | val_1_rmse: 0.65511 |  0:00:50s\n",
      "epoch 62 | loss: 0.42706 | val_0_rmse: 0.6553  | val_1_rmse: 0.65247 |  0:00:50s\n",
      "epoch 63 | loss: 0.42772 | val_0_rmse: 0.65378 | val_1_rmse: 0.65305 |  0:00:51s\n",
      "epoch 64 | loss: 0.42656 | val_0_rmse: 0.65413 | val_1_rmse: 0.65669 |  0:00:52s\n",
      "epoch 65 | loss: 0.42774 | val_0_rmse: 0.6555  | val_1_rmse: 0.66127 |  0:00:53s\n",
      "epoch 66 | loss: 0.42632 | val_0_rmse: 0.65514 | val_1_rmse: 0.68429 |  0:00:54s\n",
      "epoch 67 | loss: 0.42764 | val_0_rmse: 0.65657 | val_1_rmse: 0.69724 |  0:00:54s\n",
      "epoch 68 | loss: 0.42724 | val_0_rmse: 0.6557  | val_1_rmse: 0.78963 |  0:00:55s\n",
      "epoch 69 | loss: 0.42699 | val_0_rmse: 0.65344 | val_1_rmse: 0.75281 |  0:00:56s\n",
      "epoch 70 | loss: 0.42833 | val_0_rmse: 0.6551  | val_1_rmse: 0.65702 |  0:00:57s\n",
      "epoch 71 | loss: 0.42621 | val_0_rmse: 0.65345 | val_1_rmse: 0.65856 |  0:00:58s\n",
      "epoch 72 | loss: 0.42581 | val_0_rmse: 0.6576  | val_1_rmse: 0.70914 |  0:00:58s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_1_rmse = 0.65247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4294, Val Loss: 0.4257, RMSE: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.55477 | val_0_rmse: 0.98009 | val_1_rmse: 0.94323 |  0:00:00s\n",
      "epoch 1  | loss: 2.51207 | val_0_rmse: 1.09873 | val_1_rmse: 0.95512 |  0:00:01s\n",
      "epoch 2  | loss: 1.80688 | val_0_rmse: 1.5054  | val_1_rmse: 1.21918 |  0:00:02s\n",
      "epoch 3  | loss: 1.41913 | val_0_rmse: 1.22595 | val_1_rmse: 1.36233 |  0:00:03s\n",
      "epoch 4  | loss: 1.12409 | val_0_rmse: 1.18927 | val_1_rmse: 1.17261 |  0:00:04s\n",
      "epoch 5  | loss: 0.91584 | val_0_rmse: 0.96323 | val_1_rmse: 1.06519 |  0:00:04s\n",
      "epoch 6  | loss: 0.77433 | val_0_rmse: 0.95497 | val_1_rmse: 1.12338 |  0:00:05s\n",
      "epoch 7  | loss: 0.69969 | val_0_rmse: 0.85123 | val_1_rmse: 0.88757 |  0:00:06s\n",
      "epoch 8  | loss: 0.65325 | val_0_rmse: 0.81484 | val_1_rmse: 0.8491  |  0:00:07s\n",
      "epoch 9  | loss: 0.62622 | val_0_rmse: 0.79202 | val_1_rmse: 0.80384 |  0:00:08s\n",
      "epoch 10 | loss: 0.61758 | val_0_rmse: 0.78285 | val_1_rmse: 0.7852  |  0:00:08s\n",
      "epoch 11 | loss: 0.60267 | val_0_rmse: 0.78779 | val_1_rmse: 0.79439 |  0:00:09s\n",
      "epoch 12 | loss: 0.59911 | val_0_rmse: 0.77841 | val_1_rmse: 0.78073 |  0:00:10s\n",
      "epoch 13 | loss: 0.59609 | val_0_rmse: 0.76871 | val_1_rmse: 0.76657 |  0:00:11s\n",
      "epoch 14 | loss: 0.59066 | val_0_rmse: 0.76717 | val_1_rmse: 0.85472 |  0:00:12s\n",
      "epoch 15 | loss: 0.58791 | val_0_rmse: 0.77984 | val_1_rmse: 0.84824 |  0:00:13s\n",
      "epoch 16 | loss: 0.58042 | val_0_rmse: 0.7683  | val_1_rmse: 1.21993 |  0:00:13s\n",
      "epoch 17 | loss: 0.57948 | val_0_rmse: 0.78081 | val_1_rmse: 1.09523 |  0:00:14s\n",
      "epoch 18 | loss: 0.58086 | val_0_rmse: 0.77097 | val_1_rmse: 1.28962 |  0:00:15s\n",
      "epoch 19 | loss: 0.57684 | val_0_rmse: 0.76756 | val_1_rmse: 0.80434 |  0:00:16s\n",
      "epoch 20 | loss: 0.56986 | val_0_rmse: 0.76248 | val_1_rmse: 0.80803 |  0:00:17s\n",
      "epoch 21 | loss: 0.56867 | val_0_rmse: 0.76132 | val_1_rmse: 1.33725 |  0:00:17s\n",
      "epoch 22 | loss: 0.56727 | val_0_rmse: 0.76061 | val_1_rmse: 1.15022 |  0:00:18s\n",
      "epoch 23 | loss: 0.56876 | val_0_rmse: 0.76336 | val_1_rmse: 0.9642  |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_1_rmse = 0.76657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.5909, Val Loss: 0.5876, RMSE: 0.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 14.67555| val_0_rmse: 1.39291 | val_1_rmse: 3.73376 |  0:00:01s\n",
      "epoch 1  | loss: 13.87187| val_0_rmse: 1.61761 | val_1_rmse: 4.83244 |  0:00:02s\n",
      "epoch 2  | loss: 12.6298 | val_0_rmse: 4.19301 | val_1_rmse: 1.88416 |  0:00:04s\n",
      "epoch 3  | loss: 11.33121| val_0_rmse: 4.24872 | val_1_rmse: 2.92066 |  0:00:05s\n",
      "epoch 4  | loss: 9.6303  | val_0_rmse: 3.54714 | val_1_rmse: 3.02843 |  0:00:06s\n",
      "epoch 5  | loss: 7.73928 | val_0_rmse: 3.19302 | val_1_rmse: 3.91581 |  0:00:08s\n",
      "epoch 6  | loss: 6.25502 | val_0_rmse: 3.0838  | val_1_rmse: 3.02085 |  0:00:09s\n",
      "epoch 7  | loss: 5.40137 | val_0_rmse: 2.68241 | val_1_rmse: 5.62654 |  0:00:10s\n",
      "epoch 8  | loss: 4.89971 | val_0_rmse: 3.41847 | val_1_rmse: 11.21821|  0:00:12s\n",
      "epoch 9  | loss: 4.43331 | val_0_rmse: 2.84181 | val_1_rmse: 5.67545 |  0:00:13s\n",
      "epoch 10 | loss: 3.92189 | val_0_rmse: 2.78493 | val_1_rmse: 3.23971 |  0:00:15s\n",
      "epoch 11 | loss: 3.31706 | val_0_rmse: 2.76635 | val_1_rmse: 2.00089 |  0:00:16s\n",
      "epoch 12 | loss: 2.81984 | val_0_rmse: 1.68742 | val_1_rmse: 3.00147 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_1_rmse = 1.88416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 17.5814, Val Loss: 3.5501, RMSE: 1.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 14.37893| val_0_rmse: 1.52948 | val_1_rmse: 1.41156 |  0:00:01s\n",
      "epoch 1  | loss: 13.65628| val_0_rmse: 1.98817 | val_1_rmse: 5.8446  |  0:00:02s\n",
      "epoch 2  | loss: 12.1445 | val_0_rmse: 4.41968 | val_1_rmse: 8.21849 |  0:00:04s\n",
      "epoch 3  | loss: 10.49154| val_0_rmse: 5.07824 | val_1_rmse: 2.04429 |  0:00:05s\n",
      "epoch 4  | loss: 9.23228 | val_0_rmse: 3.38338 | val_1_rmse: 2.26184 |  0:00:06s\n",
      "epoch 5  | loss: 7.45898 | val_0_rmse: 5.30741 | val_1_rmse: 2.34191 |  0:00:08s\n",
      "epoch 6  | loss: 6.08338 | val_0_rmse: 2.84393 | val_1_rmse: 5.60943 |  0:00:09s\n",
      "epoch 7  | loss: 5.10575 | val_0_rmse: 3.12365 | val_1_rmse: 8.04816 |  0:00:11s\n",
      "epoch 8  | loss: 4.68448 | val_0_rmse: 4.21229 | val_1_rmse: 7.31198 |  0:00:12s\n",
      "epoch 9  | loss: 4.392   | val_0_rmse: 3.38427 | val_1_rmse: 7.12738 |  0:00:13s\n",
      "epoch 10 | loss: 3.73971 | val_0_rmse: 3.05631 | val_1_rmse: 5.19906 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.41156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 2.3393, Val Loss: 1.9925, RMSE: 1.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.95486 | val_0_rmse: 1.10058 | val_1_rmse: 0.94312 |  0:00:00s\n",
      "epoch 1  | loss: 1.73371 | val_0_rmse: 0.99953 | val_1_rmse: 0.98077 |  0:00:01s\n",
      "epoch 2  | loss: 1.26248 | val_0_rmse: 1.086   | val_1_rmse: 0.92371 |  0:00:01s\n",
      "epoch 3  | loss: 1.03161 | val_0_rmse: 1.09934 | val_1_rmse: 1.14556 |  0:00:02s\n",
      "epoch 4  | loss: 0.84045 | val_0_rmse: 0.9455  | val_1_rmse: 1.47055 |  0:00:02s\n",
      "epoch 5  | loss: 0.70623 | val_0_rmse: 0.86209 | val_1_rmse: 1.14111 |  0:00:03s\n",
      "epoch 6  | loss: 0.60087 | val_0_rmse: 0.77224 | val_1_rmse: 0.75865 |  0:00:04s\n",
      "epoch 7  | loss: 0.52436 | val_0_rmse: 0.72255 | val_1_rmse: 0.72189 |  0:00:04s\n",
      "epoch 8  | loss: 0.49293 | val_0_rmse: 0.70331 | val_1_rmse: 0.69608 |  0:00:05s\n",
      "epoch 9  | loss: 0.47776 | val_0_rmse: 0.68171 | val_1_rmse: 0.6799  |  0:00:05s\n",
      "epoch 10 | loss: 0.46582 | val_0_rmse: 0.68053 | val_1_rmse: 0.67792 |  0:00:06s\n",
      "epoch 11 | loss: 0.46179 | val_0_rmse: 0.67783 | val_1_rmse: 0.67458 |  0:00:07s\n",
      "epoch 12 | loss: 0.45954 | val_0_rmse: 0.67631 | val_1_rmse: 0.67239 |  0:00:07s\n",
      "epoch 13 | loss: 0.45486 | val_0_rmse: 0.67391 | val_1_rmse: 0.66913 |  0:00:08s\n",
      "epoch 14 | loss: 0.45465 | val_0_rmse: 0.67121 | val_1_rmse: 0.66686 |  0:00:08s\n",
      "epoch 15 | loss: 0.45038 | val_0_rmse: 0.67042 | val_1_rmse: 0.66669 |  0:00:09s\n",
      "epoch 16 | loss: 0.44976 | val_0_rmse: 0.66994 | val_1_rmse: 0.66562 |  0:00:10s\n",
      "epoch 17 | loss: 0.44864 | val_0_rmse: 0.67122 | val_1_rmse: 0.6657  |  0:00:10s\n",
      "epoch 18 | loss: 0.44669 | val_0_rmse: 0.67195 | val_1_rmse: 0.66429 |  0:00:11s\n",
      "epoch 19 | loss: 0.44519 | val_0_rmse: 0.66694 | val_1_rmse: 0.66234 |  0:00:11s\n",
      "epoch 20 | loss: 0.44187 | val_0_rmse: 0.66632 | val_1_rmse: 0.66414 |  0:00:12s\n",
      "epoch 21 | loss: 0.44309 | val_0_rmse: 0.66196 | val_1_rmse: 0.65901 |  0:00:12s\n",
      "epoch 22 | loss: 0.43935 | val_0_rmse: 0.66119 | val_1_rmse: 0.65804 |  0:00:13s\n",
      "epoch 23 | loss: 0.43836 | val_0_rmse: 0.66657 | val_1_rmse: 0.65563 |  0:00:14s\n",
      "epoch 24 | loss: 0.43734 | val_0_rmse: 0.66712 | val_1_rmse: 0.6542  |  0:00:14s\n",
      "epoch 25 | loss: 0.43384 | val_0_rmse: 0.66637 | val_1_rmse: 0.65463 |  0:00:15s\n",
      "epoch 26 | loss: 0.43412 | val_0_rmse: 0.66404 | val_1_rmse: 0.65352 |  0:00:15s\n",
      "epoch 27 | loss: 0.43251 | val_0_rmse: 0.65831 | val_1_rmse: 0.65461 |  0:00:16s\n",
      "epoch 28 | loss: 0.43297 | val_0_rmse: 0.65921 | val_1_rmse: 0.6572  |  0:00:17s\n",
      "epoch 29 | loss: 0.43149 | val_0_rmse: 0.65651 | val_1_rmse: 0.65403 |  0:00:17s\n",
      "epoch 30 | loss: 0.43022 | val_0_rmse: 0.6541  | val_1_rmse: 0.65114 |  0:00:18s\n",
      "epoch 31 | loss: 0.42973 | val_0_rmse: 0.65865 | val_1_rmse: 0.65563 |  0:00:18s\n",
      "epoch 32 | loss: 0.42973 | val_0_rmse: 0.6539  | val_1_rmse: 0.65181 |  0:00:19s\n",
      "epoch 33 | loss: 0.42821 | val_0_rmse: 0.65328 | val_1_rmse: 0.65099 |  0:00:20s\n",
      "epoch 34 | loss: 0.4281  | val_0_rmse: 0.66352 | val_1_rmse: 0.6524  |  0:00:20s\n",
      "epoch 35 | loss: 0.42781 | val_0_rmse: 0.66231 | val_1_rmse: 0.64939 |  0:00:21s\n",
      "epoch 36 | loss: 0.42665 | val_0_rmse: 0.65327 | val_1_rmse: 0.64859 |  0:00:21s\n",
      "epoch 37 | loss: 0.42657 | val_0_rmse: 0.65277 | val_1_rmse: 0.64829 |  0:00:22s\n",
      "epoch 38 | loss: 0.42482 | val_0_rmse: 0.65034 | val_1_rmse: 0.64879 |  0:00:23s\n",
      "epoch 39 | loss: 0.42387 | val_0_rmse: 0.64853 | val_1_rmse: 0.64679 |  0:00:23s\n",
      "epoch 40 | loss: 0.42486 | val_0_rmse: 0.65004 | val_1_rmse: 0.64891 |  0:00:24s\n",
      "epoch 41 | loss: 0.42353 | val_0_rmse: 0.65118 | val_1_rmse: 0.65095 |  0:00:24s\n",
      "epoch 42 | loss: 0.42303 | val_0_rmse: 0.64858 | val_1_rmse: 0.64782 |  0:00:25s\n",
      "epoch 43 | loss: 0.42259 | val_0_rmse: 0.64917 | val_1_rmse: 0.64857 |  0:00:25s\n",
      "epoch 44 | loss: 0.42188 | val_0_rmse: 0.64858 | val_1_rmse: 0.64867 |  0:00:26s\n",
      "epoch 45 | loss: 0.422   | val_0_rmse: 0.64893 | val_1_rmse: 0.64845 |  0:00:27s\n",
      "epoch 46 | loss: 0.42067 | val_0_rmse: 0.64791 | val_1_rmse: 0.64755 |  0:00:27s\n",
      "epoch 47 | loss: 0.42006 | val_0_rmse: 0.64716 | val_1_rmse: 0.64811 |  0:00:28s\n",
      "epoch 48 | loss: 0.42032 | val_0_rmse: 0.64659 | val_1_rmse: 0.6503  |  0:00:28s\n",
      "epoch 49 | loss: 0.42008 | val_0_rmse: 0.646   | val_1_rmse: 0.64653 |  0:00:29s\n",
      "epoch 50 | loss: 0.41944 | val_0_rmse: 0.64552 | val_1_rmse: 0.64605 |  0:00:30s\n",
      "epoch 51 | loss: 0.41844 | val_0_rmse: 0.64571 | val_1_rmse: 0.64594 |  0:00:30s\n",
      "epoch 52 | loss: 0.41788 | val_0_rmse: 0.64636 | val_1_rmse: 0.64618 |  0:00:31s\n",
      "epoch 53 | loss: 0.41885 | val_0_rmse: 0.64581 | val_1_rmse: 0.64542 |  0:00:31s\n",
      "epoch 54 | loss: 0.41973 | val_0_rmse: 0.64645 | val_1_rmse: 0.64706 |  0:00:32s\n",
      "epoch 55 | loss: 0.4178  | val_0_rmse: 0.64503 | val_1_rmse: 0.64561 |  0:00:32s\n",
      "epoch 56 | loss: 0.41657 | val_0_rmse: 0.64349 | val_1_rmse: 0.64268 |  0:00:33s\n",
      "epoch 57 | loss: 0.41678 | val_0_rmse: 0.64449 | val_1_rmse: 0.64451 |  0:00:34s\n",
      "epoch 58 | loss: 0.41674 | val_0_rmse: 0.64697 | val_1_rmse: 0.64755 |  0:00:34s\n",
      "epoch 59 | loss: 0.41742 | val_0_rmse: 0.64293 | val_1_rmse: 0.64331 |  0:00:35s\n",
      "epoch 60 | loss: 0.41745 | val_0_rmse: 0.643   | val_1_rmse: 0.64332 |  0:00:35s\n",
      "epoch 61 | loss: 0.41564 | val_0_rmse: 0.64374 | val_1_rmse: 0.64431 |  0:00:36s\n",
      "epoch 62 | loss: 0.41555 | val_0_rmse: 0.64317 | val_1_rmse: 0.64364 |  0:00:37s\n",
      "epoch 63 | loss: 0.41533 | val_0_rmse: 0.64268 | val_1_rmse: 0.64347 |  0:00:37s\n",
      "epoch 64 | loss: 0.41453 | val_0_rmse: 0.64246 | val_1_rmse: 0.64328 |  0:00:38s\n",
      "epoch 65 | loss: 0.41429 | val_0_rmse: 0.64315 | val_1_rmse: 0.64413 |  0:00:38s\n",
      "epoch 66 | loss: 0.41543 | val_0_rmse: 0.64198 | val_1_rmse: 0.6427  |  0:00:39s\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 56 and best_val_1_rmse = 0.64268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4141, Val Loss: 0.4130, RMSE: 0.6427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.95999 | val_0_rmse: 1.1272  | val_1_rmse: 0.95541 |  0:00:00s\n",
      "epoch 1  | loss: 1.71927 | val_0_rmse: 1.05048 | val_1_rmse: 0.93577 |  0:00:01s\n",
      "epoch 2  | loss: 1.28725 | val_0_rmse: 1.09709 | val_1_rmse: 0.93578 |  0:00:01s\n",
      "epoch 3  | loss: 1.02891 | val_0_rmse: 0.99401 | val_1_rmse: 0.87886 |  0:00:02s\n",
      "epoch 4  | loss: 0.85555 | val_0_rmse: 1.48192 | val_1_rmse: 0.85057 |  0:00:02s\n",
      "epoch 5  | loss: 0.73537 | val_0_rmse: 1.61576 | val_1_rmse: 0.851   |  0:00:03s\n",
      "epoch 6  | loss: 0.64886 | val_0_rmse: 1.61149 | val_1_rmse: 0.75894 |  0:00:04s\n",
      "epoch 7  | loss: 0.58671 | val_0_rmse: 1.46015 | val_1_rmse: 0.7475  |  0:00:04s\n",
      "epoch 8  | loss: 0.52165 | val_0_rmse: 0.87516 | val_1_rmse: 0.69901 |  0:00:05s\n",
      "epoch 9  | loss: 0.48347 | val_0_rmse: 0.77947 | val_1_rmse: 0.69347 |  0:00:05s\n",
      "epoch 10 | loss: 0.4642  | val_0_rmse: 0.69408 | val_1_rmse: 0.69169 |  0:00:06s\n",
      "epoch 11 | loss: 0.45797 | val_0_rmse: 0.68741 | val_1_rmse: 0.67039 |  0:00:07s\n",
      "epoch 12 | loss: 0.4515  | val_0_rmse: 0.67752 | val_1_rmse: 0.68023 |  0:00:07s\n",
      "epoch 13 | loss: 0.44713 | val_0_rmse: 0.67108 | val_1_rmse: 0.68625 |  0:00:08s\n",
      "epoch 14 | loss: 0.44485 | val_0_rmse: 0.66601 | val_1_rmse: 0.67238 |  0:00:08s\n",
      "epoch 15 | loss: 0.44168 | val_0_rmse: 0.66426 | val_1_rmse: 0.67556 |  0:00:09s\n",
      "epoch 16 | loss: 0.43886 | val_0_rmse: 0.66037 | val_1_rmse: 0.675   |  0:00:10s\n",
      "epoch 17 | loss: 0.43837 | val_0_rmse: 0.66166 | val_1_rmse: 0.6827  |  0:00:10s\n",
      "epoch 18 | loss: 0.43996 | val_0_rmse: 0.66077 | val_1_rmse: 0.68162 |  0:00:11s\n",
      "epoch 19 | loss: 0.43728 | val_0_rmse: 0.65954 | val_1_rmse: 0.67639 |  0:00:11s\n",
      "epoch 20 | loss: 0.43575 | val_0_rmse: 0.65956 | val_1_rmse: 0.68121 |  0:00:12s\n",
      "epoch 21 | loss: 0.43486 | val_0_rmse: 0.66028 | val_1_rmse: 0.67614 |  0:00:13s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_1_rmse = 0.67039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4725, Val Loss: 0.4494, RMSE: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.12597 | val_0_rmse: 1.25019 | val_1_rmse: 0.93761 |  0:00:00s\n",
      "epoch 1  | loss: 2.33989 | val_0_rmse: 1.74635 | val_1_rmse: 1.26843 |  0:00:01s\n",
      "epoch 2  | loss: 1.65575 | val_0_rmse: 1.69888 | val_1_rmse: 1.09293 |  0:00:02s\n",
      "epoch 3  | loss: 1.27913 | val_0_rmse: 1.43067 | val_1_rmse: 1.35886 |  0:00:03s\n",
      "epoch 4  | loss: 1.04896 | val_0_rmse: 1.15622 | val_1_rmse: 1.02133 |  0:00:04s\n",
      "epoch 5  | loss: 0.86225 | val_0_rmse: 1.02466 | val_1_rmse: 0.85862 |  0:00:04s\n",
      "epoch 6  | loss: 0.74931 | val_0_rmse: 0.89799 | val_1_rmse: 0.83656 |  0:00:05s\n",
      "epoch 7  | loss: 0.70275 | val_0_rmse: 0.89321 | val_1_rmse: 0.83636 |  0:00:06s\n",
      "epoch 8  | loss: 0.66708 | val_0_rmse: 0.87669 | val_1_rmse: 0.8736  |  0:00:07s\n",
      "epoch 9  | loss: 0.65285 | val_0_rmse: 0.80722 | val_1_rmse: 0.81217 |  0:00:08s\n",
      "epoch 10 | loss: 0.63748 | val_0_rmse: 0.80271 | val_1_rmse: 0.90651 |  0:00:09s\n",
      "epoch 11 | loss: 0.62674 | val_0_rmse: 0.81366 | val_1_rmse: 0.81484 |  0:00:09s\n",
      "epoch 12 | loss: 0.61506 | val_0_rmse: 0.79254 | val_1_rmse: 0.78026 |  0:00:10s\n",
      "epoch 13 | loss: 0.60018 | val_0_rmse: 0.77023 | val_1_rmse: 0.77424 |  0:00:11s\n",
      "epoch 14 | loss: 0.58124 | val_0_rmse: 0.75982 | val_1_rmse: 0.76716 |  0:00:12s\n",
      "epoch 15 | loss: 0.54933 | val_0_rmse: 0.7756  | val_1_rmse: 0.77574 |  0:00:13s\n",
      "epoch 16 | loss: 0.52242 | val_0_rmse: 0.73451 | val_1_rmse: 0.83659 |  0:00:13s\n",
      "epoch 17 | loss: 0.5051  | val_0_rmse: 0.73712 | val_1_rmse: 0.71995 |  0:00:14s\n",
      "epoch 18 | loss: 0.49406 | val_0_rmse: 0.72718 | val_1_rmse: 0.72194 |  0:00:15s\n",
      "epoch 19 | loss: 0.48577 | val_0_rmse: 0.70037 | val_1_rmse: 0.7091  |  0:00:16s\n",
      "epoch 20 | loss: 0.48342 | val_0_rmse: 0.6965  | val_1_rmse: 0.76112 |  0:00:17s\n",
      "epoch 21 | loss: 0.48083 | val_0_rmse: 0.69205 | val_1_rmse: 0.69088 |  0:00:18s\n",
      "epoch 22 | loss: 0.48548 | val_0_rmse: 0.69512 | val_1_rmse: 0.86067 |  0:00:18s\n",
      "epoch 23 | loss: 0.48414 | val_0_rmse: 0.68717 | val_1_rmse: 0.6779  |  0:00:19s\n",
      "epoch 24 | loss: 0.47689 | val_0_rmse: 0.6817  | val_1_rmse: 0.68065 |  0:00:20s\n",
      "epoch 25 | loss: 0.46866 | val_0_rmse: 0.68408 | val_1_rmse: 0.8758  |  0:00:21s\n",
      "epoch 26 | loss: 0.47323 | val_0_rmse: 0.68282 | val_1_rmse: 0.6811  |  0:00:22s\n",
      "epoch 27 | loss: 0.46757 | val_0_rmse: 0.68031 | val_1_rmse: 0.67699 |  0:00:22s\n",
      "epoch 28 | loss: 0.47098 | val_0_rmse: 0.68701 | val_1_rmse: 0.71841 |  0:00:23s\n",
      "epoch 29 | loss: 0.46712 | val_0_rmse: 0.69293 | val_1_rmse: 0.68482 |  0:00:24s\n",
      "epoch 30 | loss: 0.46519 | val_0_rmse: 0.67922 | val_1_rmse: 0.68146 |  0:00:25s\n",
      "epoch 31 | loss: 0.46251 | val_0_rmse: 0.6807  | val_1_rmse: 0.68106 |  0:00:26s\n",
      "epoch 32 | loss: 0.45811 | val_0_rmse: 0.68151 | val_1_rmse: 0.67613 |  0:00:27s\n",
      "epoch 33 | loss: 0.4599  | val_0_rmse: 0.67971 | val_1_rmse: 0.67387 |  0:00:27s\n",
      "epoch 34 | loss: 0.45702 | val_0_rmse: 0.68089 | val_1_rmse: 0.67308 |  0:00:28s\n",
      "epoch 35 | loss: 0.46158 | val_0_rmse: 0.68844 | val_1_rmse: 0.6803  |  0:00:29s\n",
      "epoch 36 | loss: 0.45786 | val_0_rmse: 0.67688 | val_1_rmse: 0.67776 |  0:00:30s\n",
      "epoch 37 | loss: 0.4577  | val_0_rmse: 0.68361 | val_1_rmse: 0.68098 |  0:00:31s\n",
      "epoch 38 | loss: 0.45071 | val_0_rmse: 0.68098 | val_1_rmse: 0.68696 |  0:00:31s\n",
      "epoch 39 | loss: 0.44795 | val_0_rmse: 0.6834  | val_1_rmse: 0.71731 |  0:00:32s\n",
      "epoch 40 | loss: 0.44675 | val_0_rmse: 0.67562 | val_1_rmse: 0.6715  |  0:00:33s\n",
      "epoch 41 | loss: 0.44668 | val_0_rmse: 0.67642 | val_1_rmse: 0.92276 |  0:00:34s\n",
      "epoch 42 | loss: 0.44502 | val_0_rmse: 0.68179 | val_1_rmse: 0.75916 |  0:00:35s\n",
      "epoch 43 | loss: 0.44395 | val_0_rmse: 0.69616 | val_1_rmse: 0.72623 |  0:00:35s\n",
      "epoch 44 | loss: 0.44358 | val_0_rmse: 0.67529 | val_1_rmse: 0.69529 |  0:00:36s\n",
      "epoch 45 | loss: 0.44264 | val_0_rmse: 0.67151 | val_1_rmse: 0.69709 |  0:00:37s\n",
      "epoch 46 | loss: 0.44258 | val_0_rmse: 0.67367 | val_1_rmse: 0.78583 |  0:00:38s\n",
      "epoch 47 | loss: 0.441   | val_0_rmse: 0.67513 | val_1_rmse: 0.85869 |  0:00:39s\n",
      "epoch 48 | loss: 0.44179 | val_0_rmse: 0.67636 | val_1_rmse: 0.95754 |  0:00:40s\n",
      "epoch 49 | loss: 0.44041 | val_0_rmse: 0.67266 | val_1_rmse: 1.00708 |  0:00:40s\n",
      "epoch 50 | loss: 0.43912 | val_0_rmse: 0.66563 | val_1_rmse: 0.77847 |  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_1_rmse = 0.6715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4565, Val Loss: 0.4509, RMSE: 0.6715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.13573 | val_0_rmse: 1.0297  | val_1_rmse: 0.94408 |  0:00:00s\n",
      "epoch 1  | loss: 2.17547 | val_0_rmse: 1.27714 | val_1_rmse: 1.84844 |  0:00:01s\n",
      "epoch 2  | loss: 1.53681 | val_0_rmse: 1.7509  | val_1_rmse: 2.23724 |  0:00:02s\n",
      "epoch 3  | loss: 1.19128 | val_0_rmse: 1.30111 | val_1_rmse: 2.15765 |  0:00:03s\n",
      "epoch 4  | loss: 0.97954 | val_0_rmse: 1.00219 | val_1_rmse: 1.00737 |  0:00:04s\n",
      "epoch 5  | loss: 0.85552 | val_0_rmse: 0.91722 | val_1_rmse: 1.30157 |  0:00:04s\n",
      "epoch 6  | loss: 0.75039 | val_0_rmse: 0.85774 | val_1_rmse: 0.99339 |  0:00:05s\n",
      "epoch 7  | loss: 0.69575 | val_0_rmse: 0.8393  | val_1_rmse: 0.86176 |  0:00:06s\n",
      "epoch 8  | loss: 0.65736 | val_0_rmse: 0.81355 | val_1_rmse: 0.8327  |  0:00:07s\n",
      "epoch 9  | loss: 0.63197 | val_0_rmse: 0.78234 | val_1_rmse: 0.79553 |  0:00:08s\n",
      "epoch 10 | loss: 0.61412 | val_0_rmse: 0.77198 | val_1_rmse: 0.7598  |  0:00:09s\n",
      "epoch 11 | loss: 0.60863 | val_0_rmse: 0.76106 | val_1_rmse: 0.75677 |  0:00:09s\n",
      "epoch 12 | loss: 0.5937  | val_0_rmse: 0.76609 | val_1_rmse: 0.75713 |  0:00:10s\n",
      "epoch 13 | loss: 0.59231 | val_0_rmse: 0.75729 | val_1_rmse: 0.74853 |  0:00:11s\n",
      "epoch 14 | loss: 0.58575 | val_0_rmse: 0.76188 | val_1_rmse: 0.74796 |  0:00:12s\n",
      "epoch 15 | loss: 0.57785 | val_0_rmse: 0.75964 | val_1_rmse: 0.75357 |  0:00:13s\n",
      "epoch 16 | loss: 0.57526 | val_0_rmse: 0.75539 | val_1_rmse: 0.74819 |  0:00:13s\n",
      "epoch 17 | loss: 0.57377 | val_0_rmse: 0.77953 | val_1_rmse: 0.79211 |  0:00:14s\n",
      "epoch 18 | loss: 0.57426 | val_0_rmse: 0.75851 | val_1_rmse: 0.75389 |  0:00:15s\n",
      "epoch 19 | loss: 0.5726  | val_0_rmse: 0.75631 | val_1_rmse: 0.75452 |  0:00:16s\n",
      "epoch 20 | loss: 0.56859 | val_0_rmse: 0.75204 | val_1_rmse: 0.75247 |  0:00:17s\n",
      "epoch 21 | loss: 0.56551 | val_0_rmse: 0.75412 | val_1_rmse: 0.74785 |  0:00:18s\n",
      "epoch 22 | loss: 0.56504 | val_0_rmse: 0.75169 | val_1_rmse: 0.74859 |  0:00:18s\n",
      "epoch 23 | loss: 0.56194 | val_0_rmse: 0.75675 | val_1_rmse: 0.75895 |  0:00:19s\n",
      "epoch 24 | loss: 0.5636  | val_0_rmse: 0.75832 | val_1_rmse: 0.76187 |  0:00:20s\n",
      "epoch 25 | loss: 0.55738 | val_0_rmse: 0.74791 | val_1_rmse: 0.75305 |  0:00:21s\n",
      "epoch 26 | loss: 0.55575 | val_0_rmse: 0.7495  | val_1_rmse: 0.77584 |  0:00:22s\n",
      "epoch 27 | loss: 0.55082 | val_0_rmse: 0.74249 | val_1_rmse: 0.75999 |  0:00:22s\n",
      "epoch 28 | loss: 0.55025 | val_0_rmse: 0.74326 | val_1_rmse: 0.76852 |  0:00:23s\n",
      "epoch 29 | loss: 0.54667 | val_0_rmse: 0.74259 | val_1_rmse: 0.75184 |  0:00:24s\n",
      "epoch 30 | loss: 0.54393 | val_0_rmse: 0.74124 | val_1_rmse: 0.74296 |  0:00:25s\n",
      "epoch 31 | loss: 0.53979 | val_0_rmse: 0.74007 | val_1_rmse: 0.75029 |  0:00:26s\n",
      "epoch 32 | loss: 0.53452 | val_0_rmse: 0.73646 | val_1_rmse: 0.73965 |  0:00:27s\n",
      "epoch 33 | loss: 0.53136 | val_0_rmse: 0.73684 | val_1_rmse: 0.74626 |  0:00:27s\n",
      "epoch 34 | loss: 0.52462 | val_0_rmse: 0.72961 | val_1_rmse: 0.87836 |  0:00:28s\n",
      "epoch 35 | loss: 0.51614 | val_0_rmse: 0.72271 | val_1_rmse: 0.81423 |  0:00:29s\n",
      "epoch 36 | loss: 0.50804 | val_0_rmse: 0.70758 | val_1_rmse: 0.70497 |  0:00:30s\n",
      "epoch 37 | loss: 0.49976 | val_0_rmse: 0.69775 | val_1_rmse: 0.70413 |  0:00:31s\n",
      "epoch 38 | loss: 0.4902  | val_0_rmse: 0.69371 | val_1_rmse: 0.72049 |  0:00:31s\n",
      "epoch 39 | loss: 0.48722 | val_0_rmse: 0.69615 | val_1_rmse: 0.76341 |  0:00:32s\n",
      "epoch 40 | loss: 0.48465 | val_0_rmse: 0.69203 | val_1_rmse: 0.68861 |  0:00:33s\n",
      "epoch 41 | loss: 0.48069 | val_0_rmse: 0.68758 | val_1_rmse: 0.68221 |  0:00:34s\n",
      "epoch 42 | loss: 0.46941 | val_0_rmse: 0.6874  | val_1_rmse: 0.67807 |  0:00:35s\n",
      "epoch 43 | loss: 0.46136 | val_0_rmse: 0.67812 | val_1_rmse: 0.67845 |  0:00:35s\n",
      "epoch 44 | loss: 0.45555 | val_0_rmse: 0.67644 | val_1_rmse: 0.67843 |  0:00:36s\n",
      "epoch 45 | loss: 0.45247 | val_0_rmse: 0.67663 | val_1_rmse: 0.6834  |  0:00:37s\n",
      "epoch 46 | loss: 0.44678 | val_0_rmse: 0.66686 | val_1_rmse: 0.66771 |  0:00:38s\n",
      "epoch 47 | loss: 0.44093 | val_0_rmse: 0.66434 | val_1_rmse: 0.67021 |  0:00:39s\n",
      "epoch 48 | loss: 0.44026 | val_0_rmse: 0.66321 | val_1_rmse: 0.67345 |  0:00:39s\n",
      "epoch 49 | loss: 0.43748 | val_0_rmse: 0.6616  | val_1_rmse: 0.66885 |  0:00:40s\n",
      "epoch 50 | loss: 0.4343  | val_0_rmse: 0.65878 | val_1_rmse: 0.66208 |  0:00:41s\n",
      "epoch 51 | loss: 0.43423 | val_0_rmse: 0.65849 | val_1_rmse: 0.66295 |  0:00:42s\n",
      "epoch 52 | loss: 0.43282 | val_0_rmse: 0.65605 | val_1_rmse: 0.65804 |  0:00:43s\n",
      "epoch 53 | loss: 0.43264 | val_0_rmse: 0.65824 | val_1_rmse: 0.65795 |  0:00:43s\n",
      "epoch 54 | loss: 0.43136 | val_0_rmse: 0.6563  | val_1_rmse: 0.65361 |  0:00:44s\n",
      "epoch 55 | loss: 0.43122 | val_0_rmse: 0.65755 | val_1_rmse: 0.65768 |  0:00:45s\n",
      "epoch 56 | loss: 0.43073 | val_0_rmse: 0.65637 | val_1_rmse: 0.6532  |  0:00:46s\n",
      "epoch 57 | loss: 0.42934 | val_0_rmse: 0.65777 | val_1_rmse: 0.6526  |  0:00:47s\n",
      "epoch 58 | loss: 0.42952 | val_0_rmse: 0.65698 | val_1_rmse: 0.65069 |  0:00:48s\n",
      "epoch 59 | loss: 0.42878 | val_0_rmse: 0.6576  | val_1_rmse: 0.65105 |  0:00:48s\n",
      "epoch 60 | loss: 0.42851 | val_0_rmse: 0.65716 | val_1_rmse: 0.64976 |  0:00:49s\n",
      "epoch 61 | loss: 0.42764 | val_0_rmse: 0.65548 | val_1_rmse: 0.65096 |  0:00:50s\n",
      "epoch 62 | loss: 0.42551 | val_0_rmse: 0.65383 | val_1_rmse: 0.64872 |  0:00:51s\n",
      "epoch 63 | loss: 0.42689 | val_0_rmse: 0.65304 | val_1_rmse: 0.64947 |  0:00:52s\n",
      "epoch 64 | loss: 0.42694 | val_0_rmse: 0.65634 | val_1_rmse: 0.65176 |  0:00:52s\n",
      "epoch 65 | loss: 0.42573 | val_0_rmse: 0.65384 | val_1_rmse: 0.65015 |  0:00:53s\n",
      "epoch 66 | loss: 0.42667 | val_0_rmse: 0.6558  | val_1_rmse: 0.65247 |  0:00:54s\n",
      "epoch 67 | loss: 0.42595 | val_0_rmse: 0.66202 | val_1_rmse: 0.64948 |  0:00:55s\n",
      "epoch 68 | loss: 0.4261  | val_0_rmse: 0.65566 | val_1_rmse: 0.65035 |  0:00:56s\n",
      "epoch 69 | loss: 0.42435 | val_0_rmse: 0.65482 | val_1_rmse: 0.65113 |  0:00:56s\n",
      "epoch 70 | loss: 0.42436 | val_0_rmse: 0.65492 | val_1_rmse: 0.67973 |  0:00:57s\n",
      "epoch 71 | loss: 0.42387 | val_0_rmse: 0.65422 | val_1_rmse: 0.6836  |  0:00:58s\n",
      "epoch 72 | loss: 0.42382 | val_0_rmse: 0.65502 | val_1_rmse: 0.6741  |  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_1_rmse = 0.64872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4275, Val Loss: 0.4208, RMSE: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 13.35035| val_0_rmse: 1.19456 | val_1_rmse: 1.09786 |  0:00:01s\n",
      "epoch 1  | loss: 11.58398| val_0_rmse: 2.09535 | val_1_rmse: 1.44622 |  0:00:02s\n",
      "epoch 2  | loss: 9.76543 | val_0_rmse: 3.05281 | val_1_rmse: 1.79374 |  0:00:04s\n",
      "epoch 3  | loss: 8.42532 | val_0_rmse: 3.77034 | val_1_rmse: 2.04962 |  0:00:05s\n",
      "epoch 4  | loss: 7.24496 | val_0_rmse: 3.37226 | val_1_rmse: 3.46707 |  0:00:06s\n",
      "epoch 5  | loss: 5.86866 | val_0_rmse: 4.28057 | val_1_rmse: 2.17592 |  0:00:08s\n",
      "epoch 6  | loss: 4.71213 | val_0_rmse: 3.28214 | val_1_rmse: 2.23341 |  0:00:09s\n",
      "epoch 7  | loss: 4.19797 | val_0_rmse: 2.69608 | val_1_rmse: 2.32807 |  0:00:11s\n",
      "epoch 8  | loss: 3.59234 | val_0_rmse: 3.11662 | val_1_rmse: 2.82071 |  0:00:12s\n",
      "epoch 9  | loss: 3.03853 | val_0_rmse: 2.49397 | val_1_rmse: 2.65524 |  0:00:13s\n",
      "epoch 10 | loss: 2.62003 | val_0_rmse: 2.36849 | val_1_rmse: 2.59082 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.09786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.4270, Val Loss: 1.2053, RMSE: 1.0979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 13.65997| val_0_rmse: 1.15621 | val_1_rmse: 1.56697 |  0:00:01s\n",
      "epoch 1  | loss: 12.70698| val_0_rmse: 1.67118 | val_1_rmse: 2.18248 |  0:00:02s\n",
      "epoch 2  | loss: 11.14113| val_0_rmse: 3.8656  | val_1_rmse: 2.28655 |  0:00:04s\n",
      "epoch 3  | loss: 9.51488 | val_0_rmse: 3.66614 | val_1_rmse: 2.64514 |  0:00:05s\n",
      "epoch 4  | loss: 8.22906 | val_0_rmse: 3.32521 | val_1_rmse: 4.19478 |  0:00:06s\n",
      "epoch 5  | loss: 6.77922 | val_0_rmse: 2.75547 | val_1_rmse: 3.7174  |  0:00:08s\n",
      "epoch 6  | loss: 5.66208 | val_0_rmse: 2.69836 | val_1_rmse: 2.30703 |  0:00:09s\n",
      "epoch 7  | loss: 4.75313 | val_0_rmse: 2.82402 | val_1_rmse: 3.30046 |  0:00:11s\n",
      "epoch 8  | loss: 4.50742 | val_0_rmse: 2.51595 | val_1_rmse: 2.15764 |  0:00:12s\n",
      "epoch 9  | loss: 3.9557  | val_0_rmse: 2.62141 | val_1_rmse: 3.98159 |  0:00:13s\n",
      "epoch 10 | loss: 3.4369  | val_0_rmse: 2.29739 | val_1_rmse: 1.96827 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.56697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.3368, Val Loss: 2.4554, RMSE: 1.5670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.81644 | val_0_rmse: 1.10438 | val_1_rmse: 2.82101 |  0:00:00s\n",
      "epoch 1  | loss: 1.68646 | val_0_rmse: 1.17433 | val_1_rmse: 2.43354 |  0:00:01s\n",
      "epoch 2  | loss: 1.23012 | val_0_rmse: 1.14129 | val_1_rmse: 1.08864 |  0:00:01s\n",
      "epoch 3  | loss: 0.9715  | val_0_rmse: 1.02288 | val_1_rmse: 1.15674 |  0:00:02s\n",
      "epoch 4  | loss: 0.77609 | val_0_rmse: 0.97068 | val_1_rmse: 0.97762 |  0:00:03s\n",
      "epoch 5  | loss: 0.64622 | val_0_rmse: 0.77858 | val_1_rmse: 0.89464 |  0:00:03s\n",
      "epoch 6  | loss: 0.5624  | val_0_rmse: 0.73868 | val_1_rmse: 0.82101 |  0:00:04s\n",
      "epoch 7  | loss: 0.52779 | val_0_rmse: 0.71256 | val_1_rmse: 0.78361 |  0:00:04s\n",
      "epoch 8  | loss: 0.49617 | val_0_rmse: 0.70003 | val_1_rmse: 0.74789 |  0:00:05s\n",
      "epoch 9  | loss: 0.48194 | val_0_rmse: 0.69097 | val_1_rmse: 0.72723 |  0:00:06s\n",
      "epoch 10 | loss: 0.47696 | val_0_rmse: 0.68677 | val_1_rmse: 0.7236  |  0:00:06s\n",
      "epoch 11 | loss: 0.47212 | val_0_rmse: 0.69666 | val_1_rmse: 0.71622 |  0:00:07s\n",
      "epoch 12 | loss: 0.46379 | val_0_rmse: 0.69928 | val_1_rmse: 0.7075  |  0:00:08s\n",
      "epoch 13 | loss: 0.46184 | val_0_rmse: 0.69278 | val_1_rmse: 0.70527 |  0:00:08s\n",
      "epoch 14 | loss: 0.45994 | val_0_rmse: 0.92308 | val_1_rmse: 0.71101 |  0:00:09s\n",
      "epoch 15 | loss: 0.45455 | val_0_rmse: 0.69656 | val_1_rmse: 0.70543 |  0:00:09s\n",
      "epoch 16 | loss: 0.45442 | val_0_rmse: 0.68147 | val_1_rmse: 0.81273 |  0:00:10s\n",
      "epoch 17 | loss: 0.45091 | val_0_rmse: 0.67423 | val_1_rmse: 0.70723 |  0:00:11s\n",
      "epoch 18 | loss: 0.4515  | val_0_rmse: 0.67747 | val_1_rmse: 0.71667 |  0:00:11s\n",
      "epoch 19 | loss: 0.44921 | val_0_rmse: 0.67189 | val_1_rmse: 0.71463 |  0:00:12s\n",
      "epoch 20 | loss: 0.44792 | val_0_rmse: 0.66957 | val_1_rmse: 0.70606 |  0:00:12s\n",
      "epoch 21 | loss: 0.44562 | val_0_rmse: 0.66788 | val_1_rmse: 0.70598 |  0:00:13s\n",
      "epoch 22 | loss: 0.44551 | val_0_rmse: 0.66767 | val_1_rmse: 0.69568 |  0:00:14s\n",
      "epoch 23 | loss: 0.44335 | val_0_rmse: 0.66285 | val_1_rmse: 0.70319 |  0:00:14s\n",
      "epoch 24 | loss: 0.44432 | val_0_rmse: 0.66291 | val_1_rmse: 0.706   |  0:00:15s\n",
      "epoch 25 | loss: 0.44203 | val_0_rmse: 0.664   | val_1_rmse: 0.71365 |  0:00:15s\n",
      "epoch 26 | loss: 0.43976 | val_0_rmse: 0.66194 | val_1_rmse: 0.71083 |  0:00:16s\n",
      "epoch 27 | loss: 0.44131 | val_0_rmse: 0.66121 | val_1_rmse: 0.7117  |  0:00:17s\n",
      "epoch 28 | loss: 0.44131 | val_0_rmse: 0.67212 | val_1_rmse: 0.71796 |  0:00:17s\n",
      "epoch 29 | loss: 0.44002 | val_0_rmse: 0.66723 | val_1_rmse: 0.75489 |  0:00:18s\n",
      "epoch 30 | loss: 0.44019 | val_0_rmse: 0.66135 | val_1_rmse: 0.71898 |  0:00:18s\n",
      "epoch 31 | loss: 0.43885 | val_0_rmse: 0.66101 | val_1_rmse: 0.72656 |  0:00:19s\n",
      "epoch 32 | loss: 0.43648 | val_0_rmse: 0.65981 | val_1_rmse: 0.74293 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_1_rmse = 0.69568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4458, Val Loss: 0.4840, RMSE: 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.92956 | val_0_rmse: 1.18358 | val_1_rmse: 2.37086 |  0:00:00s\n",
      "epoch 1  | loss: 1.61518 | val_0_rmse: 1.10948 | val_1_rmse: 1.64193 |  0:00:01s\n",
      "epoch 2  | loss: 1.21396 | val_0_rmse: 1.16128 | val_1_rmse: 0.96925 |  0:00:01s\n",
      "epoch 3  | loss: 0.97238 | val_0_rmse: 0.92796 | val_1_rmse: 0.8777  |  0:00:02s\n",
      "epoch 4  | loss: 0.80685 | val_0_rmse: 0.85359 | val_1_rmse: 0.80428 |  0:00:02s\n",
      "epoch 5  | loss: 0.67425 | val_0_rmse: 0.77221 | val_1_rmse: 0.86155 |  0:00:03s\n",
      "epoch 6  | loss: 0.58545 | val_0_rmse: 0.75545 | val_1_rmse: 0.84033 |  0:00:04s\n",
      "epoch 7  | loss: 0.53932 | val_0_rmse: 0.74503 | val_1_rmse: 0.74126 |  0:00:04s\n",
      "epoch 8  | loss: 0.50647 | val_0_rmse: 0.70757 | val_1_rmse: 0.74919 |  0:00:05s\n",
      "epoch 9  | loss: 0.48593 | val_0_rmse: 0.69701 | val_1_rmse: 0.73442 |  0:00:05s\n",
      "epoch 10 | loss: 0.4811  | val_0_rmse: 0.69249 | val_1_rmse: 0.70305 |  0:00:06s\n",
      "epoch 11 | loss: 0.47131 | val_0_rmse: 0.68706 | val_1_rmse: 0.6918  |  0:00:07s\n",
      "epoch 12 | loss: 0.46864 | val_0_rmse: 0.67235 | val_1_rmse: 0.67517 |  0:00:07s\n",
      "epoch 13 | loss: 0.46218 | val_0_rmse: 0.67887 | val_1_rmse: 0.68023 |  0:00:08s\n",
      "epoch 14 | loss: 0.45802 | val_0_rmse: 0.67595 | val_1_rmse: 0.67516 |  0:00:08s\n",
      "epoch 15 | loss: 0.45695 | val_0_rmse: 0.66965 | val_1_rmse: 0.67038 |  0:00:09s\n",
      "epoch 16 | loss: 0.45295 | val_0_rmse: 0.66903 | val_1_rmse: 0.68009 |  0:00:10s\n",
      "epoch 17 | loss: 0.44832 | val_0_rmse: 0.66737 | val_1_rmse: 0.66877 |  0:00:10s\n",
      "epoch 18 | loss: 0.4453  | val_0_rmse: 0.66462 | val_1_rmse: 0.66226 |  0:00:11s\n",
      "epoch 19 | loss: 0.44459 | val_0_rmse: 0.66282 | val_1_rmse: 0.66068 |  0:00:11s\n",
      "epoch 20 | loss: 0.44407 | val_0_rmse: 0.66179 | val_1_rmse: 0.66034 |  0:00:12s\n",
      "epoch 21 | loss: 0.44123 | val_0_rmse: 0.66088 | val_1_rmse: 0.65861 |  0:00:13s\n",
      "epoch 22 | loss: 0.43972 | val_0_rmse: 0.66154 | val_1_rmse: 0.66045 |  0:00:13s\n",
      "epoch 23 | loss: 0.43808 | val_0_rmse: 0.65794 | val_1_rmse: 0.65831 |  0:00:14s\n",
      "epoch 24 | loss: 0.43747 | val_0_rmse: 0.66179 | val_1_rmse: 0.67989 |  0:00:14s\n",
      "epoch 25 | loss: 0.43794 | val_0_rmse: 0.6588  | val_1_rmse: 0.66338 |  0:00:15s\n",
      "epoch 26 | loss: 0.43411 | val_0_rmse: 0.66483 | val_1_rmse: 0.69259 |  0:00:15s\n",
      "epoch 27 | loss: 0.43495 | val_0_rmse: 0.67174 | val_1_rmse: 0.72045 |  0:00:16s\n",
      "epoch 28 | loss: 0.43552 | val_0_rmse: 0.67023 | val_1_rmse: 0.71567 |  0:00:17s\n",
      "epoch 29 | loss: 0.43286 | val_0_rmse: 0.66681 | val_1_rmse: 0.70629 |  0:00:17s\n",
      "epoch 30 | loss: 0.43329 | val_0_rmse: 0.66669 | val_1_rmse: 0.70026 |  0:00:18s\n",
      "epoch 31 | loss: 0.43204 | val_0_rmse: 0.66619 | val_1_rmse: 0.6939  |  0:00:18s\n",
      "epoch 32 | loss: 0.4313  | val_0_rmse: 0.65784 | val_1_rmse: 0.67186 |  0:00:19s\n",
      "epoch 33 | loss: 0.43139 | val_0_rmse: 0.65806 | val_1_rmse: 0.66226 |  0:00:20s\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_1_rmse = 0.65831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4329, Val Loss: 0.4334, RMSE: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.66655 | val_0_rmse: 1.15184 | val_1_rmse: 0.95655 |  0:00:00s\n",
      "epoch 1  | loss: 2.53833 | val_0_rmse: 1.68506 | val_1_rmse: 1.08883 |  0:00:01s\n",
      "epoch 2  | loss: 1.80691 | val_0_rmse: 1.8603  | val_1_rmse: 1.06119 |  0:00:02s\n",
      "epoch 3  | loss: 1.37256 | val_0_rmse: 1.52538 | val_1_rmse: 1.13445 |  0:00:03s\n",
      "epoch 4  | loss: 1.11791 | val_0_rmse: 1.34734 | val_1_rmse: 1.57104 |  0:00:04s\n",
      "epoch 5  | loss: 0.95022 | val_0_rmse: 1.22027 | val_1_rmse: 1.31503 |  0:00:04s\n",
      "epoch 6  | loss: 0.8117  | val_0_rmse: 0.97286 | val_1_rmse: 0.89611 |  0:00:05s\n",
      "epoch 7  | loss: 0.73158 | val_0_rmse: 0.85882 | val_1_rmse: 0.85304 |  0:00:06s\n",
      "epoch 8  | loss: 0.67029 | val_0_rmse: 0.77119 | val_1_rmse: 0.7886  |  0:00:07s\n",
      "epoch 9  | loss: 0.62508 | val_0_rmse: 0.77391 | val_1_rmse: 0.7771  |  0:00:08s\n",
      "epoch 10 | loss: 0.57544 | val_0_rmse: 0.73299 | val_1_rmse: 0.72901 |  0:00:09s\n",
      "epoch 11 | loss: 0.54138 | val_0_rmse: 0.72965 | val_1_rmse: 0.72322 |  0:00:09s\n",
      "epoch 12 | loss: 0.52866 | val_0_rmse: 0.71497 | val_1_rmse: 0.69776 |  0:00:10s\n",
      "epoch 13 | loss: 0.51613 | val_0_rmse: 0.70984 | val_1_rmse: 0.71703 |  0:00:11s\n",
      "epoch 14 | loss: 0.50738 | val_0_rmse: 0.71961 | val_1_rmse: 0.73161 |  0:00:12s\n",
      "epoch 15 | loss: 0.49781 | val_0_rmse: 0.71623 | val_1_rmse: 0.70845 |  0:00:13s\n",
      "epoch 16 | loss: 0.49451 | val_0_rmse: 0.69496 | val_1_rmse: 0.69242 |  0:00:13s\n",
      "epoch 17 | loss: 0.48407 | val_0_rmse: 0.70181 | val_1_rmse: 0.70203 |  0:00:14s\n",
      "epoch 18 | loss: 0.48181 | val_0_rmse: 0.6962  | val_1_rmse: 0.70638 |  0:00:15s\n",
      "epoch 19 | loss: 0.47981 | val_0_rmse: 0.69455 | val_1_rmse: 0.69755 |  0:00:16s\n",
      "epoch 20 | loss: 0.47611 | val_0_rmse: 0.69826 | val_1_rmse: 0.69926 |  0:00:17s\n",
      "epoch 21 | loss: 0.47363 | val_0_rmse: 0.70532 | val_1_rmse: 0.70824 |  0:00:18s\n",
      "epoch 22 | loss: 0.47694 | val_0_rmse: 0.72611 | val_1_rmse: 0.70596 |  0:00:18s\n",
      "epoch 23 | loss: 0.4774  | val_0_rmse: 0.73147 | val_1_rmse: 0.71042 |  0:00:19s\n",
      "epoch 24 | loss: 0.47338 | val_0_rmse: 0.69307 | val_1_rmse: 0.68891 |  0:00:20s\n",
      "epoch 25 | loss: 0.46716 | val_0_rmse: 0.70415 | val_1_rmse: 0.68392 |  0:00:21s\n",
      "epoch 26 | loss: 0.46645 | val_0_rmse: 0.68338 | val_1_rmse: 0.6697  |  0:00:22s\n",
      "epoch 27 | loss: 0.46741 | val_0_rmse: 0.68488 | val_1_rmse: 0.67798 |  0:00:22s\n",
      "epoch 28 | loss: 0.4657  | val_0_rmse: 0.68213 | val_1_rmse: 0.68652 |  0:00:23s\n",
      "epoch 29 | loss: 0.46191 | val_0_rmse: 0.68179 | val_1_rmse: 0.67456 |  0:00:24s\n",
      "epoch 30 | loss: 0.45933 | val_0_rmse: 0.68332 | val_1_rmse: 0.68669 |  0:00:25s\n",
      "epoch 31 | loss: 0.46024 | val_0_rmse: 0.6869  | val_1_rmse: 0.68774 |  0:00:26s\n",
      "epoch 32 | loss: 0.45647 | val_0_rmse: 0.68956 | val_1_rmse: 0.69648 |  0:00:27s\n",
      "epoch 33 | loss: 0.45772 | val_0_rmse: 0.69062 | val_1_rmse: 1.70465 |  0:00:27s\n",
      "epoch 34 | loss: 0.45832 | val_0_rmse: 0.68689 | val_1_rmse: 2.20407 |  0:00:28s\n",
      "epoch 35 | loss: 0.45732 | val_0_rmse: 0.69452 | val_1_rmse: 0.74187 |  0:00:29s\n",
      "epoch 36 | loss: 0.46026 | val_0_rmse: 0.6806  | val_1_rmse: 0.83089 |  0:00:30s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_1_rmse = 0.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4670, Val Loss: 0.4485, RMSE: 0.6697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.63486 | val_0_rmse: 1.16957 | val_1_rmse: 0.97335 |  0:00:00s\n",
      "epoch 1  | loss: 2.59643 | val_0_rmse: 1.15016 | val_1_rmse: 1.05408 |  0:00:01s\n",
      "epoch 2  | loss: 1.7803  | val_0_rmse: 1.29573 | val_1_rmse: 1.06997 |  0:00:02s\n",
      "epoch 3  | loss: 1.32777 | val_0_rmse: 1.13033 | val_1_rmse: 1.0718  |  0:00:03s\n",
      "epoch 4  | loss: 1.08823 | val_0_rmse: 1.06552 | val_1_rmse: 0.94644 |  0:00:04s\n",
      "epoch 5  | loss: 0.88661 | val_0_rmse: 0.99539 | val_1_rmse: 0.90217 |  0:00:04s\n",
      "epoch 6  | loss: 0.75259 | val_0_rmse: 0.91569 | val_1_rmse: 0.95299 |  0:00:05s\n",
      "epoch 7  | loss: 0.6813  | val_0_rmse: 0.83492 | val_1_rmse: 0.94396 |  0:00:06s\n",
      "epoch 8  | loss: 0.63595 | val_0_rmse: 0.82121 | val_1_rmse: 1.71477 |  0:00:07s\n",
      "epoch 9  | loss: 0.59727 | val_0_rmse: 0.8074  | val_1_rmse: 0.92331 |  0:00:08s\n",
      "epoch 10 | loss: 0.56431 | val_0_rmse: 0.75885 | val_1_rmse: 0.78681 |  0:00:08s\n",
      "epoch 11 | loss: 0.5424  | val_0_rmse: 0.7425  | val_1_rmse: 0.74869 |  0:00:09s\n",
      "epoch 12 | loss: 0.53089 | val_0_rmse: 0.72707 | val_1_rmse: 0.732   |  0:00:10s\n",
      "epoch 13 | loss: 0.51603 | val_0_rmse: 0.72105 | val_1_rmse: 0.72964 |  0:00:11s\n",
      "epoch 14 | loss: 0.50841 | val_0_rmse: 0.71117 | val_1_rmse: 0.71785 |  0:00:12s\n",
      "epoch 15 | loss: 0.50156 | val_0_rmse: 0.70854 | val_1_rmse: 0.69217 |  0:00:12s\n",
      "epoch 16 | loss: 0.49342 | val_0_rmse: 0.69431 | val_1_rmse: 0.69016 |  0:00:13s\n",
      "epoch 17 | loss: 0.48785 | val_0_rmse: 0.69656 | val_1_rmse: 0.7036  |  0:00:14s\n",
      "epoch 18 | loss: 0.48507 | val_0_rmse: 0.68993 | val_1_rmse: 0.70676 |  0:00:15s\n",
      "epoch 19 | loss: 0.4806  | val_0_rmse: 0.69872 | val_1_rmse: 0.75434 |  0:00:16s\n",
      "epoch 20 | loss: 0.47451 | val_0_rmse: 0.68843 | val_1_rmse: 0.73889 |  0:00:17s\n",
      "epoch 21 | loss: 0.46685 | val_0_rmse: 0.68474 | val_1_rmse: 0.68324 |  0:00:17s\n",
      "epoch 22 | loss: 0.46908 | val_0_rmse: 0.72645 | val_1_rmse: 0.79118 |  0:00:18s\n",
      "epoch 23 | loss: 0.46368 | val_0_rmse: 0.69533 | val_1_rmse: 0.72211 |  0:00:19s\n",
      "epoch 24 | loss: 0.46094 | val_0_rmse: 0.68189 | val_1_rmse: 0.68134 |  0:00:20s\n",
      "epoch 25 | loss: 0.46113 | val_0_rmse: 0.67883 | val_1_rmse: 0.68199 |  0:00:21s\n",
      "epoch 26 | loss: 0.45773 | val_0_rmse: 0.67961 | val_1_rmse: 0.68947 |  0:00:21s\n",
      "epoch 27 | loss: 0.45974 | val_0_rmse: 0.67769 | val_1_rmse: 0.70915 |  0:00:22s\n",
      "epoch 28 | loss: 0.46004 | val_0_rmse: 0.68232 | val_1_rmse: 0.72322 |  0:00:23s\n",
      "epoch 29 | loss: 0.45513 | val_0_rmse: 0.67448 | val_1_rmse: 0.7144  |  0:00:24s\n",
      "epoch 30 | loss: 0.45607 | val_0_rmse: 0.68815 | val_1_rmse: 0.74194 |  0:00:25s\n",
      "epoch 31 | loss: 0.45758 | val_0_rmse: 0.68743 | val_1_rmse: 0.69216 |  0:00:26s\n",
      "epoch 32 | loss: 0.45538 | val_0_rmse: 0.68909 | val_1_rmse: 0.69319 |  0:00:26s\n",
      "epoch 33 | loss: 0.45107 | val_0_rmse: 0.68658 | val_1_rmse: 0.70488 |  0:00:27s\n",
      "epoch 34 | loss: 0.44902 | val_0_rmse: 0.68466 | val_1_rmse: 0.72776 |  0:00:28s\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_1_rmse = 0.68134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4650, Val Loss: 0.4642, RMSE: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 16.65671| val_0_rmse: 1.56503 | val_1_rmse: 2.10169 |  0:00:01s\n",
      "epoch 1  | loss: 15.69594| val_0_rmse: 2.55638 | val_1_rmse: 3.28652 |  0:00:02s\n",
      "epoch 2  | loss: 14.57403| val_0_rmse: 3.22796 | val_1_rmse: 2.12526 |  0:00:04s\n",
      "epoch 3  | loss: 12.40034| val_0_rmse: 4.06057 | val_1_rmse: 2.54442 |  0:00:05s\n",
      "epoch 4  | loss: 10.8883 | val_0_rmse: 3.8044  | val_1_rmse: 3.76048 |  0:00:07s\n",
      "epoch 5  | loss: 8.7776  | val_0_rmse: 5.2556  | val_1_rmse: 2.75503 |  0:00:08s\n",
      "epoch 6  | loss: 6.59247 | val_0_rmse: 2.94065 | val_1_rmse: 2.17832 |  0:00:09s\n",
      "epoch 7  | loss: 5.40579 | val_0_rmse: 2.54809 | val_1_rmse: 2.59668 |  0:00:11s\n",
      "epoch 8  | loss: 4.59908 | val_0_rmse: 2.66242 | val_1_rmse: 3.04406 |  0:00:12s\n",
      "epoch 9  | loss: 4.1001  | val_0_rmse: 2.27794 | val_1_rmse: 2.67706 |  0:00:14s\n",
      "epoch 10 | loss: 3.73485 | val_0_rmse: 2.66752 | val_1_rmse: 3.1344  |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 2.10169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 2.4493, Val Loss: 4.4171, RMSE: 2.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 16.42042| val_0_rmse: 1.44742 | val_1_rmse: 1.15956 |  0:00:01s\n",
      "epoch 1  | loss: 15.97551| val_0_rmse: 2.52919 | val_1_rmse: 1.76645 |  0:00:02s\n",
      "epoch 2  | loss: 15.01108| val_0_rmse: 3.65169 | val_1_rmse: 2.42122 |  0:00:04s\n",
      "epoch 3  | loss: 13.61585| val_0_rmse: 4.2108  | val_1_rmse: 3.43053 |  0:00:05s\n",
      "epoch 4  | loss: 11.80469| val_0_rmse: 3.47176 | val_1_rmse: 2.17013 |  0:00:06s\n",
      "epoch 5  | loss: 10.00186| val_0_rmse: 3.37292 | val_1_rmse: 3.04514 |  0:00:08s\n",
      "epoch 6  | loss: 8.17667 | val_0_rmse: 3.93513 | val_1_rmse: 3.55069 |  0:00:09s\n",
      "epoch 7  | loss: 7.12749 | val_0_rmse: 2.96087 | val_1_rmse: 2.47632 |  0:00:11s\n",
      "epoch 8  | loss: 5.91755 | val_0_rmse: 2.8814  | val_1_rmse: 8.29223 |  0:00:12s\n",
      "epoch 9  | loss: 4.90906 | val_0_rmse: 2.64456 | val_1_rmse: 2.47543 |  0:00:13s\n",
      "epoch 10 | loss: 4.42005 | val_0_rmse: 2.81387 | val_1_rmse: 3.64041 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.15956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 16, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 2.0950, Val Loss: 1.3446, RMSE: 1.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.54172 | val_0_rmse: 1.29822 | val_1_rmse: 0.95322 |  0:00:00s\n",
      "epoch 1  | loss: 1.82838 | val_0_rmse: 1.02948 | val_1_rmse: 0.96162 |  0:00:01s\n",
      "epoch 2  | loss: 1.27344 | val_0_rmse: 1.65037 | val_1_rmse: 0.87288 |  0:00:01s\n",
      "epoch 3  | loss: 0.93566 | val_0_rmse: 1.05212 | val_1_rmse: 0.92039 |  0:00:02s\n",
      "epoch 4  | loss: 0.73629 | val_0_rmse: 0.88013 | val_1_rmse: 0.76516 |  0:00:02s\n",
      "epoch 5  | loss: 0.61813 | val_0_rmse: 0.92718 | val_1_rmse: 0.71029 |  0:00:03s\n",
      "epoch 6  | loss: 0.54151 | val_0_rmse: 0.90733 | val_1_rmse: 0.69644 |  0:00:04s\n",
      "epoch 7  | loss: 0.49859 | val_0_rmse: 0.76013 | val_1_rmse: 0.67835 |  0:00:04s\n",
      "epoch 8  | loss: 0.47541 | val_0_rmse: 0.7012  | val_1_rmse: 0.67224 |  0:00:05s\n",
      "epoch 9  | loss: 0.4657  | val_0_rmse: 0.67897 | val_1_rmse: 0.66697 |  0:00:05s\n",
      "epoch 10 | loss: 0.457   | val_0_rmse: 0.6812  | val_1_rmse: 0.66361 |  0:00:06s\n",
      "epoch 11 | loss: 0.45182 | val_0_rmse: 0.67187 | val_1_rmse: 0.67154 |  0:00:07s\n",
      "epoch 12 | loss: 0.44609 | val_0_rmse: 0.681   | val_1_rmse: 0.65753 |  0:00:07s\n",
      "epoch 13 | loss: 0.44162 | val_0_rmse: 0.70346 | val_1_rmse: 0.66576 |  0:00:08s\n",
      "epoch 14 | loss: 0.43838 | val_0_rmse: 0.66058 | val_1_rmse: 0.6757  |  0:00:08s\n",
      "epoch 15 | loss: 0.43816 | val_0_rmse: 0.66099 | val_1_rmse: 0.65298 |  0:00:09s\n",
      "epoch 16 | loss: 0.4329  | val_0_rmse: 0.6583  | val_1_rmse: 0.65083 |  0:00:10s\n",
      "epoch 17 | loss: 0.43153 | val_0_rmse: 0.65617 | val_1_rmse: 0.64926 |  0:00:10s\n",
      "epoch 18 | loss: 0.42858 | val_0_rmse: 0.65477 | val_1_rmse: 0.64948 |  0:00:11s\n",
      "epoch 19 | loss: 0.42825 | val_0_rmse: 0.65282 | val_1_rmse: 0.6484  |  0:00:11s\n",
      "epoch 20 | loss: 0.42777 | val_0_rmse: 0.65463 | val_1_rmse: 0.64967 |  0:00:12s\n",
      "epoch 21 | loss: 0.42624 | val_0_rmse: 0.65426 | val_1_rmse: 0.64885 |  0:00:12s\n",
      "epoch 22 | loss: 0.42506 | val_0_rmse: 0.65134 | val_1_rmse: 0.6472  |  0:00:13s\n",
      "epoch 23 | loss: 0.42592 | val_0_rmse: 0.65162 | val_1_rmse: 0.64762 |  0:00:14s\n",
      "epoch 24 | loss: 0.4235  | val_0_rmse: 0.65037 | val_1_rmse: 0.64714 |  0:00:14s\n",
      "epoch 25 | loss: 0.42441 | val_0_rmse: 0.65189 | val_1_rmse: 0.64687 |  0:00:15s\n",
      "epoch 26 | loss: 0.42401 | val_0_rmse: 0.65204 | val_1_rmse: 0.64637 |  0:00:15s\n",
      "epoch 27 | loss: 0.42301 | val_0_rmse: 0.65112 | val_1_rmse: 0.64622 |  0:00:16s\n",
      "epoch 28 | loss: 0.42174 | val_0_rmse: 0.65102 | val_1_rmse: 0.646   |  0:00:17s\n",
      "epoch 29 | loss: 0.42137 | val_0_rmse: 0.65006 | val_1_rmse: 0.64554 |  0:00:17s\n",
      "epoch 30 | loss: 0.4218  | val_0_rmse: 0.65158 | val_1_rmse: 0.64628 |  0:00:18s\n",
      "epoch 31 | loss: 0.42096 | val_0_rmse: 0.65066 | val_1_rmse: 0.64621 |  0:00:18s\n",
      "epoch 32 | loss: 0.42089 | val_0_rmse: 0.65011 | val_1_rmse: 0.64694 |  0:00:19s\n",
      "epoch 33 | loss: 0.42014 | val_0_rmse: 0.64867 | val_1_rmse: 0.65153 |  0:00:20s\n",
      "epoch 34 | loss: 0.41989 | val_0_rmse: 0.64871 | val_1_rmse: 0.65666 |  0:00:20s\n",
      "epoch 35 | loss: 0.41882 | val_0_rmse: 0.64688 | val_1_rmse: 0.65247 |  0:00:21s\n",
      "epoch 36 | loss: 0.41837 | val_0_rmse: 0.64644 | val_1_rmse: 0.64954 |  0:00:21s\n",
      "epoch 37 | loss: 0.41851 | val_0_rmse: 0.64747 | val_1_rmse: 0.65269 |  0:00:22s\n",
      "epoch 38 | loss: 0.41732 | val_0_rmse: 0.64599 | val_1_rmse: 0.65907 |  0:00:22s\n",
      "epoch 39 | loss: 0.41736 | val_0_rmse: 0.64534 | val_1_rmse: 0.65357 |  0:00:23s\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_1_rmse = 0.64554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4226, Val Loss: 0.4167, RMSE: 0.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.62848 | val_0_rmse: 1.49858 | val_1_rmse: 0.9848  |  0:00:00s\n",
      "epoch 1  | loss: 1.93292 | val_0_rmse: 1.85531 | val_1_rmse: 1.12034 |  0:00:01s\n",
      "epoch 2  | loss: 1.36001 | val_0_rmse: 1.34068 | val_1_rmse: 1.08836 |  0:00:01s\n",
      "epoch 3  | loss: 1.01812 | val_0_rmse: 1.15457 | val_1_rmse: 0.91466 |  0:00:02s\n",
      "epoch 4  | loss: 0.77267 | val_0_rmse: 0.96408 | val_1_rmse: 0.81046 |  0:00:02s\n",
      "epoch 5  | loss: 0.63545 | val_0_rmse: 0.82149 | val_1_rmse: 0.83597 |  0:00:03s\n",
      "epoch 6  | loss: 0.55203 | val_0_rmse: 0.78541 | val_1_rmse: 0.74822 |  0:00:04s\n",
      "epoch 7  | loss: 0.51743 | val_0_rmse: 0.72519 | val_1_rmse: 0.72315 |  0:00:04s\n",
      "epoch 8  | loss: 0.4978  | val_0_rmse: 0.70849 | val_1_rmse: 0.6997  |  0:00:05s\n",
      "epoch 9  | loss: 0.48676 | val_0_rmse: 0.70256 | val_1_rmse: 0.68517 |  0:00:05s\n",
      "epoch 10 | loss: 0.47934 | val_0_rmse: 0.69721 | val_1_rmse: 0.67861 |  0:00:06s\n",
      "epoch 11 | loss: 0.47298 | val_0_rmse: 0.69438 | val_1_rmse: 0.68014 |  0:00:06s\n",
      "epoch 12 | loss: 0.4654  | val_0_rmse: 0.82547 | val_1_rmse: 0.67607 |  0:00:07s\n",
      "epoch 13 | loss: 0.4643  | val_0_rmse: 0.68547 | val_1_rmse: 0.67095 |  0:00:08s\n",
      "epoch 14 | loss: 0.45724 | val_0_rmse: 0.67891 | val_1_rmse: 0.66892 |  0:00:08s\n",
      "epoch 15 | loss: 0.45482 | val_0_rmse: 0.67825 | val_1_rmse: 0.67348 |  0:00:09s\n",
      "epoch 16 | loss: 0.45063 | val_0_rmse: 0.84995 | val_1_rmse: 0.66981 |  0:00:09s\n",
      "epoch 17 | loss: 0.45034 | val_0_rmse: 1.29395 | val_1_rmse: 0.66649 |  0:00:10s\n",
      "epoch 18 | loss: 0.44542 | val_0_rmse: 0.66786 | val_1_rmse: 0.66454 |  0:00:11s\n",
      "epoch 19 | loss: 0.44542 | val_0_rmse: 0.66782 | val_1_rmse: 0.6649  |  0:00:11s\n",
      "epoch 20 | loss: 0.44421 | val_0_rmse: 0.66503 | val_1_rmse: 0.66238 |  0:00:12s\n",
      "epoch 21 | loss: 0.44188 | val_0_rmse: 0.68655 | val_1_rmse: 0.66393 |  0:00:12s\n",
      "epoch 22 | loss: 0.43958 | val_0_rmse: 0.76985 | val_1_rmse: 0.66087 |  0:00:13s\n",
      "epoch 23 | loss: 0.44046 | val_0_rmse: 0.81979 | val_1_rmse: 0.65943 |  0:00:14s\n",
      "epoch 24 | loss: 0.43735 | val_0_rmse: 0.84991 | val_1_rmse: 0.65724 |  0:00:14s\n",
      "epoch 25 | loss: 0.43795 | val_0_rmse: 0.80675 | val_1_rmse: 0.65656 |  0:00:15s\n",
      "epoch 26 | loss: 0.43686 | val_0_rmse: 0.77792 | val_1_rmse: 0.65733 |  0:00:15s\n",
      "epoch 27 | loss: 0.43527 | val_0_rmse: 0.66034 | val_1_rmse: 0.6531  |  0:00:16s\n",
      "epoch 28 | loss: 0.43204 | val_0_rmse: 0.66615 | val_1_rmse: 0.6538  |  0:00:17s\n",
      "epoch 29 | loss: 0.43057 | val_0_rmse: 0.67352 | val_1_rmse: 0.65211 |  0:00:17s\n",
      "epoch 30 | loss: 0.43153 | val_0_rmse: 0.67103 | val_1_rmse: 0.6512  |  0:00:18s\n",
      "epoch 31 | loss: 0.43042 | val_0_rmse: 0.67055 | val_1_rmse: 0.65237 |  0:00:18s\n",
      "epoch 32 | loss: 0.42958 | val_0_rmse: 0.67227 | val_1_rmse: 0.6534  |  0:00:19s\n",
      "epoch 33 | loss: 0.42834 | val_0_rmse: 0.6747  | val_1_rmse: 0.65211 |  0:00:19s\n",
      "epoch 34 | loss: 0.42782 | val_0_rmse: 0.67605 | val_1_rmse: 0.66663 |  0:00:20s\n",
      "epoch 35 | loss: 0.42808 | val_0_rmse: 0.66142 | val_1_rmse: 0.65197 |  0:00:21s\n",
      "epoch 36 | loss: 0.42628 | val_0_rmse: 0.67697 | val_1_rmse: 0.65035 |  0:00:21s\n",
      "epoch 37 | loss: 0.42668 | val_0_rmse: 0.6565  | val_1_rmse: 0.65077 |  0:00:22s\n",
      "epoch 38 | loss: 0.426   | val_0_rmse: 0.66138 | val_1_rmse: 0.65113 |  0:00:22s\n",
      "epoch 39 | loss: 0.42614 | val_0_rmse: 0.6558  | val_1_rmse: 0.64988 |  0:00:23s\n",
      "epoch 40 | loss: 0.42515 | val_0_rmse: 0.65898 | val_1_rmse: 0.64925 |  0:00:24s\n",
      "epoch 41 | loss: 0.42532 | val_0_rmse: 0.6653  | val_1_rmse: 0.65517 |  0:00:24s\n",
      "epoch 42 | loss: 0.42603 | val_0_rmse: 0.65948 | val_1_rmse: 0.65151 |  0:00:25s\n",
      "epoch 43 | loss: 0.42436 | val_0_rmse: 0.6592  | val_1_rmse: 0.65039 |  0:00:25s\n",
      "epoch 44 | loss: 0.42382 | val_0_rmse: 0.65435 | val_1_rmse: 0.64951 |  0:00:26s\n",
      "epoch 45 | loss: 0.42404 | val_0_rmse: 0.66007 | val_1_rmse: 0.65119 |  0:00:27s\n",
      "epoch 46 | loss: 0.42346 | val_0_rmse: 0.65268 | val_1_rmse: 0.65053 |  0:00:27s\n",
      "epoch 47 | loss: 0.42441 | val_0_rmse: 0.65677 | val_1_rmse: 0.6506  |  0:00:28s\n",
      "epoch 48 | loss: 0.42342 | val_0_rmse: 0.65594 | val_1_rmse: 0.65097 |  0:00:28s\n",
      "epoch 49 | loss: 0.4247  | val_0_rmse: 0.65839 | val_1_rmse: 0.79164 |  0:00:29s\n",
      "epoch 50 | loss: 0.42317 | val_0_rmse: 0.65401 | val_1_rmse: 0.8257  |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_1_rmse = 0.64925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4343, Val Loss: 0.4215, RMSE: 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.23242 | val_0_rmse: 0.96211 | val_1_rmse: 0.95998 |  0:00:00s\n",
      "epoch 1  | loss: 3.06968 | val_0_rmse: 1.19665 | val_1_rmse: 0.98628 |  0:00:01s\n",
      "epoch 2  | loss: 2.02715 | val_0_rmse: 1.1634  | val_1_rmse: 1.05502 |  0:00:02s\n",
      "epoch 3  | loss: 1.43182 | val_0_rmse: 1.5556  | val_1_rmse: 1.01992 |  0:00:03s\n",
      "epoch 4  | loss: 1.0995  | val_0_rmse: 0.99631 | val_1_rmse: 1.17636 |  0:00:04s\n",
      "epoch 5  | loss: 0.89802 | val_0_rmse: 0.99617 | val_1_rmse: 1.13603 |  0:00:04s\n",
      "epoch 6  | loss: 0.74946 | val_0_rmse: 0.8514  | val_1_rmse: 0.88809 |  0:00:05s\n",
      "epoch 7  | loss: 0.67265 | val_0_rmse: 0.8796  | val_1_rmse: 0.85407 |  0:00:06s\n",
      "epoch 8  | loss: 0.62911 | val_0_rmse: 0.82224 | val_1_rmse: 0.79398 |  0:00:07s\n",
      "epoch 9  | loss: 0.59979 | val_0_rmse: 0.78147 | val_1_rmse: 0.75629 |  0:00:08s\n",
      "epoch 10 | loss: 0.58393 | val_0_rmse: 0.7515  | val_1_rmse: 0.73188 |  0:00:08s\n",
      "epoch 11 | loss: 0.56679 | val_0_rmse: 0.76764 | val_1_rmse: 0.72779 |  0:00:09s\n",
      "epoch 12 | loss: 0.55993 | val_0_rmse: 0.73997 | val_1_rmse: 0.72189 |  0:00:10s\n",
      "epoch 13 | loss: 0.55735 | val_0_rmse: 0.73102 | val_1_rmse: 0.71361 |  0:00:11s\n",
      "epoch 14 | loss: 0.54263 | val_0_rmse: 0.72294 | val_1_rmse: 0.71464 |  0:00:12s\n",
      "epoch 15 | loss: 0.53972 | val_0_rmse: 0.72545 | val_1_rmse: 0.73646 |  0:00:13s\n",
      "epoch 16 | loss: 0.53863 | val_0_rmse: 0.72589 | val_1_rmse: 0.71868 |  0:00:13s\n",
      "epoch 17 | loss: 0.53919 | val_0_rmse: 0.71878 | val_1_rmse: 0.70913 |  0:00:14s\n",
      "epoch 18 | loss: 0.52474 | val_0_rmse: 0.71339 | val_1_rmse: 0.70361 |  0:00:15s\n",
      "epoch 19 | loss: 0.51272 | val_0_rmse: 0.71671 | val_1_rmse: 0.70708 |  0:00:16s\n",
      "epoch 20 | loss: 0.50686 | val_0_rmse: 0.69598 | val_1_rmse: 0.68376 |  0:00:17s\n",
      "epoch 21 | loss: 0.4962  | val_0_rmse: 0.6872  | val_1_rmse: 0.68106 |  0:00:17s\n",
      "epoch 22 | loss: 0.4937  | val_0_rmse: 0.69263 | val_1_rmse: 0.81656 |  0:00:18s\n",
      "epoch 23 | loss: 0.48653 | val_0_rmse: 0.69834 | val_1_rmse: 0.68512 |  0:00:19s\n",
      "epoch 24 | loss: 0.49079 | val_0_rmse: 0.69803 | val_1_rmse: 0.68582 |  0:00:20s\n",
      "epoch 25 | loss: 0.48192 | val_0_rmse: 0.6944  | val_1_rmse: 0.69341 |  0:00:21s\n",
      "epoch 26 | loss: 0.47391 | val_0_rmse: 0.68639 | val_1_rmse: 0.68348 |  0:00:21s\n",
      "epoch 27 | loss: 0.47106 | val_0_rmse: 0.68501 | val_1_rmse: 1.53161 |  0:00:22s\n",
      "epoch 28 | loss: 0.46464 | val_0_rmse: 0.69518 | val_1_rmse: 0.71205 |  0:00:23s\n",
      "epoch 29 | loss: 0.46428 | val_0_rmse: 0.68508 | val_1_rmse: 0.6945  |  0:00:24s\n",
      "epoch 30 | loss: 0.4627  | val_0_rmse: 0.67555 | val_1_rmse: 0.67427 |  0:00:25s\n",
      "epoch 31 | loss: 0.4598  | val_0_rmse: 0.67808 | val_1_rmse: 0.67373 |  0:00:25s\n",
      "epoch 32 | loss: 0.45919 | val_0_rmse: 0.67647 | val_1_rmse: 0.6771  |  0:00:26s\n",
      "epoch 33 | loss: 0.45389 | val_0_rmse: 0.68166 | val_1_rmse: 0.67074 |  0:00:27s\n",
      "epoch 34 | loss: 0.45366 | val_0_rmse: 0.67664 | val_1_rmse: 0.6732  |  0:00:28s\n",
      "epoch 35 | loss: 0.45424 | val_0_rmse: 0.67793 | val_1_rmse: 0.6881  |  0:00:29s\n",
      "epoch 36 | loss: 0.45309 | val_0_rmse: 0.67489 | val_1_rmse: 0.68987 |  0:00:29s\n",
      "epoch 37 | loss: 0.45241 | val_0_rmse: 0.68157 | val_1_rmse: 0.69501 |  0:00:30s\n",
      "epoch 38 | loss: 0.45198 | val_0_rmse: 0.69348 | val_1_rmse: 0.69265 |  0:00:31s\n",
      "epoch 39 | loss: 0.45129 | val_0_rmse: 0.70497 | val_1_rmse: 0.72433 |  0:00:32s\n",
      "epoch 40 | loss: 0.45055 | val_0_rmse: 0.68946 | val_1_rmse: 0.71707 |  0:00:33s\n",
      "epoch 41 | loss: 0.45193 | val_0_rmse: 0.68487 | val_1_rmse: 0.76737 |  0:00:34s\n",
      "epoch 42 | loss: 0.45099 | val_0_rmse: 0.68596 | val_1_rmse: 0.71639 |  0:00:34s\n",
      "epoch 43 | loss: 0.44994 | val_0_rmse: 0.68226 | val_1_rmse: 0.70572 |  0:00:35s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_1_rmse = 0.67074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4647, Val Loss: 0.4499, RMSE: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.03167 | val_0_rmse: 1.02648 | val_1_rmse: 0.96114 |  0:00:00s\n",
      "epoch 1  | loss: 2.8731  | val_0_rmse: 1.83115 | val_1_rmse: 0.99549 |  0:00:01s\n",
      "epoch 2  | loss: 1.91738 | val_0_rmse: 2.09587 | val_1_rmse: 1.0358  |  0:00:02s\n",
      "epoch 3  | loss: 1.38871 | val_0_rmse: 1.67781 | val_1_rmse: 1.07463 |  0:00:03s\n",
      "epoch 4  | loss: 1.02856 | val_0_rmse: 1.32192 | val_1_rmse: 0.95689 |  0:00:04s\n",
      "epoch 5  | loss: 0.82233 | val_0_rmse: 0.9835  | val_1_rmse: 0.86832 |  0:00:04s\n",
      "epoch 6  | loss: 0.71749 | val_0_rmse: 0.86562 | val_1_rmse: 0.83146 |  0:00:05s\n",
      "epoch 7  | loss: 0.65911 | val_0_rmse: 0.81082 | val_1_rmse: 0.84372 |  0:00:06s\n",
      "epoch 8  | loss: 0.62139 | val_0_rmse: 0.77941 | val_1_rmse: 0.78755 |  0:00:07s\n",
      "epoch 9  | loss: 0.60317 | val_0_rmse: 0.77431 | val_1_rmse: 0.76151 |  0:00:08s\n",
      "epoch 10 | loss: 0.58325 | val_0_rmse: 0.76491 | val_1_rmse: 0.74748 |  0:00:09s\n",
      "epoch 11 | loss: 0.57538 | val_0_rmse: 0.74531 | val_1_rmse: 0.74556 |  0:00:09s\n",
      "epoch 12 | loss: 0.56138 | val_0_rmse: 0.72192 | val_1_rmse: 0.71951 |  0:00:10s\n",
      "epoch 13 | loss: 0.54172 | val_0_rmse: 0.73553 | val_1_rmse: 0.71912 |  0:00:11s\n",
      "epoch 14 | loss: 0.53056 | val_0_rmse: 0.69159 | val_1_rmse: 0.68713 |  0:00:12s\n",
      "epoch 15 | loss: 0.51014 | val_0_rmse: 0.68925 | val_1_rmse: 0.69002 |  0:00:13s\n",
      "epoch 16 | loss: 0.48956 | val_0_rmse: 0.68451 | val_1_rmse: 0.67893 |  0:00:14s\n",
      "epoch 17 | loss: 0.47549 | val_0_rmse: 0.69097 | val_1_rmse: 0.69361 |  0:00:14s\n",
      "epoch 18 | loss: 0.46741 | val_0_rmse: 0.68594 | val_1_rmse: 0.67792 |  0:00:15s\n",
      "epoch 19 | loss: 0.45828 | val_0_rmse: 0.68561 | val_1_rmse: 0.66871 |  0:00:16s\n",
      "epoch 20 | loss: 0.45137 | val_0_rmse: 0.67921 | val_1_rmse: 0.66229 |  0:00:17s\n",
      "epoch 21 | loss: 0.44643 | val_0_rmse: 0.68063 | val_1_rmse: 0.66928 |  0:00:18s\n",
      "epoch 22 | loss: 0.44417 | val_0_rmse: 0.66706 | val_1_rmse: 0.66069 |  0:00:18s\n",
      "epoch 23 | loss: 0.44216 | val_0_rmse: 0.6623  | val_1_rmse: 0.65782 |  0:00:19s\n",
      "epoch 24 | loss: 0.43822 | val_0_rmse: 0.66006 | val_1_rmse: 0.6676  |  0:00:20s\n",
      "epoch 25 | loss: 0.43933 | val_0_rmse: 0.6803  | val_1_rmse: 0.65688 |  0:00:21s\n",
      "epoch 26 | loss: 0.43778 | val_0_rmse: 0.67874 | val_1_rmse: 0.65545 |  0:00:22s\n",
      "epoch 27 | loss: 0.43601 | val_0_rmse: 0.6617  | val_1_rmse: 0.6593  |  0:00:23s\n",
      "epoch 28 | loss: 0.43393 | val_0_rmse: 0.65542 | val_1_rmse: 0.66082 |  0:00:23s\n",
      "epoch 29 | loss: 0.4337  | val_0_rmse: 0.65708 | val_1_rmse: 0.66135 |  0:00:24s\n",
      "epoch 30 | loss: 0.43192 | val_0_rmse: 0.65553 | val_1_rmse: 0.65545 |  0:00:25s\n",
      "epoch 31 | loss: 0.43108 | val_0_rmse: 0.66083 | val_1_rmse: 0.65617 |  0:00:26s\n",
      "epoch 32 | loss: 0.43057 | val_0_rmse: 0.65817 | val_1_rmse: 0.65278 |  0:00:27s\n",
      "epoch 33 | loss: 0.42944 | val_0_rmse: 0.65388 | val_1_rmse: 0.65089 |  0:00:27s\n",
      "epoch 34 | loss: 0.42995 | val_0_rmse: 0.65739 | val_1_rmse: 0.65439 |  0:00:28s\n",
      "epoch 35 | loss: 0.42883 | val_0_rmse: 0.65735 | val_1_rmse: 0.65557 |  0:00:29s\n",
      "epoch 36 | loss: 0.42798 | val_0_rmse: 0.65637 | val_1_rmse: 0.65834 |  0:00:30s\n",
      "epoch 37 | loss: 0.42843 | val_0_rmse: 0.65916 | val_1_rmse: 0.65899 |  0:00:31s\n",
      "epoch 38 | loss: 0.42838 | val_0_rmse: 0.65852 | val_1_rmse: 0.65792 |  0:00:31s\n",
      "epoch 39 | loss: 0.42855 | val_0_rmse: 0.65339 | val_1_rmse: 0.65112 |  0:00:32s\n",
      "epoch 40 | loss: 0.42851 | val_0_rmse: 0.65361 | val_1_rmse: 0.65187 |  0:00:33s\n",
      "epoch 41 | loss: 0.42851 | val_0_rmse: 0.6533  | val_1_rmse: 0.65038 |  0:00:34s\n",
      "epoch 42 | loss: 0.42802 | val_0_rmse: 0.65419 | val_1_rmse: 0.65292 |  0:00:35s\n",
      "epoch 43 | loss: 0.42673 | val_0_rmse: 0.65187 | val_1_rmse: 0.64879 |  0:00:35s\n",
      "epoch 44 | loss: 0.42627 | val_0_rmse: 0.65446 | val_1_rmse: 0.65229 |  0:00:36s\n",
      "epoch 45 | loss: 0.42611 | val_0_rmse: 0.65527 | val_1_rmse: 0.64975 |  0:00:37s\n",
      "epoch 46 | loss: 0.42637 | val_0_rmse: 0.65333 | val_1_rmse: 0.64924 |  0:00:38s\n",
      "epoch 47 | loss: 0.42563 | val_0_rmse: 0.65408 | val_1_rmse: 0.64802 |  0:00:39s\n",
      "epoch 48 | loss: 0.42511 | val_0_rmse: 0.65198 | val_1_rmse: 0.65297 |  0:00:40s\n",
      "epoch 49 | loss: 0.42613 | val_0_rmse: 0.65367 | val_1_rmse: 0.64929 |  0:00:40s\n",
      "epoch 50 | loss: 0.4252  | val_0_rmse: 0.65486 | val_1_rmse: 0.65072 |  0:00:41s\n",
      "epoch 51 | loss: 0.42507 | val_0_rmse: 0.6554  | val_1_rmse: 0.64873 |  0:00:42s\n",
      "epoch 52 | loss: 0.42536 | val_0_rmse: 0.65472 | val_1_rmse: 0.64945 |  0:00:43s\n",
      "epoch 53 | loss: 0.42504 | val_0_rmse: 0.65276 | val_1_rmse: 0.64878 |  0:00:44s\n",
      "epoch 54 | loss: 0.4247  | val_0_rmse: 0.6555  | val_1_rmse: 0.64962 |  0:00:44s\n",
      "epoch 55 | loss: 0.42385 | val_0_rmse: 0.6595  | val_1_rmse: 0.65114 |  0:00:45s\n",
      "epoch 56 | loss: 0.42344 | val_0_rmse: 0.65864 | val_1_rmse: 0.65382 |  0:00:46s\n",
      "epoch 57 | loss: 0.42307 | val_0_rmse: 0.65633 | val_1_rmse: 0.65148 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 47 and best_val_1_rmse = 0.64802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4278, Val Loss: 0.4199, RMSE: 0.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 20.23121| val_0_rmse: 2.32818 | val_1_rmse: 1.41595 |  0:00:01s\n",
      "epoch 1  | loss: 18.56586| val_0_rmse: 2.80437 | val_1_rmse: 2.65761 |  0:00:02s\n",
      "epoch 2  | loss: 16.40838| val_0_rmse: 5.57805 | val_1_rmse: 5.26557 |  0:00:04s\n",
      "epoch 3  | loss: 13.6436 | val_0_rmse: 3.3148  | val_1_rmse: 8.30055 |  0:00:05s\n",
      "epoch 4  | loss: 10.14461| val_0_rmse: 3.92485 | val_1_rmse: 4.63069 |  0:00:06s\n",
      "epoch 5  | loss: 7.91432 | val_0_rmse: 3.42822 | val_1_rmse: 2.85281 |  0:00:08s\n",
      "epoch 6  | loss: 6.89024 | val_0_rmse: 4.50514 | val_1_rmse: 3.01204 |  0:00:09s\n",
      "epoch 7  | loss: 6.48222 | val_0_rmse: 3.27943 | val_1_rmse: 2.98312 |  0:00:11s\n",
      "epoch 8  | loss: 5.95815 | val_0_rmse: 3.43803 | val_1_rmse: 6.33103 |  0:00:12s\n",
      "epoch 9  | loss: 5.35096 | val_0_rmse: 4.70395 | val_1_rmse: 2.98181 |  0:00:13s\n",
      "epoch 10 | loss: 4.54428 | val_0_rmse: 3.52694 | val_1_rmse: 2.90574 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.41595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 5.4204, Val Loss: 2.0049, RMSE: 1.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 20.63812| val_0_rmse: 1.66908 | val_1_rmse: 1.45577 |  0:00:01s\n",
      "epoch 1  | loss: 18.90732| val_0_rmse: 2.04515 | val_1_rmse: 1.40421 |  0:00:02s\n",
      "epoch 2  | loss: 16.09416| val_0_rmse: 3.71259 | val_1_rmse: 4.37065 |  0:00:04s\n",
      "epoch 3  | loss: 12.37631| val_0_rmse: 3.91437 | val_1_rmse: 2.92485 |  0:00:05s\n",
      "epoch 4  | loss: 9.55448 | val_0_rmse: 3.64573 | val_1_rmse: 3.39103 |  0:00:06s\n",
      "epoch 5  | loss: 8.22685 | val_0_rmse: 4.89939 | val_1_rmse: 2.71369 |  0:00:08s\n",
      "epoch 6  | loss: 7.35821 | val_0_rmse: 5.11827 | val_1_rmse: 2.96431 |  0:00:09s\n",
      "epoch 7  | loss: 7.20074 | val_0_rmse: 4.20379 | val_1_rmse: 3.3849  |  0:00:11s\n",
      "epoch 8  | loss: 6.8156  | val_0_rmse: 3.21233 | val_1_rmse: 4.85353 |  0:00:12s\n",
      "epoch 9  | loss: 6.22125 | val_0_rmse: 3.71954 | val_1_rmse: 2.28092 |  0:00:13s\n",
      "epoch 10 | loss: 5.22624 | val_0_rmse: 3.21864 | val_1_rmse: 3.70292 |  0:00:15s\n",
      "epoch 11 | loss: 4.22599 | val_0_rmse: 2.99563 | val_1_rmse: 4.33122 |  0:00:16s\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_1_rmse = 1.40421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 8, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 4.1827, Val Loss: 1.9718, RMSE: 1.4042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.66684 | val_0_rmse: 1.03038 | val_1_rmse: 0.98354 |  0:00:00s\n",
      "epoch 1  | loss: 2.04582 | val_0_rmse: 1.48849 | val_1_rmse: 1.0328  |  0:00:01s\n",
      "epoch 2  | loss: 1.51722 | val_0_rmse: 1.61123 | val_1_rmse: 1.12217 |  0:00:01s\n",
      "epoch 3  | loss: 1.12104 | val_0_rmse: 1.20278 | val_1_rmse: 1.43556 |  0:00:02s\n",
      "epoch 4  | loss: 0.86942 | val_0_rmse: 0.97137 | val_1_rmse: 0.87129 |  0:00:02s\n",
      "epoch 5  | loss: 0.7151  | val_0_rmse: 1.14773 | val_1_rmse: 0.81559 |  0:00:03s\n",
      "epoch 6  | loss: 0.62555 | val_0_rmse: 0.86647 | val_1_rmse: 0.77491 |  0:00:04s\n",
      "epoch 7  | loss: 0.55832 | val_0_rmse: 0.78945 | val_1_rmse: 0.71074 |  0:00:04s\n",
      "epoch 8  | loss: 0.52334 | val_0_rmse: 0.73908 | val_1_rmse: 0.71195 |  0:00:05s\n",
      "epoch 9  | loss: 0.49547 | val_0_rmse: 0.7523  | val_1_rmse: 0.70107 |  0:00:05s\n",
      "epoch 10 | loss: 0.48851 | val_0_rmse: 0.7343  | val_1_rmse: 0.70069 |  0:00:06s\n",
      "epoch 11 | loss: 0.48039 | val_0_rmse: 0.71176 | val_1_rmse: 0.69333 |  0:00:06s\n",
      "epoch 12 | loss: 0.47702 | val_0_rmse: 0.69397 | val_1_rmse: 0.67701 |  0:00:07s\n",
      "epoch 13 | loss: 0.47189 | val_0_rmse: 0.72672 | val_1_rmse: 0.68573 |  0:00:08s\n",
      "epoch 14 | loss: 0.47004 | val_0_rmse: 0.69075 | val_1_rmse: 0.68634 |  0:00:08s\n",
      "epoch 15 | loss: 0.46627 | val_0_rmse: 0.67899 | val_1_rmse: 0.6813  |  0:00:09s\n",
      "epoch 16 | loss: 0.46609 | val_0_rmse: 0.69102 | val_1_rmse: 0.67587 |  0:00:09s\n",
      "epoch 17 | loss: 0.46321 | val_0_rmse: 0.68531 | val_1_rmse: 0.66923 |  0:00:10s\n",
      "epoch 18 | loss: 0.4621  | val_0_rmse: 0.68132 | val_1_rmse: 0.66871 |  0:00:11s\n",
      "epoch 19 | loss: 0.4587  | val_0_rmse: 0.70799 | val_1_rmse: 0.66803 |  0:00:11s\n",
      "epoch 20 | loss: 0.45801 | val_0_rmse: 0.69403 | val_1_rmse: 0.66949 |  0:00:12s\n",
      "epoch 21 | loss: 0.45669 | val_0_rmse: 0.67922 | val_1_rmse: 0.67367 |  0:00:12s\n",
      "epoch 22 | loss: 0.45392 | val_0_rmse: 0.67738 | val_1_rmse: 0.67159 |  0:00:13s\n",
      "epoch 23 | loss: 0.45459 | val_0_rmse: 0.67217 | val_1_rmse: 0.66756 |  0:00:13s\n",
      "epoch 24 | loss: 0.45544 | val_0_rmse: 0.67543 | val_1_rmse: 0.67218 |  0:00:14s\n",
      "epoch 25 | loss: 0.45243 | val_0_rmse: 0.68289 | val_1_rmse: 0.66811 |  0:00:15s\n",
      "epoch 26 | loss: 0.45017 | val_0_rmse: 0.67674 | val_1_rmse: 0.66615 |  0:00:15s\n",
      "epoch 27 | loss: 0.45033 | val_0_rmse: 0.68048 | val_1_rmse: 0.66503 |  0:00:16s\n",
      "epoch 28 | loss: 0.44872 | val_0_rmse: 0.68582 | val_1_rmse: 0.66507 |  0:00:16s\n",
      "epoch 29 | loss: 0.44677 | val_0_rmse: 0.68556 | val_1_rmse: 0.66444 |  0:00:17s\n",
      "epoch 30 | loss: 0.4432  | val_0_rmse: 0.68046 | val_1_rmse: 0.6635  |  0:00:18s\n",
      "epoch 31 | loss: 0.4466  | val_0_rmse: 0.67281 | val_1_rmse: 0.66389 |  0:00:18s\n",
      "epoch 32 | loss: 0.44206 | val_0_rmse: 0.66681 | val_1_rmse: 1.26121 |  0:00:19s\n",
      "epoch 33 | loss: 0.44247 | val_0_rmse: 0.66741 | val_1_rmse: 0.66271 |  0:00:19s\n",
      "epoch 34 | loss: 0.44146 | val_0_rmse: 0.66733 | val_1_rmse: 0.66337 |  0:00:20s\n",
      "epoch 35 | loss: 0.43977 | val_0_rmse: 0.66808 | val_1_rmse: 0.66233 |  0:00:20s\n",
      "epoch 36 | loss: 0.43898 | val_0_rmse: 0.66544 | val_1_rmse: 0.66133 |  0:00:21s\n",
      "epoch 37 | loss: 0.43854 | val_0_rmse: 0.66479 | val_1_rmse: 0.69095 |  0:00:22s\n",
      "epoch 38 | loss: 0.43781 | val_0_rmse: 0.66353 | val_1_rmse: 0.68345 |  0:00:22s\n",
      "epoch 39 | loss: 0.43501 | val_0_rmse: 0.66072 | val_1_rmse: 0.69896 |  0:00:23s\n",
      "epoch 40 | loss: 0.43491 | val_0_rmse: 0.66132 | val_1_rmse: 0.69514 |  0:00:23s\n",
      "epoch 41 | loss: 0.4318  | val_0_rmse: 0.6612  | val_1_rmse: 0.71511 |  0:00:24s\n",
      "epoch 42 | loss: 0.43265 | val_0_rmse: 0.65968 | val_1_rmse: 0.75154 |  0:00:25s\n",
      "epoch 43 | loss: 0.4327  | val_0_rmse: 0.66082 | val_1_rmse: 0.67011 |  0:00:25s\n",
      "epoch 44 | loss: 0.43395 | val_0_rmse: 0.65946 | val_1_rmse: 0.69836 |  0:00:26s\n",
      "epoch 45 | loss: 0.43194 | val_0_rmse: 0.6598  | val_1_rmse: 0.73201 |  0:00:26s\n",
      "epoch 46 | loss: 0.43348 | val_0_rmse: 0.6582  | val_1_rmse: 0.68473 |  0:00:27s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_1_rmse = 0.66133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4428, Val Loss: 0.4374, RMSE: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.59057 | val_0_rmse: 1.02571 | val_1_rmse: 0.95168 |  0:00:00s\n",
      "epoch 1  | loss: 2.21214 | val_0_rmse: 1.64197 | val_1_rmse: 1.0037  |  0:00:01s\n",
      "epoch 2  | loss: 1.58791 | val_0_rmse: 1.69732 | val_1_rmse: 1.11784 |  0:00:01s\n",
      "epoch 3  | loss: 1.2056  | val_0_rmse: 1.30817 | val_1_rmse: 0.97346 |  0:00:02s\n",
      "epoch 4  | loss: 0.92878 | val_0_rmse: 1.12976 | val_1_rmse: 1.34239 |  0:00:03s\n",
      "epoch 5  | loss: 0.76776 | val_0_rmse: 0.90905 | val_1_rmse: 1.07398 |  0:00:03s\n",
      "epoch 6  | loss: 0.68237 | val_0_rmse: 0.83456 | val_1_rmse: 0.93675 |  0:00:04s\n",
      "epoch 7  | loss: 0.62933 | val_0_rmse: 0.79846 | val_1_rmse: 0.90593 |  0:00:04s\n",
      "epoch 8  | loss: 0.56687 | val_0_rmse: 0.77646 | val_1_rmse: 0.92968 |  0:00:05s\n",
      "epoch 9  | loss: 0.5217  | val_0_rmse: 0.7332  | val_1_rmse: 0.80024 |  0:00:05s\n",
      "epoch 10 | loss: 0.49866 | val_0_rmse: 0.72254 | val_1_rmse: 0.77581 |  0:00:06s\n",
      "epoch 11 | loss: 0.48415 | val_0_rmse: 0.7317  | val_1_rmse: 0.7839  |  0:00:07s\n",
      "epoch 12 | loss: 0.477   | val_0_rmse: 0.71297 | val_1_rmse: 0.77481 |  0:00:07s\n",
      "epoch 13 | loss: 0.47013 | val_0_rmse: 0.70974 | val_1_rmse: 0.80119 |  0:00:08s\n",
      "epoch 14 | loss: 0.46557 | val_0_rmse: 0.68699 | val_1_rmse: 0.72253 |  0:00:08s\n",
      "epoch 15 | loss: 0.46155 | val_0_rmse: 0.70098 | val_1_rmse: 0.74491 |  0:00:09s\n",
      "epoch 16 | loss: 0.45721 | val_0_rmse: 0.68735 | val_1_rmse: 0.728   |  0:00:10s\n",
      "epoch 17 | loss: 0.4566  | val_0_rmse: 0.69916 | val_1_rmse: 0.77901 |  0:00:10s\n",
      "epoch 18 | loss: 0.45743 | val_0_rmse: 0.69661 | val_1_rmse: 0.76711 |  0:00:11s\n",
      "epoch 19 | loss: 0.45466 | val_0_rmse: 0.69327 | val_1_rmse: 0.75395 |  0:00:11s\n",
      "epoch 20 | loss: 0.45085 | val_0_rmse: 0.6722  | val_1_rmse: 0.73324 |  0:00:12s\n",
      "epoch 21 | loss: 0.45177 | val_0_rmse: 0.67262 | val_1_rmse: 0.83039 |  0:00:13s\n",
      "epoch 22 | loss: 0.44916 | val_0_rmse: 0.67904 | val_1_rmse: 0.83567 |  0:00:13s\n",
      "epoch 23 | loss: 0.44813 | val_0_rmse: 0.67729 | val_1_rmse: 0.72833 |  0:00:14s\n",
      "epoch 24 | loss: 0.44585 | val_0_rmse: 0.67838 | val_1_rmse: 0.73876 |  0:00:14s\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_1_rmse = 0.72253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4720, Val Loss: 0.5221, RMSE: 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.34889 | val_0_rmse: 1.57843 | val_1_rmse: 1.16818 |  0:00:00s\n",
      "epoch 1  | loss: 2.81097 | val_0_rmse: 1.96639 | val_1_rmse: 1.3795  |  0:00:01s\n",
      "epoch 2  | loss: 2.06354 | val_0_rmse: 1.4438  | val_1_rmse: 1.20822 |  0:00:02s\n",
      "epoch 3  | loss: 1.48275 | val_0_rmse: 1.30285 | val_1_rmse: 1.20187 |  0:00:03s\n",
      "epoch 4  | loss: 1.06383 | val_0_rmse: 1.86098 | val_1_rmse: 1.01656 |  0:00:04s\n",
      "epoch 5  | loss: 0.83702 | val_0_rmse: 1.0304  | val_1_rmse: 0.86966 |  0:00:04s\n",
      "epoch 6  | loss: 0.71838 | val_0_rmse: 1.03495 | val_1_rmse: 0.9605  |  0:00:05s\n",
      "epoch 7  | loss: 0.66781 | val_0_rmse: 0.85722 | val_1_rmse: 0.83057 |  0:00:06s\n",
      "epoch 8  | loss: 0.64456 | val_0_rmse: 0.80332 | val_1_rmse: 0.81951 |  0:00:07s\n",
      "epoch 9  | loss: 0.63046 | val_0_rmse: 0.80206 | val_1_rmse: 0.80212 |  0:00:08s\n",
      "epoch 10 | loss: 0.61797 | val_0_rmse: 0.7918  | val_1_rmse: 0.77561 |  0:00:09s\n",
      "epoch 11 | loss: 0.59748 | val_0_rmse: 0.78434 | val_1_rmse: 0.76367 |  0:00:09s\n",
      "epoch 12 | loss: 0.56546 | val_0_rmse: 0.76845 | val_1_rmse: 0.7306  |  0:00:10s\n",
      "epoch 13 | loss: 0.52018 | val_0_rmse: 0.73505 | val_1_rmse: 0.73089 |  0:00:11s\n",
      "epoch 14 | loss: 0.50536 | val_0_rmse: 0.7227  | val_1_rmse: 0.70748 |  0:00:12s\n",
      "epoch 15 | loss: 0.49187 | val_0_rmse: 0.71645 | val_1_rmse: 0.69852 |  0:00:13s\n",
      "epoch 16 | loss: 0.48839 | val_0_rmse: 0.72338 | val_1_rmse: 0.68967 |  0:00:13s\n",
      "epoch 17 | loss: 0.48155 | val_0_rmse: 0.75603 | val_1_rmse: 0.68683 |  0:00:14s\n",
      "epoch 18 | loss: 0.47961 | val_0_rmse: 0.71727 | val_1_rmse: 0.69466 |  0:00:15s\n",
      "epoch 19 | loss: 0.48207 | val_0_rmse: 0.75092 | val_1_rmse: 0.72634 |  0:00:16s\n",
      "epoch 20 | loss: 0.48778 | val_0_rmse: 0.75507 | val_1_rmse: 0.7403  |  0:00:17s\n",
      "epoch 21 | loss: 0.4769  | val_0_rmse: 0.79313 | val_1_rmse: 1.00817 |  0:00:17s\n",
      "epoch 22 | loss: 0.46842 | val_0_rmse: 0.72934 | val_1_rmse: 0.74273 |  0:00:18s\n",
      "epoch 23 | loss: 0.46358 | val_0_rmse: 0.70466 | val_1_rmse: 0.7093  |  0:00:19s\n",
      "epoch 24 | loss: 0.46159 | val_0_rmse: 0.69996 | val_1_rmse: 0.69909 |  0:00:20s\n",
      "epoch 25 | loss: 0.45824 | val_0_rmse: 0.72008 | val_1_rmse: 0.77065 |  0:00:21s\n",
      "epoch 26 | loss: 0.45638 | val_0_rmse: 0.69521 | val_1_rmse: 0.68281 |  0:00:22s\n",
      "epoch 27 | loss: 0.45636 | val_0_rmse: 0.70432 | val_1_rmse: 0.71098 |  0:00:23s\n",
      "epoch 28 | loss: 0.45654 | val_0_rmse: 0.68638 | val_1_rmse: 0.67478 |  0:00:23s\n",
      "epoch 29 | loss: 0.4498  | val_0_rmse: 0.68462 | val_1_rmse: 0.67152 |  0:00:24s\n",
      "epoch 30 | loss: 0.44727 | val_0_rmse: 0.68313 | val_1_rmse: 0.66027 |  0:00:25s\n",
      "epoch 31 | loss: 0.44513 | val_0_rmse: 0.708   | val_1_rmse: 0.71932 |  0:00:26s\n",
      "epoch 32 | loss: 0.44194 | val_0_rmse: 0.70819 | val_1_rmse: 0.66878 |  0:00:27s\n",
      "epoch 33 | loss: 0.44188 | val_0_rmse: 0.74679 | val_1_rmse: 0.6733  |  0:00:28s\n",
      "epoch 34 | loss: 0.44054 | val_0_rmse: 0.70455 | val_1_rmse: 0.69697 |  0:00:29s\n",
      "epoch 35 | loss: 0.44017 | val_0_rmse: 0.70319 | val_1_rmse: 0.72254 |  0:00:29s\n",
      "epoch 36 | loss: 0.4386  | val_0_rmse: 0.68077 | val_1_rmse: 0.7055  |  0:00:30s\n",
      "epoch 37 | loss: 0.43839 | val_0_rmse: 0.68669 | val_1_rmse: 0.69727 |  0:00:31s\n",
      "epoch 38 | loss: 0.43734 | val_0_rmse: 0.68263 | val_1_rmse: 0.6799  |  0:00:32s\n",
      "epoch 39 | loss: 0.4373  | val_0_rmse: 0.67293 | val_1_rmse: 0.6902  |  0:00:33s\n",
      "epoch 40 | loss: 0.43558 | val_0_rmse: 0.67027 | val_1_rmse: 0.66653 |  0:00:34s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_1_rmse = 0.66027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4667, Val Loss: 0.4359, RMSE: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.21852 | val_0_rmse: 1.30924 | val_1_rmse: 1.02903 |  0:00:00s\n",
      "epoch 1  | loss: 2.7981  | val_0_rmse: 1.3666  | val_1_rmse: 1.18331 |  0:00:01s\n",
      "epoch 2  | loss: 1.85825 | val_0_rmse: 1.38691 | val_1_rmse: 1.00406 |  0:00:02s\n",
      "epoch 3  | loss: 1.32476 | val_0_rmse: 1.21011 | val_1_rmse: 1.14123 |  0:00:03s\n",
      "epoch 4  | loss: 1.00395 | val_0_rmse: 0.91014 | val_1_rmse: 0.90286 |  0:00:04s\n",
      "epoch 5  | loss: 0.81055 | val_0_rmse: 1.21538 | val_1_rmse: 0.82353 |  0:00:04s\n",
      "epoch 6  | loss: 0.71504 | val_0_rmse: 0.93724 | val_1_rmse: 0.8198  |  0:00:05s\n",
      "epoch 7  | loss: 0.66615 | val_0_rmse: 0.81653 | val_1_rmse: 0.8188  |  0:00:06s\n",
      "epoch 8  | loss: 0.64462 | val_0_rmse: 0.83601 | val_1_rmse: 0.83019 |  0:00:07s\n",
      "epoch 9  | loss: 0.62211 | val_0_rmse: 0.79012 | val_1_rmse: 0.79914 |  0:00:08s\n",
      "epoch 10 | loss: 0.6027  | val_0_rmse: 0.74799 | val_1_rmse: 0.74841 |  0:00:09s\n",
      "epoch 11 | loss: 0.58354 | val_0_rmse: 0.73949 | val_1_rmse: 0.72839 |  0:00:09s\n",
      "epoch 12 | loss: 0.56321 | val_0_rmse: 0.73047 | val_1_rmse: 0.7213  |  0:00:10s\n",
      "epoch 13 | loss: 0.51772 | val_0_rmse: 0.70867 | val_1_rmse: 0.69723 |  0:00:11s\n",
      "epoch 14 | loss: 0.49336 | val_0_rmse: 0.72749 | val_1_rmse: 0.70607 |  0:00:12s\n",
      "epoch 15 | loss: 0.4968  | val_0_rmse: 0.70203 | val_1_rmse: 0.69638 |  0:00:13s\n",
      "epoch 16 | loss: 0.48752 | val_0_rmse: 0.71148 | val_1_rmse: 0.74153 |  0:00:13s\n",
      "epoch 17 | loss: 0.48321 | val_0_rmse: 0.71701 | val_1_rmse: 0.68974 |  0:00:14s\n",
      "epoch 18 | loss: 0.478   | val_0_rmse: 0.69866 | val_1_rmse: 0.69176 |  0:00:15s\n",
      "epoch 19 | loss: 0.47122 | val_0_rmse: 0.68623 | val_1_rmse: 0.68574 |  0:00:16s\n",
      "epoch 20 | loss: 0.46604 | val_0_rmse: 0.69515 | val_1_rmse: 0.68677 |  0:00:17s\n",
      "epoch 21 | loss: 0.46267 | val_0_rmse: 0.70673 | val_1_rmse: 0.86345 |  0:00:18s\n",
      "epoch 22 | loss: 0.46072 | val_0_rmse: 0.70047 | val_1_rmse: 0.69602 |  0:00:18s\n",
      "epoch 23 | loss: 0.46447 | val_0_rmse: 0.70634 | val_1_rmse: 0.74528 |  0:00:19s\n",
      "epoch 24 | loss: 0.45879 | val_0_rmse: 0.68672 | val_1_rmse: 0.82749 |  0:00:20s\n",
      "epoch 25 | loss: 0.4525  | val_0_rmse: 0.70136 | val_1_rmse: 0.88465 |  0:00:21s\n",
      "epoch 26 | loss: 0.44973 | val_0_rmse: 0.69065 | val_1_rmse: 0.79055 |  0:00:22s\n",
      "epoch 27 | loss: 0.44879 | val_0_rmse: 0.68131 | val_1_rmse: 0.67968 |  0:00:22s\n",
      "epoch 28 | loss: 0.44977 | val_0_rmse: 0.68812 | val_1_rmse: 0.68263 |  0:00:23s\n",
      "epoch 29 | loss: 0.44798 | val_0_rmse: 0.69899 | val_1_rmse: 0.68103 |  0:00:24s\n",
      "epoch 30 | loss: 0.44852 | val_0_rmse: 0.69001 | val_1_rmse: 0.67768 |  0:00:25s\n",
      "epoch 31 | loss: 0.44796 | val_0_rmse: 0.69364 | val_1_rmse: 0.6823  |  0:00:26s\n",
      "epoch 32 | loss: 0.44591 | val_0_rmse: 0.69164 | val_1_rmse: 0.68454 |  0:00:26s\n",
      "epoch 33 | loss: 0.44442 | val_0_rmse: 0.70189 | val_1_rmse: 0.68904 |  0:00:27s\n",
      "epoch 34 | loss: 0.44731 | val_0_rmse: 0.70854 | val_1_rmse: 0.70331 |  0:00:28s\n",
      "epoch 35 | loss: 0.4445  | val_0_rmse: 0.67935 | val_1_rmse: 0.69502 |  0:00:29s\n",
      "epoch 36 | loss: 0.44664 | val_0_rmse: 0.68222 | val_1_rmse: 0.68863 |  0:00:30s\n",
      "epoch 37 | loss: 0.446   | val_0_rmse: 0.6776  | val_1_rmse: 0.6874  |  0:00:30s\n",
      "epoch 38 | loss: 0.44259 | val_0_rmse: 0.69886 | val_1_rmse: 0.69485 |  0:00:31s\n",
      "epoch 39 | loss: 0.44182 | val_0_rmse: 0.72082 | val_1_rmse: 0.68741 |  0:00:32s\n",
      "epoch 40 | loss: 0.43956 | val_0_rmse: 0.67963 | val_1_rmse: 0.67269 |  0:00:33s\n",
      "epoch 41 | loss: 0.43804 | val_0_rmse: 0.69174 | val_1_rmse: 0.68268 |  0:00:33s\n",
      "epoch 42 | loss: 0.44008 | val_0_rmse: 0.70042 | val_1_rmse: 0.68082 |  0:00:34s\n",
      "epoch 43 | loss: 0.4399  | val_0_rmse: 0.70743 | val_1_rmse: 0.69021 |  0:00:35s\n",
      "epoch 44 | loss: 0.43902 | val_0_rmse: 0.68817 | val_1_rmse: 0.6844  |  0:00:36s\n",
      "epoch 45 | loss: 0.43739 | val_0_rmse: 0.68663 | val_1_rmse: 0.69538 |  0:00:37s\n",
      "epoch 46 | loss: 0.43547 | val_0_rmse: 0.6942  | val_1_rmse: 0.68739 |  0:00:37s\n",
      "epoch 47 | loss: 0.43794 | val_0_rmse: 0.67459 | val_1_rmse: 0.6777  |  0:00:38s\n",
      "epoch 48 | loss: 0.43663 | val_0_rmse: 0.68479 | val_1_rmse: 0.69206 |  0:00:39s\n",
      "epoch 49 | loss: 0.43673 | val_0_rmse: 0.67977 | val_1_rmse: 0.66009 |  0:00:40s\n",
      "epoch 50 | loss: 0.43512 | val_0_rmse: 0.71226 | val_1_rmse: 0.66159 |  0:00:41s\n",
      "epoch 51 | loss: 0.4343  | val_0_rmse: 0.68178 | val_1_rmse: 0.65867 |  0:00:41s\n",
      "epoch 52 | loss: 0.4343  | val_0_rmse: 0.7049  | val_1_rmse: 0.65821 |  0:00:42s\n",
      "epoch 53 | loss: 0.43193 | val_0_rmse: 0.6967  | val_1_rmse: 0.65917 |  0:00:43s\n",
      "epoch 54 | loss: 0.43213 | val_0_rmse: 0.72899 | val_1_rmse: 0.65903 |  0:00:44s\n",
      "epoch 55 | loss: 0.43275 | val_0_rmse: 0.75067 | val_1_rmse: 0.65958 |  0:00:45s\n",
      "epoch 56 | loss: 0.43342 | val_0_rmse: 0.686   | val_1_rmse: 0.65826 |  0:00:45s\n",
      "epoch 57 | loss: 0.43178 | val_0_rmse: 0.68269 | val_1_rmse: 0.65356 |  0:00:46s\n",
      "epoch 58 | loss: 0.43148 | val_0_rmse: 0.69915 | val_1_rmse: 0.65396 |  0:00:47s\n",
      "epoch 59 | loss: 0.43061 | val_0_rmse: 0.66953 | val_1_rmse: 0.65331 |  0:00:48s\n",
      "epoch 60 | loss: 0.42927 | val_0_rmse: 0.67933 | val_1_rmse: 0.66619 |  0:00:49s\n",
      "epoch 61 | loss: 0.42824 | val_0_rmse: 0.68639 | val_1_rmse: 0.67491 |  0:00:49s\n",
      "epoch 62 | loss: 0.42874 | val_0_rmse: 0.66789 | val_1_rmse: 0.65441 |  0:00:50s\n",
      "epoch 63 | loss: 0.42673 | val_0_rmse: 0.67951 | val_1_rmse: 0.65297 |  0:00:51s\n",
      "epoch 64 | loss: 0.4261  | val_0_rmse: 0.6967  | val_1_rmse: 0.65191 |  0:00:52s\n",
      "epoch 65 | loss: 0.42717 | val_0_rmse: 0.66828 | val_1_rmse: 0.65155 |  0:00:53s\n",
      "epoch 66 | loss: 0.42611 | val_0_rmse: 0.67181 | val_1_rmse: 0.6532  |  0:00:53s\n",
      "epoch 67 | loss: 0.42666 | val_0_rmse: 0.68723 | val_1_rmse: 0.65133 |  0:00:54s\n",
      "epoch 68 | loss: 0.42535 | val_0_rmse: 0.67089 | val_1_rmse: 0.70137 |  0:00:55s\n",
      "epoch 69 | loss: 0.42406 | val_0_rmse: 0.67558 | val_1_rmse: 0.67798 |  0:00:56s\n",
      "epoch 70 | loss: 0.42488 | val_0_rmse: 0.66837 | val_1_rmse: 0.67339 |  0:00:57s\n",
      "epoch 71 | loss: 0.4252  | val_0_rmse: 0.66945 | val_1_rmse: 0.68149 |  0:00:57s\n",
      "epoch 72 | loss: 0.42611 | val_0_rmse: 0.66    | val_1_rmse: 0.66534 |  0:00:58s\n",
      "epoch 73 | loss: 0.42403 | val_0_rmse: 0.65708 | val_1_rmse: 0.65597 |  0:00:59s\n",
      "epoch 74 | loss: 0.42525 | val_0_rmse: 0.65336 | val_1_rmse: 0.65293 |  0:01:00s\n",
      "epoch 75 | loss: 0.42393 | val_0_rmse: 0.65718 | val_1_rmse: 0.65163 |  0:01:01s\n",
      "epoch 76 | loss: 0.42492 | val_0_rmse: 0.65657 | val_1_rmse: 0.65084 |  0:01:01s\n",
      "epoch 77 | loss: 0.42345 | val_0_rmse: 0.65394 | val_1_rmse: 0.65186 |  0:01:02s\n",
      "epoch 78 | loss: 0.42311 | val_0_rmse: 0.65963 | val_1_rmse: 0.65078 |  0:01:03s\n",
      "epoch 79 | loss: 0.42371 | val_0_rmse: 0.65478 | val_1_rmse: 0.65366 |  0:01:04s\n",
      "epoch 80 | loss: 0.42232 | val_0_rmse: 0.65604 | val_1_rmse: 0.67309 |  0:01:05s\n",
      "epoch 81 | loss: 0.42354 | val_0_rmse: 0.65152 | val_1_rmse: 0.65041 |  0:01:06s\n",
      "epoch 82 | loss: 0.42264 | val_0_rmse: 0.65245 | val_1_rmse: 0.6503  |  0:01:06s\n",
      "epoch 83 | loss: 0.4231  | val_0_rmse: 0.65253 | val_1_rmse: 0.65294 |  0:01:07s\n",
      "epoch 84 | loss: 0.42192 | val_0_rmse: 0.65205 | val_1_rmse: 0.6983  |  0:01:08s\n",
      "epoch 85 | loss: 0.42081 | val_0_rmse: 0.65232 | val_1_rmse: 0.71709 |  0:01:09s\n",
      "epoch 86 | loss: 0.42111 | val_0_rmse: 0.65111 | val_1_rmse: 0.65498 |  0:01:10s\n",
      "epoch 87 | loss: 0.42155 | val_0_rmse: 0.65441 | val_1_rmse: 0.66579 |  0:01:10s\n",
      "epoch 88 | loss: 0.42213 | val_0_rmse: 0.6581  | val_1_rmse: 0.66816 |  0:01:11s\n",
      "epoch 89 | loss: 0.4217  | val_0_rmse: 0.6525  | val_1_rmse: 0.66429 |  0:01:12s\n",
      "epoch 90 | loss: 0.42015 | val_0_rmse: 0.65204 | val_1_rmse: 0.70633 |  0:01:13s\n",
      "epoch 91 | loss: 0.4204  | val_0_rmse: 0.65175 | val_1_rmse: 0.71339 |  0:01:14s\n",
      "epoch 92 | loss: 0.42018 | val_0_rmse: 0.6486  | val_1_rmse: 0.72704 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 92 with best_epoch = 82 and best_val_1_rmse = 0.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4257, Val Loss: 0.4229, RMSE: 0.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 19.17974| val_0_rmse: 1.24971 | val_1_rmse: 1.34671 |  0:00:01s\n",
      "epoch 1  | loss: 17.77365| val_0_rmse: 2.45233 | val_1_rmse: 1.98681 |  0:00:02s\n",
      "epoch 2  | loss: 15.82596| val_0_rmse: 2.71724 | val_1_rmse: 14.48679|  0:00:04s\n",
      "epoch 3  | loss: 13.79275| val_0_rmse: 3.30767 | val_1_rmse: 5.27615 |  0:00:05s\n",
      "epoch 4  | loss: 11.5645 | val_0_rmse: 4.17942 | val_1_rmse: 3.94569 |  0:00:07s\n",
      "epoch 5  | loss: 9.73276 | val_0_rmse: 3.4652  | val_1_rmse: 3.10769 |  0:00:08s\n",
      "epoch 6  | loss: 8.33175 | val_0_rmse: 3.40332 | val_1_rmse: 3.63654 |  0:00:09s\n",
      "epoch 7  | loss: 7.52328 | val_0_rmse: 4.05405 | val_1_rmse: 3.8819  |  0:00:11s\n",
      "epoch 8  | loss: 7.11496 | val_0_rmse: 4.07049 | val_1_rmse: 7.39889 |  0:00:12s\n",
      "epoch 9  | loss: 6.61182 | val_0_rmse: 3.05786 | val_1_rmse: 6.80809 |  0:00:14s\n",
      "epoch 10 | loss: 5.91051 | val_0_rmse: 3.71112 | val_1_rmse: 6.20905 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.34671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.5618, Val Loss: 1.8136, RMSE: 1.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 18.96796| val_0_rmse: 1.40204 | val_1_rmse: 1.72748 |  0:00:01s\n",
      "epoch 1  | loss: 17.00845| val_0_rmse: 2.8661  | val_1_rmse: 2.10345 |  0:00:03s\n",
      "epoch 2  | loss: 14.91967| val_0_rmse: 5.11881 | val_1_rmse: 3.30892 |  0:00:04s\n",
      "epoch 3  | loss: 12.46124| val_0_rmse: 3.53606 | val_1_rmse: 3.47927 |  0:00:05s\n",
      "epoch 4  | loss: 10.03938| val_0_rmse: 3.4716  | val_1_rmse: 4.80049 |  0:00:07s\n",
      "epoch 5  | loss: 8.48785 | val_0_rmse: 3.74034 | val_1_rmse: 3.50536 |  0:00:08s\n",
      "epoch 6  | loss: 7.51184 | val_0_rmse: 4.0562  | val_1_rmse: 7.2338  |  0:00:10s\n",
      "epoch 7  | loss: 7.04154 | val_0_rmse: 2.99103 | val_1_rmse: 4.69815 |  0:00:11s\n",
      "epoch 8  | loss: 6.69365 | val_0_rmse: 3.55542 | val_1_rmse: 3.98602 |  0:00:12s\n",
      "epoch 9  | loss: 5.83919 | val_0_rmse: 3.31417 | val_1_rmse: 4.2883  |  0:00:14s\n",
      "epoch 10 | loss: 5.34325 | val_0_rmse: 3.69938 | val_1_rmse: 3.66391 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.72748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 16, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.9657, Val Loss: 2.9842, RMSE: 1.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.34725 | val_0_rmse: 1.42802 | val_1_rmse: 0.92896 |  0:00:00s\n",
      "epoch 1  | loss: 1.84493 | val_0_rmse: 1.66863 | val_1_rmse: 1.07925 |  0:00:01s\n",
      "epoch 2  | loss: 1.31607 | val_0_rmse: 1.86442 | val_1_rmse: 1.11617 |  0:00:01s\n",
      "epoch 3  | loss: 0.96159 | val_0_rmse: 1.24419 | val_1_rmse: 0.90994 |  0:00:02s\n",
      "epoch 4  | loss: 0.76746 | val_0_rmse: 1.07477 | val_1_rmse: 0.85038 |  0:00:03s\n",
      "epoch 5  | loss: 0.67104 | val_0_rmse: 0.83291 | val_1_rmse: 0.79334 |  0:00:03s\n",
      "epoch 6  | loss: 0.59481 | val_0_rmse: 0.74085 | val_1_rmse: 0.72054 |  0:00:04s\n",
      "epoch 7  | loss: 0.52364 | val_0_rmse: 0.70386 | val_1_rmse: 1.43585 |  0:00:05s\n",
      "epoch 8  | loss: 0.48894 | val_0_rmse: 0.69003 | val_1_rmse: 0.77214 |  0:00:05s\n",
      "epoch 9  | loss: 0.46668 | val_0_rmse: 0.68863 | val_1_rmse: 0.68415 |  0:00:06s\n",
      "epoch 10 | loss: 0.45615 | val_0_rmse: 0.70933 | val_1_rmse: 0.67362 |  0:00:07s\n",
      "epoch 11 | loss: 0.44528 | val_0_rmse: 0.70799 | val_1_rmse: 0.6625  |  0:00:07s\n",
      "epoch 12 | loss: 0.44219 | val_0_rmse: 0.67815 | val_1_rmse: 0.65753 |  0:00:08s\n",
      "epoch 13 | loss: 0.43914 | val_0_rmse: 0.6648  | val_1_rmse: 0.6553  |  0:00:08s\n",
      "epoch 14 | loss: 0.43683 | val_0_rmse: 0.66118 | val_1_rmse: 0.6537  |  0:00:09s\n",
      "epoch 15 | loss: 0.43508 | val_0_rmse: 0.66251 | val_1_rmse: 0.65226 |  0:00:10s\n",
      "epoch 16 | loss: 0.43369 | val_0_rmse: 0.662   | val_1_rmse: 0.65199 |  0:00:10s\n",
      "epoch 17 | loss: 0.43365 | val_0_rmse: 0.66266 | val_1_rmse: 0.65197 |  0:00:11s\n",
      "epoch 18 | loss: 0.43486 | val_0_rmse: 0.66138 | val_1_rmse: 0.65245 |  0:00:11s\n",
      "epoch 19 | loss: 0.43212 | val_0_rmse: 0.66104 | val_1_rmse: 0.65274 |  0:00:12s\n",
      "epoch 20 | loss: 0.43146 | val_0_rmse: 0.65754 | val_1_rmse: 0.65107 |  0:00:13s\n",
      "epoch 21 | loss: 0.42911 | val_0_rmse: 0.65552 | val_1_rmse: 0.64982 |  0:00:13s\n",
      "epoch 22 | loss: 0.4293  | val_0_rmse: 0.65953 | val_1_rmse: 0.65359 |  0:00:14s\n",
      "epoch 23 | loss: 0.43055 | val_0_rmse: 0.65714 | val_1_rmse: 0.65095 |  0:00:14s\n",
      "epoch 24 | loss: 0.42917 | val_0_rmse: 0.65718 | val_1_rmse: 0.64984 |  0:00:15s\n",
      "epoch 25 | loss: 0.4268  | val_0_rmse: 0.65345 | val_1_rmse: 0.65017 |  0:00:16s\n",
      "epoch 26 | loss: 0.42575 | val_0_rmse: 0.6552  | val_1_rmse: 0.64721 |  0:00:16s\n",
      "epoch 27 | loss: 0.42458 | val_0_rmse: 0.65779 | val_1_rmse: 0.64699 |  0:00:17s\n",
      "epoch 28 | loss: 0.42604 | val_0_rmse: 0.65809 | val_1_rmse: 0.64817 |  0:00:17s\n",
      "epoch 29 | loss: 0.42442 | val_0_rmse: 0.65612 | val_1_rmse: 0.64727 |  0:00:18s\n",
      "epoch 30 | loss: 0.4239  | val_0_rmse: 0.6566  | val_1_rmse: 0.64804 |  0:00:18s\n",
      "epoch 31 | loss: 0.42329 | val_0_rmse: 0.65754 | val_1_rmse: 0.64891 |  0:00:19s\n",
      "epoch 32 | loss: 0.42485 | val_0_rmse: 0.65618 | val_1_rmse: 0.64828 |  0:00:20s\n",
      "epoch 33 | loss: 0.42489 | val_0_rmse: 0.65681 | val_1_rmse: 0.64678 |  0:00:20s\n",
      "epoch 34 | loss: 0.42392 | val_0_rmse: 0.65789 | val_1_rmse: 0.6466  |  0:00:21s\n",
      "epoch 35 | loss: 0.42106 | val_0_rmse: 0.66462 | val_1_rmse: 0.64716 |  0:00:21s\n",
      "epoch 36 | loss: 0.42123 | val_0_rmse: 0.66468 | val_1_rmse: 0.64576 |  0:00:22s\n",
      "epoch 37 | loss: 0.42015 | val_0_rmse: 0.67109 | val_1_rmse: 0.64596 |  0:00:23s\n",
      "epoch 38 | loss: 0.42151 | val_0_rmse: 0.66949 | val_1_rmse: 0.64535 |  0:00:23s\n",
      "epoch 39 | loss: 0.4214  | val_0_rmse: 0.6734  | val_1_rmse: 0.64643 |  0:00:24s\n",
      "epoch 40 | loss: 0.42002 | val_0_rmse: 0.65892 | val_1_rmse: 0.65711 |  0:00:24s\n",
      "epoch 41 | loss: 0.41887 | val_0_rmse: 0.65944 | val_1_rmse: 0.64552 |  0:00:25s\n",
      "epoch 42 | loss: 0.41944 | val_0_rmse: 0.66219 | val_1_rmse: 0.6462  |  0:00:25s\n",
      "epoch 43 | loss: 0.41932 | val_0_rmse: 0.66086 | val_1_rmse: 0.64759 |  0:00:26s\n",
      "epoch 44 | loss: 0.41908 | val_0_rmse: 0.66043 | val_1_rmse: 0.64701 |  0:00:27s\n",
      "epoch 45 | loss: 0.41983 | val_0_rmse: 0.66379 | val_1_rmse: 0.64621 |  0:00:27s\n",
      "epoch 46 | loss: 0.41824 | val_0_rmse: 0.6588  | val_1_rmse: 0.64696 |  0:00:28s\n",
      "epoch 47 | loss: 0.41816 | val_0_rmse: 0.65792 | val_1_rmse: 0.6461  |  0:00:28s\n",
      "epoch 48 | loss: 0.41792 | val_0_rmse: 0.65568 | val_1_rmse: 0.6457  |  0:00:29s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_1_rmse = 0.64535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4482, Val Loss: 0.4165, RMSE: 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.31862 | val_0_rmse: 1.17798 | val_1_rmse: 0.9138  |  0:00:00s\n",
      "epoch 1  | loss: 1.76258 | val_0_rmse: 1.32206 | val_1_rmse: 1.3886  |  0:00:01s\n",
      "epoch 2  | loss: 1.28197 | val_0_rmse: 1.48669 | val_1_rmse: 1.77492 |  0:00:01s\n",
      "epoch 3  | loss: 0.99989 | val_0_rmse: 1.15478 | val_1_rmse: 1.39013 |  0:00:02s\n",
      "epoch 4  | loss: 0.81125 | val_0_rmse: 0.92024 | val_1_rmse: 0.94163 |  0:00:02s\n",
      "epoch 5  | loss: 0.70111 | val_0_rmse: 0.84203 | val_1_rmse: 0.83676 |  0:00:03s\n",
      "epoch 6  | loss: 0.63331 | val_0_rmse: 0.78077 | val_1_rmse: 0.76577 |  0:00:04s\n",
      "epoch 7  | loss: 0.5658  | val_0_rmse: 0.73689 | val_1_rmse: 0.72663 |  0:00:04s\n",
      "epoch 8  | loss: 0.51467 | val_0_rmse: 0.71739 | val_1_rmse: 0.7021  |  0:00:05s\n",
      "epoch 9  | loss: 0.48809 | val_0_rmse: 0.69872 | val_1_rmse: 0.68017 |  0:00:05s\n",
      "epoch 10 | loss: 0.47075 | val_0_rmse: 0.69265 | val_1_rmse: 0.67439 |  0:00:06s\n",
      "epoch 11 | loss: 0.46128 | val_0_rmse: 0.68572 | val_1_rmse: 0.66443 |  0:00:07s\n",
      "epoch 12 | loss: 0.45538 | val_0_rmse: 0.67965 | val_1_rmse: 0.66851 |  0:00:07s\n",
      "epoch 13 | loss: 0.45099 | val_0_rmse: 0.69124 | val_1_rmse: 0.66327 |  0:00:08s\n",
      "epoch 14 | loss: 0.44718 | val_0_rmse: 0.66749 | val_1_rmse: 0.6561  |  0:00:08s\n",
      "epoch 15 | loss: 0.44456 | val_0_rmse: 0.66263 | val_1_rmse: 0.66809 |  0:00:09s\n",
      "epoch 16 | loss: 0.44355 | val_0_rmse: 0.65904 | val_1_rmse: 0.66339 |  0:00:10s\n",
      "epoch 17 | loss: 0.44248 | val_0_rmse: 0.65907 | val_1_rmse: 0.66078 |  0:00:10s\n",
      "epoch 18 | loss: 0.44024 | val_0_rmse: 0.69507 | val_1_rmse: 0.6603  |  0:00:11s\n",
      "epoch 19 | loss: 0.43865 | val_0_rmse: 0.66255 | val_1_rmse: 0.65068 |  0:00:11s\n",
      "epoch 20 | loss: 0.43655 | val_0_rmse: 0.65631 | val_1_rmse: 0.65117 |  0:00:12s\n",
      "epoch 21 | loss: 0.43081 | val_0_rmse: 0.65334 | val_1_rmse: 0.64771 |  0:00:12s\n",
      "epoch 22 | loss: 0.42971 | val_0_rmse: 0.65567 | val_1_rmse: 0.64871 |  0:00:13s\n",
      "epoch 23 | loss: 0.42993 | val_0_rmse: 0.66056 | val_1_rmse: 0.64968 |  0:00:14s\n",
      "epoch 24 | loss: 0.42763 | val_0_rmse: 0.65847 | val_1_rmse: 0.64604 |  0:00:14s\n",
      "epoch 25 | loss: 0.42507 | val_0_rmse: 0.65959 | val_1_rmse: 0.64638 |  0:00:15s\n",
      "epoch 26 | loss: 0.42446 | val_0_rmse: 0.64952 | val_1_rmse: 0.64488 |  0:00:15s\n",
      "epoch 27 | loss: 0.42483 | val_0_rmse: 0.64768 | val_1_rmse: 0.64474 |  0:00:16s\n",
      "epoch 28 | loss: 0.42371 | val_0_rmse: 0.64883 | val_1_rmse: 0.64632 |  0:00:17s\n",
      "epoch 29 | loss: 0.42292 | val_0_rmse: 0.65464 | val_1_rmse: 0.64517 |  0:00:17s\n",
      "epoch 30 | loss: 0.42237 | val_0_rmse: 0.65222 | val_1_rmse: 0.64443 |  0:00:18s\n",
      "epoch 31 | loss: 0.42303 | val_0_rmse: 0.65446 | val_1_rmse: 0.64544 |  0:00:18s\n",
      "epoch 32 | loss: 0.42352 | val_0_rmse: 0.65102 | val_1_rmse: 0.6441  |  0:00:19s\n",
      "epoch 33 | loss: 0.42257 | val_0_rmse: 0.64793 | val_1_rmse: 0.64293 |  0:00:20s\n",
      "epoch 34 | loss: 0.42173 | val_0_rmse: 0.64805 | val_1_rmse: 0.64363 |  0:00:20s\n",
      "epoch 35 | loss: 0.42084 | val_0_rmse: 0.65339 | val_1_rmse: 0.64359 |  0:00:21s\n",
      "epoch 36 | loss: 0.41953 | val_0_rmse: 0.6507  | val_1_rmse: 0.64224 |  0:00:21s\n",
      "epoch 37 | loss: 0.41896 | val_0_rmse: 0.65306 | val_1_rmse: 0.64359 |  0:00:22s\n",
      "epoch 38 | loss: 0.41967 | val_0_rmse: 0.65407 | val_1_rmse: 0.64495 |  0:00:23s\n",
      "epoch 39 | loss: 0.41903 | val_0_rmse: 0.65261 | val_1_rmse: 0.64305 |  0:00:23s\n",
      "epoch 40 | loss: 0.41884 | val_0_rmse: 0.65015 | val_1_rmse: 0.64458 |  0:00:24s\n",
      "epoch 41 | loss: 0.41796 | val_0_rmse: 0.65093 | val_1_rmse: 0.64702 |  0:00:24s\n",
      "epoch 42 | loss: 0.41787 | val_0_rmse: 0.64905 | val_1_rmse: 0.64191 |  0:00:25s\n",
      "epoch 43 | loss: 0.41754 | val_0_rmse: 0.65129 | val_1_rmse: 0.64293 |  0:00:26s\n",
      "epoch 44 | loss: 0.41824 | val_0_rmse: 0.64953 | val_1_rmse: 0.64099 |  0:00:26s\n",
      "epoch 45 | loss: 0.41972 | val_0_rmse: 0.64957 | val_1_rmse: 0.64357 |  0:00:27s\n",
      "epoch 46 | loss: 0.41836 | val_0_rmse: 0.64929 | val_1_rmse: 0.64485 |  0:00:27s\n",
      "epoch 47 | loss: 0.41947 | val_0_rmse: 0.6499  | val_1_rmse: 0.64349 |  0:00:28s\n",
      "epoch 48 | loss: 0.41996 | val_0_rmse: 0.65201 | val_1_rmse: 0.64238 |  0:00:29s\n",
      "epoch 49 | loss: 0.41807 | val_0_rmse: 0.64605 | val_1_rmse: 0.64302 |  0:00:29s\n",
      "epoch 50 | loss: 0.41636 | val_0_rmse: 0.64442 | val_1_rmse: 0.64133 |  0:00:30s\n",
      "epoch 51 | loss: 0.41529 | val_0_rmse: 0.64236 | val_1_rmse: 0.64057 |  0:00:30s\n",
      "epoch 52 | loss: 0.41675 | val_0_rmse: 0.64497 | val_1_rmse: 0.64299 |  0:00:31s\n",
      "epoch 53 | loss: 0.41456 | val_0_rmse: 0.64536 | val_1_rmse: 0.65397 |  0:00:31s\n",
      "epoch 54 | loss: 0.41472 | val_0_rmse: 0.64407 | val_1_rmse: 0.64661 |  0:00:32s\n",
      "epoch 55 | loss: 0.41429 | val_0_rmse: 0.64297 | val_1_rmse: 0.64318 |  0:00:33s\n",
      "epoch 56 | loss: 0.41298 | val_0_rmse: 0.64162 | val_1_rmse: 0.64078 |  0:00:33s\n",
      "epoch 57 | loss: 0.41325 | val_0_rmse: 0.64231 | val_1_rmse: 0.64244 |  0:00:34s\n",
      "epoch 58 | loss: 0.41347 | val_0_rmse: 0.64286 | val_1_rmse: 0.64171 |  0:00:34s\n",
      "epoch 59 | loss: 0.41192 | val_0_rmse: 0.64083 | val_1_rmse: 0.64004 |  0:00:35s\n",
      "epoch 60 | loss: 0.41185 | val_0_rmse: 0.64038 | val_1_rmse: 0.67151 |  0:00:35s\n",
      "epoch 61 | loss: 0.41206 | val_0_rmse: 0.6411  | val_1_rmse: 0.65178 |  0:00:36s\n",
      "epoch 62 | loss: 0.4115  | val_0_rmse: 0.64102 | val_1_rmse: 0.64879 |  0:00:37s\n",
      "epoch 63 | loss: 0.41175 | val_0_rmse: 0.64197 | val_1_rmse: 0.65207 |  0:00:37s\n",
      "epoch 64 | loss: 0.41198 | val_0_rmse: 0.64126 | val_1_rmse: 0.65225 |  0:00:38s\n",
      "epoch 65 | loss: 0.40978 | val_0_rmse: 0.63797 | val_1_rmse: 0.6458  |  0:00:38s\n",
      "epoch 66 | loss: 0.41014 | val_0_rmse: 0.63833 | val_1_rmse: 0.64621 |  0:00:39s\n",
      "epoch 67 | loss: 0.40901 | val_0_rmse: 0.63909 | val_1_rmse: 0.76123 |  0:00:40s\n",
      "epoch 68 | loss: 0.40898 | val_0_rmse: 0.6407  | val_1_rmse: 0.654   |  0:00:40s\n",
      "epoch 69 | loss: 0.40949 | val_0_rmse: 0.64087 | val_1_rmse: 0.65017 |  0:00:41s\n",
      "\n",
      "Early stopping occurred at epoch 69 with best_epoch = 59 and best_val_1_rmse = 0.64004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 3, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4107, Val Loss: 0.4097, RMSE: 0.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.71498 | val_0_rmse: 1.56615 | val_1_rmse: 0.94109 |  0:00:00s\n",
      "epoch 1  | loss: 2.67478 | val_0_rmse: 2.05881 | val_1_rmse: 0.96823 |  0:00:01s\n",
      "epoch 2  | loss: 1.79499 | val_0_rmse: 2.07447 | val_1_rmse: 1.79349 |  0:00:02s\n",
      "epoch 3  | loss: 1.35906 | val_0_rmse: 1.4605  | val_1_rmse: 1.61661 |  0:00:03s\n",
      "epoch 4  | loss: 1.0753  | val_0_rmse: 1.09958 | val_1_rmse: 1.08723 |  0:00:04s\n",
      "epoch 5  | loss: 0.86735 | val_0_rmse: 0.95297 | val_1_rmse: 0.9829  |  0:00:04s\n",
      "epoch 6  | loss: 0.73218 | val_0_rmse: 0.87717 | val_1_rmse: 0.81891 |  0:00:05s\n",
      "epoch 7  | loss: 0.66629 | val_0_rmse: 0.80353 | val_1_rmse: 0.78951 |  0:00:06s\n",
      "epoch 8  | loss: 0.63443 | val_0_rmse: 0.82178 | val_1_rmse: 0.77126 |  0:00:07s\n",
      "epoch 9  | loss: 0.61833 | val_0_rmse: 0.7852  | val_1_rmse: 0.77149 |  0:00:08s\n",
      "epoch 10 | loss: 0.60755 | val_0_rmse: 0.7875  | val_1_rmse: 0.76928 |  0:00:09s\n",
      "epoch 11 | loss: 0.60221 | val_0_rmse: 0.77711 | val_1_rmse: 0.78482 |  0:00:09s\n",
      "epoch 12 | loss: 0.60137 | val_0_rmse: 0.78696 | val_1_rmse: 0.80136 |  0:00:10s\n",
      "epoch 13 | loss: 0.59338 | val_0_rmse: 0.78571 | val_1_rmse: 0.77137 |  0:00:11s\n",
      "epoch 14 | loss: 0.58423 | val_0_rmse: 0.7653  | val_1_rmse: 0.76348 |  0:00:12s\n",
      "epoch 15 | loss: 0.58595 | val_0_rmse: 0.76595 | val_1_rmse: 0.80446 |  0:00:13s\n",
      "epoch 16 | loss: 0.581   | val_0_rmse: 0.76046 | val_1_rmse: 0.75684 |  0:00:13s\n",
      "epoch 17 | loss: 0.5771  | val_0_rmse: 0.7642  | val_1_rmse: 0.75559 |  0:00:14s\n",
      "epoch 18 | loss: 0.57823 | val_0_rmse: 0.75592 | val_1_rmse: 0.75266 |  0:00:15s\n",
      "epoch 19 | loss: 0.57412 | val_0_rmse: 0.75651 | val_1_rmse: 0.75097 |  0:00:16s\n",
      "epoch 20 | loss: 0.56967 | val_0_rmse: 0.75449 | val_1_rmse: 0.74942 |  0:00:17s\n",
      "epoch 21 | loss: 0.56656 | val_0_rmse: 0.75058 | val_1_rmse: 0.76759 |  0:00:18s\n",
      "epoch 22 | loss: 0.56177 | val_0_rmse: 0.76206 | val_1_rmse: 0.74822 |  0:00:18s\n",
      "epoch 23 | loss: 0.5619  | val_0_rmse: 0.74651 | val_1_rmse: 0.76735 |  0:00:19s\n",
      "epoch 24 | loss: 0.5566  | val_0_rmse: 0.74329 | val_1_rmse: 0.74219 |  0:00:20s\n",
      "epoch 25 | loss: 0.55097 | val_0_rmse: 0.74391 | val_1_rmse: 0.74831 |  0:00:21s\n",
      "epoch 26 | loss: 0.55011 | val_0_rmse: 0.74743 | val_1_rmse: 0.74598 |  0:00:22s\n",
      "epoch 27 | loss: 0.54669 | val_0_rmse: 0.7472  | val_1_rmse: 0.74397 |  0:00:22s\n",
      "epoch 28 | loss: 0.54735 | val_0_rmse: 0.73857 | val_1_rmse: 0.73409 |  0:00:23s\n",
      "epoch 29 | loss: 0.54233 | val_0_rmse: 0.73298 | val_1_rmse: 0.72994 |  0:00:24s\n",
      "epoch 30 | loss: 0.52841 | val_0_rmse: 0.72453 | val_1_rmse: 0.72293 |  0:00:25s\n",
      "epoch 31 | loss: 0.51138 | val_0_rmse: 0.71058 | val_1_rmse: 0.70515 |  0:00:26s\n",
      "epoch 32 | loss: 0.49432 | val_0_rmse: 0.69905 | val_1_rmse: 0.68732 |  0:00:27s\n",
      "epoch 33 | loss: 0.48102 | val_0_rmse: 0.69368 | val_1_rmse: 0.68584 |  0:00:27s\n",
      "epoch 34 | loss: 0.47993 | val_0_rmse: 0.69155 | val_1_rmse: 0.68712 |  0:00:28s\n",
      "epoch 35 | loss: 0.47329 | val_0_rmse: 0.68902 | val_1_rmse: 0.68449 |  0:00:29s\n",
      "epoch 36 | loss: 0.47066 | val_0_rmse: 0.68546 | val_1_rmse: 0.71802 |  0:00:30s\n",
      "epoch 37 | loss: 0.4695  | val_0_rmse: 0.68344 | val_1_rmse: 0.67999 |  0:00:31s\n",
      "epoch 38 | loss: 0.4658  | val_0_rmse: 0.68207 | val_1_rmse: 0.67687 |  0:00:31s\n",
      "epoch 39 | loss: 0.46099 | val_0_rmse: 0.67795 | val_1_rmse: 0.67434 |  0:00:32s\n",
      "epoch 40 | loss: 0.46009 | val_0_rmse: 0.67797 | val_1_rmse: 0.67486 |  0:00:33s\n",
      "epoch 41 | loss: 0.45892 | val_0_rmse: 0.67682 | val_1_rmse: 0.67359 |  0:00:34s\n",
      "epoch 42 | loss: 0.45875 | val_0_rmse: 0.67493 | val_1_rmse: 0.67278 |  0:00:35s\n",
      "epoch 43 | loss: 0.45977 | val_0_rmse: 0.67487 | val_1_rmse: 0.67087 |  0:00:36s\n",
      "epoch 44 | loss: 0.45774 | val_0_rmse: 0.67934 | val_1_rmse: 0.67149 |  0:00:36s\n",
      "epoch 45 | loss: 0.45371 | val_0_rmse: 0.6829  | val_1_rmse: 0.6739  |  0:00:37s\n",
      "epoch 46 | loss: 0.45396 | val_0_rmse: 0.67712 | val_1_rmse: 0.66672 |  0:00:38s\n",
      "epoch 47 | loss: 0.45293 | val_0_rmse: 0.68776 | val_1_rmse: 0.66716 |  0:00:39s\n",
      "epoch 48 | loss: 0.45479 | val_0_rmse: 0.69194 | val_1_rmse: 0.67209 |  0:00:40s\n",
      "epoch 49 | loss: 0.45255 | val_0_rmse: 0.70402 | val_1_rmse: 0.67249 |  0:00:40s\n",
      "epoch 50 | loss: 0.45175 | val_0_rmse: 0.69301 | val_1_rmse: 0.67413 |  0:00:41s\n",
      "epoch 51 | loss: 0.45007 | val_0_rmse: 0.69487 | val_1_rmse: 0.66964 |  0:00:42s\n",
      "epoch 52 | loss: 0.4469  | val_0_rmse: 0.68205 | val_1_rmse: 0.66747 |  0:00:43s\n",
      "epoch 53 | loss: 0.44757 | val_0_rmse: 0.67697 | val_1_rmse: 0.66668 |  0:00:44s\n",
      "epoch 54 | loss: 0.44577 | val_0_rmse: 0.67114 | val_1_rmse: 0.6665  |  0:00:44s\n",
      "epoch 55 | loss: 0.44616 | val_0_rmse: 0.66997 | val_1_rmse: 0.66726 |  0:00:45s\n",
      "epoch 56 | loss: 0.44295 | val_0_rmse: 0.67002 | val_1_rmse: 0.66655 |  0:00:46s\n",
      "epoch 57 | loss: 0.44252 | val_0_rmse: 0.67495 | val_1_rmse: 0.67009 |  0:00:47s\n",
      "epoch 58 | loss: 0.44301 | val_0_rmse: 0.6819  | val_1_rmse: 0.669   |  0:00:48s\n",
      "epoch 59 | loss: 0.44198 | val_0_rmse: 0.67084 | val_1_rmse: 0.66785 |  0:00:49s\n",
      "epoch 60 | loss: 0.44109 | val_0_rmse: 0.665   | val_1_rmse: 0.66515 |  0:00:49s\n",
      "epoch 61 | loss: 0.44092 | val_0_rmse: 0.66415 | val_1_rmse: 0.66511 |  0:00:50s\n",
      "epoch 62 | loss: 0.43993 | val_0_rmse: 0.66465 | val_1_rmse: 0.66649 |  0:00:51s\n",
      "epoch 63 | loss: 0.43911 | val_0_rmse: 0.66655 | val_1_rmse: 0.66779 |  0:00:52s\n",
      "epoch 64 | loss: 0.43721 | val_0_rmse: 0.66347 | val_1_rmse: 0.66438 |  0:00:53s\n",
      "epoch 65 | loss: 0.43452 | val_0_rmse: 0.66249 | val_1_rmse: 0.66194 |  0:00:53s\n",
      "epoch 66 | loss: 0.43374 | val_0_rmse: 0.65962 | val_1_rmse: 0.65925 |  0:00:54s\n",
      "epoch 67 | loss: 0.43066 | val_0_rmse: 0.65969 | val_1_rmse: 0.66058 |  0:00:55s\n",
      "epoch 68 | loss: 0.43062 | val_0_rmse: 0.65945 | val_1_rmse: 0.65829 |  0:00:56s\n",
      "epoch 69 | loss: 0.42835 | val_0_rmse: 0.65902 | val_1_rmse: 0.65632 |  0:00:57s\n",
      "epoch 70 | loss: 0.42678 | val_0_rmse: 0.65833 | val_1_rmse: 0.65627 |  0:00:57s\n",
      "epoch 71 | loss: 0.42658 | val_0_rmse: 0.65839 | val_1_rmse: 0.65634 |  0:00:58s\n",
      "epoch 72 | loss: 0.42558 | val_0_rmse: 0.65914 | val_1_rmse: 0.65732 |  0:00:59s\n",
      "epoch 73 | loss: 0.42621 | val_0_rmse: 0.6568  | val_1_rmse: 0.65572 |  0:01:00s\n",
      "epoch 74 | loss: 0.42544 | val_0_rmse: 0.65775 | val_1_rmse: 0.65626 |  0:01:01s\n",
      "epoch 75 | loss: 0.42468 | val_0_rmse: 0.65774 | val_1_rmse: 0.65534 |  0:01:02s\n",
      "epoch 76 | loss: 0.42485 | val_0_rmse: 0.65997 | val_1_rmse: 0.65661 |  0:01:02s\n",
      "epoch 77 | loss: 0.42525 | val_0_rmse: 0.65724 | val_1_rmse: 0.65415 |  0:01:03s\n",
      "epoch 78 | loss: 0.42442 | val_0_rmse: 0.658   | val_1_rmse: 0.65447 |  0:01:04s\n",
      "epoch 79 | loss: 0.42399 | val_0_rmse: 0.65669 | val_1_rmse: 0.65301 |  0:01:05s\n",
      "epoch 80 | loss: 0.42483 | val_0_rmse: 0.65707 | val_1_rmse: 0.65337 |  0:01:06s\n",
      "epoch 81 | loss: 0.42459 | val_0_rmse: 0.65699 | val_1_rmse: 0.65262 |  0:01:06s\n",
      "epoch 82 | loss: 0.42427 | val_0_rmse: 0.65774 | val_1_rmse: 0.6538  |  0:01:07s\n",
      "epoch 83 | loss: 0.42459 | val_0_rmse: 0.65833 | val_1_rmse: 0.65387 |  0:01:08s\n",
      "epoch 84 | loss: 0.42472 | val_0_rmse: 0.65743 | val_1_rmse: 0.65272 |  0:01:09s\n",
      "epoch 85 | loss: 0.42493 | val_0_rmse: 0.65639 | val_1_rmse: 0.65246 |  0:01:10s\n",
      "epoch 86 | loss: 0.42409 | val_0_rmse: 0.65747 | val_1_rmse: 0.65414 |  0:01:10s\n",
      "epoch 87 | loss: 0.42622 | val_0_rmse: 0.66192 | val_1_rmse: 0.65954 |  0:01:11s\n",
      "epoch 88 | loss: 0.42518 | val_0_rmse: 0.65664 | val_1_rmse: 0.6537  |  0:01:12s\n",
      "epoch 89 | loss: 0.42451 | val_0_rmse: 0.65541 | val_1_rmse: 0.65168 |  0:01:13s\n",
      "epoch 90 | loss: 0.42461 | val_0_rmse: 0.6604  | val_1_rmse: 0.65346 |  0:01:14s\n",
      "epoch 91 | loss: 0.42343 | val_0_rmse: 0.65691 | val_1_rmse: 0.65311 |  0:01:14s\n",
      "epoch 92 | loss: 0.4254  | val_0_rmse: 0.65831 | val_1_rmse: 0.65499 |  0:01:15s\n",
      "epoch 93 | loss: 0.42569 | val_0_rmse: 0.65435 | val_1_rmse: 0.65073 |  0:01:16s\n",
      "epoch 94 | loss: 0.42597 | val_0_rmse: 0.65572 | val_1_rmse: 0.65384 |  0:01:17s\n",
      "epoch 95 | loss: 0.42441 | val_0_rmse: 0.65666 | val_1_rmse: 0.65679 |  0:01:18s\n",
      "epoch 96 | loss: 0.42444 | val_0_rmse: 0.65845 | val_1_rmse: 0.65494 |  0:01:18s\n",
      "epoch 97 | loss: 0.42373 | val_0_rmse: 0.65737 | val_1_rmse: 0.65295 |  0:01:19s\n",
      "epoch 98 | loss: 0.42314 | val_0_rmse: 0.65684 | val_1_rmse: 0.65222 |  0:01:20s\n",
      "epoch 99 | loss: 0.42314 | val_0_rmse: 0.65564 | val_1_rmse: 0.65143 |  0:01:21s\n",
      "epoch 100| loss: 0.42293 | val_0_rmse: 0.65508 | val_1_rmse: 0.65057 |  0:01:22s\n",
      "epoch 101| loss: 0.4217  | val_0_rmse: 0.65697 | val_1_rmse: 0.65246 |  0:01:22s\n",
      "epoch 102| loss: 0.42144 | val_0_rmse: 0.65669 | val_1_rmse: 0.65246 |  0:01:23s\n",
      "epoch 103| loss: 0.42164 | val_0_rmse: 0.6612  | val_1_rmse: 0.65363 |  0:01:24s\n",
      "epoch 104| loss: 0.42103 | val_0_rmse: 0.66039 | val_1_rmse: 0.65164 |  0:01:25s\n",
      "epoch 105| loss: 0.42096 | val_0_rmse: 0.66176 | val_1_rmse: 0.65486 |  0:01:26s\n",
      "epoch 106| loss: 0.42085 | val_0_rmse: 0.66946 | val_1_rmse: 0.66049 |  0:01:26s\n",
      "epoch 107| loss: 0.42114 | val_0_rmse: 0.65594 | val_1_rmse: 0.65153 |  0:01:27s\n",
      "epoch 108| loss: 0.42018 | val_0_rmse: 0.65678 | val_1_rmse: 0.65139 |  0:01:28s\n",
      "epoch 109| loss: 0.41989 | val_0_rmse: 0.66562 | val_1_rmse: 0.65088 |  0:01:29s\n",
      "epoch 110| loss: 0.42013 | val_0_rmse: 0.6557  | val_1_rmse: 0.65229 |  0:01:30s\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 100 and best_val_1_rmse = 0.65057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.4291, Val Loss: 0.4232, RMSE: 0.6506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.82514 | val_0_rmse: 0.97478 | val_1_rmse: 0.96532 |  0:00:00s\n",
      "epoch 1  | loss: 2.70434 | val_0_rmse: 2.2306  | val_1_rmse: 1.11936 |  0:00:01s\n",
      "epoch 2  | loss: 1.88997 | val_0_rmse: 1.24858 | val_1_rmse: 1.56404 |  0:00:02s\n",
      "epoch 3  | loss: 1.39897 | val_0_rmse: 1.29545 | val_1_rmse: 1.44253 |  0:00:03s\n",
      "epoch 4  | loss: 1.05952 | val_0_rmse: 1.05457 | val_1_rmse: 1.15833 |  0:00:04s\n",
      "epoch 5  | loss: 0.83133 | val_0_rmse: 1.28014 | val_1_rmse: 0.99059 |  0:00:04s\n",
      "epoch 6  | loss: 0.70865 | val_0_rmse: 0.95171 | val_1_rmse: 0.82532 |  0:00:05s\n",
      "epoch 7  | loss: 0.63804 | val_0_rmse: 0.81461 | val_1_rmse: 0.74345 |  0:00:06s\n",
      "epoch 8  | loss: 0.57036 | val_0_rmse: 0.75322 | val_1_rmse: 0.70864 |  0:00:07s\n",
      "epoch 9  | loss: 0.52946 | val_0_rmse: 0.7162  | val_1_rmse: 0.70967 |  0:00:08s\n",
      "epoch 10 | loss: 0.50832 | val_0_rmse: 0.70657 | val_1_rmse: 0.71056 |  0:00:09s\n",
      "epoch 11 | loss: 0.5     | val_0_rmse: 0.70937 | val_1_rmse: 0.68906 |  0:00:09s\n",
      "epoch 12 | loss: 0.49705 | val_0_rmse: 0.70654 | val_1_rmse: 0.69212 |  0:00:10s\n",
      "epoch 13 | loss: 0.48992 | val_0_rmse: 0.70223 | val_1_rmse: 0.69787 |  0:00:11s\n",
      "epoch 14 | loss: 0.48395 | val_0_rmse: 0.70902 | val_1_rmse: 0.70042 |  0:00:12s\n",
      "epoch 15 | loss: 0.47612 | val_0_rmse: 0.71092 | val_1_rmse: 0.71773 |  0:00:13s\n",
      "epoch 16 | loss: 0.47758 | val_0_rmse: 0.7335  | val_1_rmse: 0.7255  |  0:00:13s\n",
      "epoch 17 | loss: 0.48816 | val_0_rmse: 0.71425 | val_1_rmse: 0.73248 |  0:00:14s\n",
      "epoch 18 | loss: 0.47853 | val_0_rmse: 0.70436 | val_1_rmse: 0.71396 |  0:00:15s\n",
      "epoch 19 | loss: 0.47163 | val_0_rmse: 0.69957 | val_1_rmse: 0.71885 |  0:00:16s\n",
      "epoch 20 | loss: 0.46868 | val_0_rmse: 0.69649 | val_1_rmse: 0.70497 |  0:00:17s\n",
      "epoch 21 | loss: 0.46808 | val_0_rmse: 0.69137 | val_1_rmse: 0.69841 |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_1_rmse = 0.68906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 5, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 0.5032, Val Loss: 0.4748, RMSE: 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 17.53231| val_0_rmse: 1.22936 | val_1_rmse: 2.45087 |  0:00:01s\n",
      "epoch 1  | loss: 16.51986| val_0_rmse: 2.51836 | val_1_rmse: 4.34087 |  0:00:02s\n",
      "epoch 2  | loss: 14.6415 | val_0_rmse: 4.64985 | val_1_rmse: 3.54695 |  0:00:04s\n",
      "epoch 3  | loss: 13.38675| val_0_rmse: 3.27042 | val_1_rmse: 5.10911 |  0:00:05s\n",
      "epoch 4  | loss: 11.57731| val_0_rmse: 3.43779 | val_1_rmse: 3.60606 |  0:00:07s\n",
      "epoch 5  | loss: 9.65692 | val_0_rmse: 3.7812  | val_1_rmse: 5.25138 |  0:00:08s\n",
      "epoch 6  | loss: 8.55065 | val_0_rmse: 3.51088 | val_1_rmse: 4.22723 |  0:00:09s\n",
      "epoch 7  | loss: 8.08097 | val_0_rmse: 3.29028 | val_1_rmse: 4.01755 |  0:00:11s\n",
      "epoch 8  | loss: 7.70767 | val_0_rmse: 3.17928 | val_1_rmse: 4.37881 |  0:00:12s\n",
      "epoch 9  | loss: 7.21149 | val_0_rmse: 3.53841 | val_1_rmse: 4.33137 |  0:00:13s\n",
      "epoch 10 | loss: 6.64837 | val_0_rmse: 4.00484 | val_1_rmse: 3.06097 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 2.45087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.0001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.5113, Val Loss: 6.0068, RMSE: 2.4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 17.4222 | val_0_rmse: 1.25367 | val_1_rmse: 1.12588 |  0:00:01s\n",
      "epoch 1  | loss: 15.45504| val_0_rmse: 2.3877  | val_1_rmse: 2.3629  |  0:00:02s\n",
      "epoch 2  | loss: 13.46263| val_0_rmse: 4.43665 | val_1_rmse: 7.51701 |  0:00:04s\n",
      "epoch 3  | loss: 11.6746 | val_0_rmse: 3.93887 | val_1_rmse: 6.10895 |  0:00:05s\n",
      "epoch 4  | loss: 9.71685 | val_0_rmse: 4.22028 | val_1_rmse: 5.38276 |  0:00:07s\n",
      "epoch 5  | loss: 8.55854 | val_0_rmse: 4.68467 | val_1_rmse: 3.10592 |  0:00:08s\n",
      "epoch 6  | loss: 8.21675 | val_0_rmse: 4.23158 | val_1_rmse: 4.21398 |  0:00:10s\n",
      "epoch 7  | loss: 7.93512 | val_0_rmse: 3.67317 | val_1_rmse: 3.36622 |  0:00:11s\n",
      "epoch 8  | loss: 7.45221 | val_0_rmse: 4.0766  | val_1_rmse: 3.90735 |  0:00:12s\n",
      "epoch 9  | loss: 7.04712 | val_0_rmse: 2.85327 | val_1_rmse: 7.86502 |  0:00:14s\n",
      "epoch 10 | loss: 6.26912 | val_0_rmse: 3.44064 | val_1_rmse: 4.11045 |  0:00:15s\n",
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_1_rmse = 1.12588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training with params: {'n_d': 32, 'n_a': 32, 'n_steps': 10, 'gamma': 1.5, 'lambda_sparse': 0.001, 'optimizer_params': {'lr': 0.01}, 'mask_type': 'entmax'}\n",
      "Train Loss: 1.5717, Val Loss: 1.2676, RMSE: 1.1259\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "import csv\n",
    "\n",
    "# Prepare data\n",
    "X = new_df.drop(columns=[\"h3_index\"] + unique_types)  # Feature data\n",
    "y = new_df[unique_types]  # Target variables (multiple columns)\n",
    "\n",
    "# Standardize feature data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=46)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=46)\n",
    "\n",
    "# Convert target variables to numpy format, suitable for TabNet input\n",
    "y_train_np = y_train.values\n",
    "y_val_np = y_val.values\n",
    "\n",
    "# Define parameter search space\n",
    "param_grid = {\n",
    "    \"n_d\": [8, 16, 32],\n",
    "    \"n_a\": [8, 16, 32],\n",
    "    \"n_steps\": [3, 5, 10],\n",
    "    \"gamma\": [1.5],\n",
    "    \"lambda_sparse\": [0.0001, 0.001],\n",
    "    \"optimizer_params\": [{\"lr\": 0.01}],\n",
    "    \"mask_type\": [\"entmax\"]\n",
    "}\n",
    "\n",
    "# Get all parameter combinations\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "param_names = list(param_grid.keys())\n",
    "\n",
    "# Initialize CSV file to save results\n",
    "csv_filename = \"tabnet_hyperparameter_search_results2.csv\"\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    header = param_names + [\"train_loss\", \"val_loss\", \"rmse\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "# Start parameter search\n",
    "for params in param_combinations:\n",
    "    param_dict = dict(zip(param_names, params))\n",
    "    \n",
    "    # Initialize TabNet model\n",
    "    tabnet_model = TabNetRegressor(\n",
    "        n_d=param_dict[\"n_d\"],\n",
    "        n_a=param_dict[\"n_a\"],\n",
    "        n_steps=param_dict[\"n_steps\"],\n",
    "        gamma=param_dict[\"gamma\"],\n",
    "        lambda_sparse=param_dict[\"lambda_sparse\"],\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=param_dict[\"optimizer_params\"],\n",
    "        mask_type=param_dict[\"mask_type\"]\n",
    "    )\n",
    "\n",
    "    # Set maximum number of epochs and early stopping\n",
    "    max_epochs = 1000\n",
    "    early_stopping_rounds = 10\n",
    "\n",
    "    # Train the model\n",
    "    tabnet_model.fit(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train_np,\n",
    "        eval_set=[(X_train, y_train_np), (X_val, y_val_np)],\n",
    "        max_epochs=max_epochs,\n",
    "        patience=early_stopping_rounds,\n",
    "        eval_metric=['rmse'],\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # Calculate training loss and validation loss\n",
    "    train_loss = mean_squared_error(y_train_np, tabnet_model.predict(X_train))\n",
    "    val_loss = mean_squared_error(y_val_np, tabnet_model.predict(X_val))\n",
    "    rmse = np.sqrt(val_loss)  # Use RMSE as the final evaluation metric\n",
    "\n",
    "    # Save results to CSV file\n",
    "    with open(csv_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        result_row = list(params) + [train_loss, val_loss, rmse]\n",
    "        writer.writerow(result_row)\n",
    "\n",
    "    print(f\"Finished training with params: {param_dict}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "results_df = pd.read_csv(\"tabnet_hyperparameter_search_results2.csv\")\n",
    "\n",
    "# Visualize the effect of different parameters on validation loss and RMSE\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=results_df, x=\"n_d\", y=\"val_loss\", hue=\"mask_type\")\n",
    "plt.title(\"Effect of n_d on Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=results_df, x=\"n_d\", y=\"rmse\", hue=\"mask_type\")\n",
    "plt.title(\"Effect of n_d on RMSE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=results_df, x=\"n_steps\", y=\"val_loss\", hue=\"mask_type\")\n",
    "plt.title(\"Effect of n_steps on Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=results_df, x=\"n_steps\", y=\"rmse\", hue=\"mask_type\")\n",
    "plt.title(\"Effect of n_steps on RMSE\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter combination:\n",
      "n_d                           16\n",
      "n_a                            8\n",
      "n_steps                        3\n",
      "gamma                        1.5\n",
      "lambda_sparse              0.001\n",
      "optimizer_params    {'lr': 0.01}\n",
      "mask_type                 entmax\n",
      "train_loss              0.410536\n",
      "val_loss                0.408831\n",
      "rmse                    0.639399\n",
      "Name: 19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the row with the minimum validation loss as the optimal parameter set\n",
    "best_params = results_df.loc[results_df[\"val_loss\"].idxmin()]\n",
    "print(\"Best parameter combination:\")\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.27981 | val_0_rmse: 1.11882 | val_1_rmse: 1.18067 |  0:00:00s\n",
      "epoch 1  | loss: 3.77337 | val_0_rmse: 1.09057 | val_1_rmse: 1.01172 |  0:00:00s\n",
      "epoch 2  | loss: 3.2985  | val_0_rmse: 1.15588 | val_1_rmse: 0.97522 |  0:00:00s\n",
      "epoch 3  | loss: 2.89247 | val_0_rmse: 1.28208 | val_1_rmse: 0.96588 |  0:00:00s\n",
      "epoch 4  | loss: 2.51057 | val_0_rmse: 1.33601 | val_1_rmse: 0.95995 |  0:00:00s\n",
      "epoch 5  | loss: 2.13982 | val_0_rmse: 1.38714 | val_1_rmse: 0.9522  |  0:00:00s\n",
      "epoch 6  | loss: 2.23449 | val_0_rmse: 1.39524 | val_1_rmse: 0.94496 |  0:00:00s\n",
      "epoch 7  | loss: 1.87152 | val_0_rmse: 1.51847 | val_1_rmse: 0.93883 |  0:00:01s\n",
      "epoch 8  | loss: 1.67493 | val_0_rmse: 1.51849 | val_1_rmse: 0.9302  |  0:00:01s\n",
      "epoch 9  | loss: 1.60763 | val_0_rmse: 1.42946 | val_1_rmse: 0.9225  |  0:00:01s\n",
      "epoch 10 | loss: 1.69615 | val_0_rmse: 1.49105 | val_1_rmse: 0.9138  |  0:00:01s\n",
      "epoch 11 | loss: 1.50724 | val_0_rmse: 1.57873 | val_1_rmse: 0.90773 |  0:00:01s\n",
      "epoch 12 | loss: 1.32696 | val_0_rmse: 1.58089 | val_1_rmse: 0.89434 |  0:00:01s\n",
      "epoch 13 | loss: 1.31078 | val_0_rmse: 1.49344 | val_1_rmse: 0.87825 |  0:00:01s\n",
      "epoch 14 | loss: 1.21254 | val_0_rmse: 1.4566  | val_1_rmse: 0.8632  |  0:00:01s\n",
      "epoch 15 | loss: 1.11776 | val_0_rmse: 1.49798 | val_1_rmse: 0.84737 |  0:00:02s\n",
      "epoch 16 | loss: 1.081   | val_0_rmse: 1.54856 | val_1_rmse: 0.82807 |  0:00:02s\n",
      "epoch 17 | loss: 1.05312 | val_0_rmse: 1.34782 | val_1_rmse: 0.80857 |  0:00:02s\n",
      "epoch 18 | loss: 0.98526 | val_0_rmse: 1.33814 | val_1_rmse: 0.78731 |  0:00:02s\n",
      "epoch 19 | loss: 0.90272 | val_0_rmse: 1.15922 | val_1_rmse: 0.76609 |  0:00:02s\n",
      "epoch 20 | loss: 0.83653 | val_0_rmse: 1.20681 | val_1_rmse: 0.76166 |  0:00:02s\n",
      "epoch 21 | loss: 0.78574 | val_0_rmse: 1.12592 | val_1_rmse: 0.74838 |  0:00:02s\n",
      "epoch 22 | loss: 0.78477 | val_0_rmse: 0.99754 | val_1_rmse: 0.75292 |  0:00:02s\n",
      "epoch 23 | loss: 0.73868 | val_0_rmse: 0.9928  | val_1_rmse: 0.93647 |  0:00:03s\n",
      "epoch 24 | loss: 0.68072 | val_0_rmse: 0.98734 | val_1_rmse: 0.79178 |  0:00:03s\n",
      "epoch 25 | loss: 0.67515 | val_0_rmse: 0.89968 | val_1_rmse: 0.71156 |  0:00:03s\n",
      "epoch 26 | loss: 0.63722 | val_0_rmse: 0.86023 | val_1_rmse: 0.70796 |  0:00:03s\n",
      "epoch 27 | loss: 0.62638 | val_0_rmse: 0.84513 | val_1_rmse: 0.70515 |  0:00:03s\n",
      "epoch 28 | loss: 0.59508 | val_0_rmse: 0.86015 | val_1_rmse: 0.70773 |  0:00:03s\n",
      "epoch 29 | loss: 0.58353 | val_0_rmse: 0.83075 | val_1_rmse: 0.70574 |  0:00:03s\n",
      "epoch 30 | loss: 0.54892 | val_0_rmse: 0.79008 | val_1_rmse: 0.69779 |  0:00:03s\n",
      "epoch 31 | loss: 0.54743 | val_0_rmse: 0.81175 | val_1_rmse: 0.69509 |  0:00:04s\n",
      "epoch 32 | loss: 0.54599 | val_0_rmse: 0.75832 | val_1_rmse: 0.67533 |  0:00:04s\n",
      "epoch 33 | loss: 0.50878 | val_0_rmse: 0.71973 | val_1_rmse: 0.65871 |  0:00:04s\n",
      "epoch 34 | loss: 0.50345 | val_0_rmse: 0.71325 | val_1_rmse: 0.64624 |  0:00:04s\n",
      "epoch 35 | loss: 0.49018 | val_0_rmse: 0.68742 | val_1_rmse: 0.64034 |  0:00:04s\n",
      "epoch 36 | loss: 0.47663 | val_0_rmse: 0.68513 | val_1_rmse: 0.63038 |  0:00:04s\n",
      "epoch 37 | loss: 0.46543 | val_0_rmse: 0.69053 | val_1_rmse: 0.62546 |  0:00:04s\n",
      "epoch 38 | loss: 0.46297 | val_0_rmse: 0.6981  | val_1_rmse: 0.62675 |  0:00:04s\n",
      "epoch 39 | loss: 0.44816 | val_0_rmse: 0.6544  | val_1_rmse: 0.61809 |  0:00:05s\n",
      "epoch 40 | loss: 0.43124 | val_0_rmse: 0.64025 | val_1_rmse: 0.60641 |  0:00:05s\n",
      "epoch 41 | loss: 0.43058 | val_0_rmse: 0.63607 | val_1_rmse: 0.59697 |  0:00:05s\n",
      "epoch 42 | loss: 0.42178 | val_0_rmse: 0.62566 | val_1_rmse: 0.59649 |  0:00:05s\n",
      "epoch 43 | loss: 0.41828 | val_0_rmse: 0.62163 | val_1_rmse: 0.59499 |  0:00:05s\n",
      "epoch 44 | loss: 0.40911 | val_0_rmse: 0.61899 | val_1_rmse: 0.59173 |  0:00:05s\n",
      "epoch 45 | loss: 0.40514 | val_0_rmse: 0.61414 | val_1_rmse: 0.59076 |  0:00:05s\n",
      "epoch 46 | loss: 0.39819 | val_0_rmse: 0.61952 | val_1_rmse: 0.58857 |  0:00:05s\n",
      "epoch 47 | loss: 0.39749 | val_0_rmse: 0.61719 | val_1_rmse: 0.58612 |  0:00:06s\n",
      "epoch 48 | loss: 0.38791 | val_0_rmse: 0.61285 | val_1_rmse: 0.5836  |  0:00:06s\n",
      "epoch 49 | loss: 0.38953 | val_0_rmse: 0.60411 | val_1_rmse: 0.58277 |  0:00:06s\n",
      "epoch 50 | loss: 0.39199 | val_0_rmse: 0.60025 | val_1_rmse: 0.58146 |  0:00:06s\n",
      "epoch 51 | loss: 0.37965 | val_0_rmse: 0.60437 | val_1_rmse: 0.58181 |  0:00:06s\n",
      "epoch 52 | loss: 0.37866 | val_0_rmse: 0.60471 | val_1_rmse: 0.58027 |  0:00:06s\n",
      "epoch 53 | loss: 0.3771  | val_0_rmse: 0.60434 | val_1_rmse: 0.57961 |  0:00:06s\n",
      "epoch 54 | loss: 0.37599 | val_0_rmse: 0.60103 | val_1_rmse: 0.57806 |  0:00:06s\n",
      "epoch 55 | loss: 0.37358 | val_0_rmse: 0.59915 | val_1_rmse: 0.57682 |  0:00:07s\n",
      "epoch 56 | loss: 0.36722 | val_0_rmse: 0.59767 | val_1_rmse: 0.57494 |  0:00:07s\n",
      "epoch 57 | loss: 0.37333 | val_0_rmse: 0.59718 | val_1_rmse: 0.57502 |  0:00:07s\n",
      "epoch 58 | loss: 0.36963 | val_0_rmse: 0.59491 | val_1_rmse: 0.57447 |  0:00:07s\n",
      "epoch 59 | loss: 0.36905 | val_0_rmse: 0.59539 | val_1_rmse: 0.57456 |  0:00:07s\n",
      "epoch 60 | loss: 0.36729 | val_0_rmse: 0.59686 | val_1_rmse: 0.57625 |  0:00:07s\n",
      "epoch 61 | loss: 0.36587 | val_0_rmse: 0.59893 | val_1_rmse: 0.58182 |  0:00:07s\n",
      "epoch 62 | loss: 0.36148 | val_0_rmse: 0.59862 | val_1_rmse: 0.58256 |  0:00:07s\n",
      "epoch 63 | loss: 0.36423 | val_0_rmse: 0.59621 | val_1_rmse: 0.57959 |  0:00:08s\n",
      "epoch 64 | loss: 0.36466 | val_0_rmse: 0.59796 | val_1_rmse: 0.57663 |  0:00:08s\n",
      "epoch 65 | loss: 0.36132 | val_0_rmse: 0.60486 | val_1_rmse: 0.57754 |  0:00:08s\n",
      "epoch 66 | loss: 0.35713 | val_0_rmse: 0.6058  | val_1_rmse: 0.5762  |  0:00:08s\n",
      "epoch 67 | loss: 0.357   | val_0_rmse: 0.60372 | val_1_rmse: 0.57353 |  0:00:08s\n",
      "epoch 68 | loss: 0.3613  | val_0_rmse: 0.60398 | val_1_rmse: 0.57352 |  0:00:08s\n",
      "epoch 69 | loss: 0.35356 | val_0_rmse: 0.60334 | val_1_rmse: 0.57079 |  0:00:08s\n",
      "epoch 70 | loss: 0.35694 | val_0_rmse: 0.59438 | val_1_rmse: 0.56632 |  0:00:08s\n",
      "epoch 71 | loss: 0.35051 | val_0_rmse: 0.58636 | val_1_rmse: 0.56418 |  0:00:08s\n",
      "epoch 72 | loss: 0.35735 | val_0_rmse: 0.58583 | val_1_rmse: 0.5664  |  0:00:09s\n",
      "epoch 73 | loss: 0.35438 | val_0_rmse: 0.58668 | val_1_rmse: 0.56865 |  0:00:09s\n",
      "epoch 74 | loss: 0.35356 | val_0_rmse: 0.5876  | val_1_rmse: 0.56976 |  0:00:09s\n",
      "epoch 75 | loss: 0.34807 | val_0_rmse: 0.58729 | val_1_rmse: 0.56918 |  0:00:09s\n",
      "epoch 76 | loss: 0.34966 | val_0_rmse: 0.58714 | val_1_rmse: 0.57097 |  0:00:09s\n",
      "epoch 77 | loss: 0.34785 | val_0_rmse: 0.58419 | val_1_rmse: 0.56702 |  0:00:09s\n",
      "epoch 78 | loss: 0.34111 | val_0_rmse: 0.58261 | val_1_rmse: 0.56767 |  0:00:09s\n",
      "epoch 79 | loss: 0.34473 | val_0_rmse: 0.58161 | val_1_rmse: 0.56682 |  0:00:09s\n",
      "epoch 80 | loss: 0.34671 | val_0_rmse: 0.58134 | val_1_rmse: 0.57036 |  0:00:10s\n",
      "epoch 81 | loss: 0.34754 | val_0_rmse: 0.58059 | val_1_rmse: 0.57481 |  0:00:10s\n",
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 71 and best_val_1_rmse = 0.56418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\tf_torch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TabNet model with the optimal parameters\n",
    "tabnet_model = TabNetRegressor(\n",
    "    n_d=int(best_params[\"n_d\"]),\n",
    "    n_a=int(best_params[\"n_a\"]),\n",
    "    n_steps=int(best_params[\"n_steps\"]),\n",
    "    gamma=best_params[\"gamma\"],\n",
    "    lambda_sparse=best_params[\"lambda_sparse\"],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=eval(best_params[\"optimizer_params\"]),\n",
    "    mask_type=best_params[\"mask_type\"]\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "max_epochs = 1000\n",
    "early_stopping_rounds = 10\n",
    "\n",
    "# Train TabNet model and extract features\n",
    "tabnet_model.fit(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train_np,\n",
    "    eval_set=[(X_train, y_train_np), (X_val, y_val_np)],\n",
    "    max_epochs=max_epochs,\n",
    "    patience=early_stopping_rounds,\n",
    "    eval_metric=['rmse'],\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract compressed features from TabNet\n",
    "X_train_compressed = tabnet_model.predict(X_train)\n",
    "X_val_compressed = tabnet_model.predict(X_val)\n",
    "X_test_compressed = tabnet_model.predict(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_compressed, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_compressed, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_compressed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Optimized regression model with additional layers, dropout, and batch normalization\n",
    "class OptimizedRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(OptimizedRegressionModel, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Dropout with probability 0.3\n",
    "            \n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(64, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Set model dimensions and output\n",
    "input_dim = X_train_compressed.shape[1]\n",
    "output_dim = y_train.shape[1] * 4  # Number of targets as one-hot for each column\n",
    "\n",
    "# Initialize the optimized model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimized_regression_model = OptimizedRegressionModel(input_dim=input_dim, output_dim=output_dim).to(device)\n",
    "\n",
    "# Use a different optimizer and learning rate scheduler\n",
    "optimizer = optim.AdamW(optimized_regression_model.parameters(), lr=0.001, weight_decay=1e-5)  # AdamW with L2 regularization\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)  # Reduce LR by half every 20 epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with early stopping and learning rate scheduler\n",
    "epochs = 1000\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "best_val_loss = float(\"inf\")\n",
    "no_improve_rounds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from TabNet\n",
    "X_train_compressed = tabnet_model.predict(X_train)\n",
    "X_val_compressed = tabnet_model.predict(X_val)\n",
    "X_test_compressed = tabnet_model.predict(X_test)\n",
    "\n",
    "# 转换为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train_compressed, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_compressed, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_compressed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.long)\n",
    "\n",
    "# DataLoader for batch processing\n",
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Optimized Regression Model:   4%|▍         | 43/1000 [00:03<01:27, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping for Optimized Regression Model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Training Optimized Regression Model\"):\n",
    "    optimized_regression_model.train()\n",
    "    epoch_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = optimized_regression_model(X_batch)\n",
    "        loss = criterion(outputs.view(-1, 4), y_batch.view(-1))  # CrossEntropy loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = outputs.view(-1, 4).max(1)\n",
    "        correct_train += (predicted == y_batch.view(-1)).sum().item()\n",
    "        total_train += y_batch.view(-1).size(0)\n",
    "    \n",
    "    # Average training loss and accuracy\n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Validation loss and accuracy\n",
    "    optimized_regression_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = optimized_regression_model(X_batch)\n",
    "            val_loss += criterion(outputs.view(-1, 4), y_batch.view(-1)).item()\n",
    "\n",
    "            _, predicted = outputs.view(-1, 4).max(1)\n",
    "            correct_val += (predicted == y_batch.view(-1)).sum().item()\n",
    "            total_val += y_batch.view(-1).size(0)\n",
    "\n",
    "    # Average validation loss and accuracy\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improve_rounds = 0\n",
    "    else:\n",
    "        no_improve_rounds += 1\n",
    "\n",
    "    if no_improve_rounds >= 10:\n",
    "        print(\"Early stopping for Optimized Regression Model.\")\n",
    "        break\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss and accuracy curves\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_losses, label=\"Regression Train Loss\")\n",
    "plt.plot(val_losses, label=\"Regression Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Optimized Regression Model Training and Validation Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(train_accuracies, label=\"Regression Train Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Regression Val Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Optimized Regression Model Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5824\n",
      "Test Accuracy: 0.7606\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on the test set\n",
    "with torch.no_grad():\n",
    "    optimized_regression_model.eval()  # Set the model to evaluation mode\n",
    "    test_outputs = optimized_regression_model(X_test_tensor.to(device))  # Get model predictions for test data\n",
    "\n",
    "    # Calculate test loss using CrossEntropy\n",
    "    test_loss = criterion(\n",
    "        test_outputs.reshape(-1, 4),\n",
    "        torch.tensor(y_test.values, dtype=torch.long).reshape(-1).to(device)\n",
    "    ).item()\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    _, test_predicted = test_outputs.reshape(-1, 4).max(1)  # Get the class predictions\n",
    "    test_correct = (test_predicted == torch.tensor(y_test.values, dtype=torch.long).reshape(-1).to(device)).sum().item()\n",
    "    test_total = y_test.values.size  # Total number of samples in the test set\n",
    "    test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try based on the district not randomly select the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h3_index</th>\n",
       "      <th>density</th>\n",
       "      <th>stripclub</th>\n",
       "      <th>sports_centre</th>\n",
       "      <th>gatehouse</th>\n",
       "      <th>block</th>\n",
       "      <th>beauty_school</th>\n",
       "      <th>data_center</th>\n",
       "      <th>Noise - Noise: Construction Before/After Hours (NM1)</th>\n",
       "      <th>crossing</th>\n",
       "      <th>...</th>\n",
       "      <th>industrial</th>\n",
       "      <th>carport</th>\n",
       "      <th>Noise - Park - Loud Talking</th>\n",
       "      <th>music</th>\n",
       "      <th>bowling</th>\n",
       "      <th>public_bookcase</th>\n",
       "      <th>dog_toilet</th>\n",
       "      <th>summer_camp</th>\n",
       "      <th>Noise - Vehicle - Car/Truck Music</th>\n",
       "      <th>total_complaint_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bf05aa41743fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8bf05aa65a06fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8bf05ab4c759fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8bf05aa44cd1fff</td>\n",
       "      <td>951142.310717</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8bf05ab4b08cfff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71562</th>\n",
       "      <td>8bf0584e9775fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71563</th>\n",
       "      <td>8bf058455232fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71564</th>\n",
       "      <td>8bf05aa6a960fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71565</th>\n",
       "      <td>8bf05ab6ea19fff</td>\n",
       "      <td>65889.696876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71566</th>\n",
       "      <td>8bf05ab6c531fff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71567 rows × 482 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              h3_index        density  stripclub  sports_centre  gatehouse  \\\n",
       "0      8bf05aa41743fff       0.000000          0              0          0   \n",
       "1      8bf05aa65a06fff       0.000000          0              0          0   \n",
       "2      8bf05ab4c759fff       0.000000          0              0          0   \n",
       "3      8bf05aa44cd1fff  951142.310717          0              0          0   \n",
       "4      8bf05ab4b08cfff       0.000000          0              0          0   \n",
       "...                ...            ...        ...            ...        ...   \n",
       "71562  8bf0584e9775fff       0.000000          0              0          0   \n",
       "71563  8bf058455232fff       0.000000          0              0          0   \n",
       "71564  8bf05aa6a960fff       0.000000          0              0          0   \n",
       "71565  8bf05ab6ea19fff   65889.696876          0              0          0   \n",
       "71566  8bf05ab6c531fff       0.000000          0              0          0   \n",
       "\n",
       "       block  beauty_school  data_center  \\\n",
       "0          0              0            0   \n",
       "1          0              0            0   \n",
       "2          0              0            0   \n",
       "3          0              0            0   \n",
       "4          0              0            0   \n",
       "...      ...            ...          ...   \n",
       "71562      0              0            0   \n",
       "71563      0              0            0   \n",
       "71564      0              0            0   \n",
       "71565      0              0            0   \n",
       "71566      0              0            0   \n",
       "\n",
       "       Noise - Noise: Construction Before/After Hours (NM1)  crossing  ...  \\\n",
       "0                                                      2            6  ...   \n",
       "1                                                      0            4  ...   \n",
       "2                                                      2            6  ...   \n",
       "3                                                      0            0  ...   \n",
       "4                                                      2            0  ...   \n",
       "...                                                  ...          ...  ...   \n",
       "71562                                                  0            0  ...   \n",
       "71563                                                  0            0  ...   \n",
       "71564                                                  0            7  ...   \n",
       "71565                                                  0            0  ...   \n",
       "71566                                                  0            0  ...   \n",
       "\n",
       "       industrial  carport  Noise - Park - Loud Talking  music  bowling  \\\n",
       "0               0        0                            3      0        0   \n",
       "1               0        0                            0      0        0   \n",
       "2               0        0                            0      0        0   \n",
       "3               0        0                            0      0        0   \n",
       "4               0        0                            0      0        0   \n",
       "...           ...      ...                          ...    ...      ...   \n",
       "71562           0        0                            0      0        0   \n",
       "71563           0        0                            0      0        0   \n",
       "71564           0        0                            0      0        0   \n",
       "71565           0        0                            0      0        0   \n",
       "71566           0        0                            0      0        0   \n",
       "\n",
       "       public_bookcase  dog_toilet  summer_camp  \\\n",
       "0                    0           0            0   \n",
       "1                    0           0            0   \n",
       "2                    0           0            0   \n",
       "3                    0           0            0   \n",
       "4                    0           0            0   \n",
       "...                ...         ...          ...   \n",
       "71562                0           0            0   \n",
       "71563                0           0            0   \n",
       "71564                0           0            0   \n",
       "71565                0           0            0   \n",
       "71566                0           0            0   \n",
       "\n",
       "       Noise - Vehicle - Car/Truck Music  total_complaint_count  \n",
       "0                                      0                   98.0  \n",
       "1                                      2                   38.0  \n",
       "2                                      3                  134.0  \n",
       "3                                      1                  126.0  \n",
       "4                                      0                   19.0  \n",
       "...                                  ...                    ...  \n",
       "71562                                  0                    1.0  \n",
       "71563                                  0                    1.0  \n",
       "71564                                  0                    1.0  \n",
       "71565                                  0                    1.0  \n",
       "71566                                  0                    1.0  \n",
       "\n",
       "[71567 rows x 482 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
